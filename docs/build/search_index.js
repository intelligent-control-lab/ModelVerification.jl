var documenterSearchIndex = {"docs":
[{"location":"branching/","page":"Branching","title":"Branching","text":"CurrentModule = ModelVerification","category":"page"},{"location":"branching/","page":"Branching","title":"Branching","text":"Pages=[\"branching.md\"]\nDepth = 3","category":"page"},{"location":"branching/#Branching","page":"Branching","title":"Branching","text":"","category":"section"},{"location":"branching/","page":"Branching","title":"Branching","text":"The \"branch\" part of the Branch and Bound paradigm for verification algorithms. The branching folder contains algorithms for dividing the input set into searchable smaller sets, which we call \"branches.\" ","category":"page"},{"location":"branching/","page":"Branching","title":"Branching","text":"The search.jl module includes algorithms to iterate over all branches, such as BFS (Breadth-first Search) and DFS (Depth-first Search). The search.jl\\search_branches function is of particular importance since it executes the verification procedure.","category":"page"},{"location":"branching/","page":"Branching","title":"Branching","text":"The split.jl module includes algorithms to split an unknown branch, such as bisect, sensitivity analysis, etc. The split.jl\\split_branch function divides the unknown branches into smaller pieces and put them back to the branch bank for future verification. This is done so that we can get a more concrete answer by refining the problem in case the over-approximation introduced in the verification process prevents us from getting a firm result.","category":"page"},{"location":"branching/#Search","page":"Branching","title":"Search","text":"","category":"section"},{"location":"branching/","page":"Branching","title":"Branching","text":"BFS\nsearch_branches(search_method::BFS, split_method, prop_method, problem, model_info)","category":"page"},{"location":"branching/#ModelVerification.BFS","page":"Branching","title":"ModelVerification.BFS","text":"BFS <: SearchMethod\n\nBreadth-first Search (BFS) used to iteratively go through the branches in the  branch bank.\n\nFields\n\nmax_iter (Int64): Maximum number of iterations to go through the branches    in the branch bank.\nbatch_size (Int64): Size of the batch. Defaults to 1.\n\n\n\n\n\n","category":"type"},{"location":"branching/#ModelVerification.search_branches-Tuple{BFS, Vararg{Any, 4}}","page":"Branching","title":"ModelVerification.search_branches","text":"search_branches(search_method::BFS, split_method, prop_method, \n                problem, model_info)\n\nSearches through the branches in the branch bank, branches, until the branch  bank is empty or time out. In each iteration (up to search_method.max_iter),  a batch of unverified branches will be extracted from the branch bank. Then, the  following is performed to verify the model:\n\nprepare_method initializes the bound of the start node of the \n\ncomputational graph based on the geometric representation and corresponding  solver.\n\npropagate propagates the bound from the start node to the end node of the \n\ncomputational graph.\n\nprocess_bound processes the bounds resulting from the propagation \n\naccordingly to the solver, prop_method. For example, for Ai2-based methods,  process_bound simply returns the bounds from the propagate step. However,  for Crown-based methods, process_bound post-processes the bounds.\n\ncheck_inclusion decides whether the bound of the end node, the reachable \n\nset, satisfies the output specification or not.      1. If not, i.e., :violated, then the counterexample is returned and the      verification process terminates.     2. If yes, i.e., :holds, then the current branch is verified and the      function starts Step 1 again for the next branch, if any.     3. If unknown, i.e., :unknown, further refinement of the problem is      preformed using split_branch, which divides the current branch into      smaller pieces and puts them into the branch bank for further verification.      Such :unknown status results due to the overapproximation introduced in      the verification process.\n\nIf the branch bank is empty after going through search_method.max_iter number  of verification procedures, the model is verified to be valid and returns  :holds. If the branch bank is not empty, the function returns :unknown.\n\nArguments\n\nsearch_method (BFS): Breadth-first Search method for iteratively going    through the branches.\nsplit_method: Method for splitting the branches when further refinement is    needed. This inclueds methods such as Bisect and BaBSR.\nprop_method: Propagation method used for the verification process. This is    one of the solvers used to verify the given model.\nproblem: Problem definition for model verification.\nmodel_info: Structure containing the information of the neural network to be    verified.\ncollect_bound(optional): default: false, whether return the verified bound.\npre_split(optional): nothing, the number of split before nay propagation. This    is particularly useful for large input set that could lead to memory overflow.\n\nReturns\n\nBasicResult(:holds) if all the reachable sets are within the corresponding    output specifications in the batch.\nBasicResult(:unknown) if the function failed to make a firm decision within    the given time. This is due to the overapproximation introduced in the    verification process.\nCounterExampleResult(:violated, x) if a reachable set is not within the    corresponding output specification and there is a counterexample found.\n\n\n\n\n\n","category":"method"},{"location":"branching/#Split","page":"Branching","title":"Split","text":"","category":"section"},{"location":"branching/#Bisection","page":"Branching","title":"Bisection","text":"","category":"section"},{"location":"branching/","page":"Branching","title":"Branching","text":"Bisect\nsplit_branch(split_method::Bisect, model::Chain, input::Hyperrectangle, output, model_info, batch_info)\nsplit_branch(split_method::Bisect, model::Chain, input::LazySet, output, model_info, batch_info)\nsplit_branch(split_method::Bisect, model::Chain, input::ImageStarBound, output)\nsplit_branch(split_method::Bisect, model::Chain, input::ImageStarBound, output, model_info, batch_info)\nsplit_branch(split_method::Bisect, model::Chain, input::ImageZonoBound, output, model_info, batch_info)\nsplit_interval(dom::Hyperrectangle, i::Int64)","category":"page"},{"location":"branching/#ModelVerification.Bisect","page":"Branching","title":"ModelVerification.Bisect","text":"Bisect <: SplitMethod\n\nBisection method for splitting branches.\n\nFields\n\nnum_split (Int64): Number of splits to be called.\n\n\n\n\n\n","category":"type"},{"location":"branching/#ModelVerification.split_branch-Tuple{Bisect, Flux.Chain, LazySets.Hyperrectangle, Any, Any, Any}","page":"Branching","title":"ModelVerification.split_branch","text":"split_branch(split_method::Bisect, model::Chain, input::Hyperrectangle, \n             output, model_info, batch_info)\n\nRecursively bisects the hyperrectangle input specification at the center for  split_method.num_split number of times.\n\nArguments\n\nsplit_method (Bisect): Bisection split method.\nmodel (Chain): Model to be verified.\ninput (Hyperrectangle): Input specification represented with a    Hyperrectangle.\noutput: Output specification.\nmodel_info: Structure containing the information of the neural network to be    verified.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nList of subtrees split from the input.\n\n\n\n\n\n","category":"method"},{"location":"branching/#ModelVerification.split_branch-Tuple{Bisect, Flux.Chain, LazySets.LazySet, Any, Any, Any}","page":"Branching","title":"ModelVerification.split_branch","text":"split_branch(split_method::Bisect, model::Chain, input::LazySet, \n             output, model_info, batch_info)\n\nGiven an input specification represented with any geometry, this function  converts it to a hyperrectangle. Then, it calls split_branch(...,  input::Hyperrectangle, ...) to recursively bisect the input specification for a  split_method.num_split number of times.\n\nArguments\n\nsplit_method (Bisect): Bisection split method.\nmodel (Chain): Model to be verified.\ninput (LazySet): Input specification represented with any LazySet.\noutput: Output specification.\nmodel_info: Structure containing the information of the neural network to be    verified.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nList of subtrees split from the input.\n\n\n\n\n\n","category":"method"},{"location":"branching/#ModelVerification.split_branch-Tuple{Bisect, Flux.Chain, ModelVerification.ImageStarBound, Any}","page":"Branching","title":"ModelVerification.split_branch","text":"split_branch(split_method::Bisect, model::Chain, \n             input::ImageStarBound, output)\n\nGiven an input specification represented with an ImageStarBound, this function  converts it \n\nArguments\n\nsplit_method (Bisect): Bisection split method.\nmodel (Chain): Model to be verified.\ninput (ImageStarBound): Input specification represented with an    ImageStarBound.\noutput: Output specification.\n\n\n\n\n\n","category":"method"},{"location":"branching/#ModelVerification.split_branch-Tuple{Bisect, Flux.Chain, ModelVerification.ImageStarBound, Any, Any, Any}","page":"Branching","title":"ModelVerification.split_branch","text":"split_branch(split_method::Bisect, model::Chain, \n             input::ImageStarBound, output, model_info, batch_info)\n\nTO-BE-IMPLEMENTED\n\n\n\n\n\n","category":"method"},{"location":"branching/#ModelVerification.split_branch-Tuple{Bisect, Flux.Chain, ModelVerification.ImageZonoBound, Any, Any, Any}","page":"Branching","title":"ModelVerification.split_branch","text":"split_branch(split_method::Bisect, model::Chain, input::ImageZonoBound, \n             output, model_info, batch_info)\n\n\n\n\n\n","category":"method"},{"location":"branching/#ModelVerification.split_interval-Tuple{LazySets.Hyperrectangle, Int64}","page":"Branching","title":"ModelVerification.split_interval","text":"split_interval(dom::Hyperrectangle, i::Int64)\n\nSplit a set into two at the given index.\n\nArguments\n\ndom (Hyperrectangle): The set in hyperrectangle to be split.\ni (Int64): The index to split at.\n\nReturns\n\n(left, right)::Tuple{Hyperrectangle, Hyperrectangle}: Two sets after split.\n\n\n\n\n\n","category":"method"},{"location":"branching/#Branch-and-bound","page":"Branching","title":"Branch-and-bound","text":"","category":"section"},{"location":"branching/","page":"Branching","title":"Branching","text":"BaBSR\nsplit_branch(split_method::BaBSR, model::Chain, input::ReLUConstrainedDomain, output, model_info, batch_info)\nsplit_beta(S_dict, score, split_relu_node, i, split_neurons_index_in_node, j, input, output)\nvecsign_convert_to_original_size(index, vector, original)\nvecmask_convert_to_original_size(index, original)\nbranching_scores_kfsb(model_info, batch_info, input)\ntopk(score, k, model_info)","category":"page"},{"location":"branching/#ModelVerification.BaBSR","page":"Branching","title":"ModelVerification.BaBSR","text":"BaBSR <: SplitMethod\n\nBranch-and-Bound method for splitting branches.\n\nFields\n\nnum_split (Int64): Number of splits to be called.\n\n\n\n\n\n","category":"type"},{"location":"branching/#ModelVerification.split_branch-Tuple{BaBSR, Flux.Chain, ModelVerification.ReLUConstrainedDomain, Any, Any, Any}","page":"Branching","title":"ModelVerification.split_branch","text":"split_branch(split_method::BaBSR, model::Chain, \n             input::ReLUConstrainedDomain, output, model_info, batch_info)\n\n\n\n\n\n","category":"method"},{"location":"branching/#ModelVerification.split_beta-NTuple{8, Any}","page":"Branching","title":"ModelVerification.split_beta","text":"split_beta(relu_con_dict, score, split_relu_node, i, split_neurons_index_in_node, j, input, output)\n\n\n\n\n\n","category":"method"},{"location":"branching/#ModelVerification.vecsign_convert_to_original_size-Tuple{Any, Any, Any}","page":"Branching","title":"ModelVerification.vecsign_convert_to_original_size","text":"vecsign_convert_to_original_size(index, vector, original)\n\nArguments\n\nReturns\n\n\n\n\n\n","category":"method"},{"location":"branching/#ModelVerification.vecmask_convert_to_original_size-Tuple{Any, Any}","page":"Branching","title":"ModelVerification.vecmask_convert_to_original_size","text":"vecmask_convert_to_original_size(index, original)\n\nArguments\n\nReturns\n\n\n\n\n\n","category":"method"},{"location":"branching/#ModelVerification.branching_scores_kfsb-Tuple{Any, Any, Any}","page":"Branching","title":"ModelVerification.branching_scores_kfsb","text":"branching_scores_kfsb(model_info, batch_info, input)\n\n\"Kernel Function Split Branch\"\n\n\n\n\n\n","category":"method"},{"location":"branching/#ModelVerification.topk-Tuple{Any, Any, Any}","page":"Branching","title":"ModelVerification.topk","text":"topk(score, k, model_info)\n\n\"Top Kernel\"\n\n\n\n\n\n","category":"method"},{"location":"branching/#Input-Gradient-Split","page":"Branching","title":"Input Gradient Split","text":"","category":"section"},{"location":"branching/","page":"Branching","title":"Branching","text":"InputGradSplit","category":"page"},{"location":"branching/#ModelVerification.InputGradSplit","page":"Branching","title":"ModelVerification.InputGradSplit","text":"InputGradSplit <: SplitMethod\n\nFields\n\nnum_split (Int64): Number of splits to be called.\n\n\n\n\n\n","category":"type"},{"location":"network/","page":"Network","title":"Network","text":"CurrentModule = ModelVerification","category":"page"},{"location":"network/","page":"Network","title":"Network","text":"Pages = [\"network.md\"]\nDepth = 3","category":"page"},{"location":"network/#Network","page":"Network","title":"Network","text":"","category":"section"},{"location":"network/#Model","page":"Network","title":"Model","text":"","category":"section"},{"location":"network/","page":"Network","title":"Network","text":"Model","category":"page"},{"location":"network/#ModelVerification.Model","page":"Network","title":"ModelVerification.Model","text":"Model\n\nStructure containing the information of the neural network to be verified.\n\nFields\n\nstart_nodes (Array{String, 1}): List of input layer nodes' names.\nfinal_nodes (Array{String, 1}): List of output layer nodes' names.\nall_nodes (Array{String, 1}): List of all the nodes's names.\nnode_layer (Dict): Dictionary of all the nodes. The key is the name of the    node and the value is the operation performed at the node.\nnode_prevs (Dict): Dictionary of the nodes connected to the current node.   The key is the name of the node and the value is the list of nodes.\nnode_nexts (Dict): Dictionary of the nodes connected from the current    node. The key is the name of the node and the value is the list of nodes.\nactivation_nodes (Array{String, 1}): List of all the activation nodes'    names.\nactivation_number (Int): Number of activation nodes (deprecated in the    future).\n\n\n\n\n\n","category":"type"},{"location":"network/#Network-2","page":"Network","title":"Network","text":"","category":"section"},{"location":"network/","page":"Network","title":"Network","text":"Network\nLayer{F<:ActivationFunction, N<:Number}","category":"page"},{"location":"network/#ModelVerification.Network","page":"Network","title":"ModelVerification.Network","text":"Network\n\nA vector of layers.\n\nFields\n\nlayers (Vector{Layer}): Layers of the network, including the output layer.\n\nSee also: Layer\n\n\n\n\n\n","category":"type"},{"location":"network/#ModelVerification.Layer","page":"Network","title":"ModelVerification.Layer","text":"Layer{F<:ActivationFunction, N<:Number}\n\nConsists of weights and bias for linear mapping, and activation for  nonlinear mapping.\n\nFields\n\nweights::Matrix{N}\nbias::Vector{N}\nactivation::F\n\nSee also: Network\n\n\n\n\n\n","category":"type"},{"location":"network/#Activation-Functions","page":"Network","title":"Activation Functions","text":"","category":"section"},{"location":"network/","page":"Network","title":"Network","text":"Modules=[ModelVerification]\nPages=[\"activation.jl\"]","category":"page"},{"location":"network/#ModelVerification.ActivationFunction","page":"Network","title":"ModelVerification.ActivationFunction","text":"ActivationFunction\n\nFunction that calculates the output of the node. Supported activation functions are:\n\nReLU (ReLU)\nMax (Max)\nIdentity (Id)\nSigmoid (Sigmoid)\nTanh (Tanh)\n\n\n\n\n\n","category":"type"},{"location":"network/#ModelVerification.GeneralAct","page":"Network","title":"ModelVerification.GeneralAct","text":"GeneralAct <: ActivationFunction\n\nWrapper type for a general activation function.\n\nUsage\n\nact = GeneralAct(tanh)\n\nact(0) == tanh(0)           # true\nact(10.0) == tanh(10.0)     # true\n\nact = GeneralAct(x->tanh.(x))\n\njulia> act(-2:2)\n5-element Array{Float64,1}:\n -0.9640275800758169\n -0.7615941559557649\n  0.0\n  0.7615941559557649\n  0.9640275800758169\n\n\n\n\n\n","category":"type"},{"location":"network/#ModelVerification.Id","page":"Network","title":"ModelVerification.Id","text":"Id <: ActivationFunction\n\nIdentity operator\n\n(Id())(x) -> x\n\n\n\n\n\n","category":"type"},{"location":"network/#ModelVerification.Max","page":"Network","title":"ModelVerification.Max","text":"Max <: ActivationFunction\n\n(Max())(x) -> max(maximum(x), 0)\n\n\n\n\n\n","category":"type"},{"location":"network/#ModelVerification.PiecewiseLinear","page":"Network","title":"ModelVerification.PiecewiseLinear","text":"PiecewiseLinear <: ActivationFunction\n\nActivation function that uses linear interpolation between supplied knots. An extrapolation condition can be set for values outside the set of knots. Default is Linear.\n\nPiecewiseLinear(knots_x, knots_y, [extrapolation = Line()])\n\nUsage\n\nkx = [0.0, 1.2, 1.7, 3.1]\nky = [0.0, 0.5, 1.0, 1.5]\nact = PiecewiseLinear(kx, ky)\n\nact(first(kx)) == first(ky) == 0.0\nact(last(kx))  == last(ky)  == 1.5\n\nact(1.0)    # 0.4166666666666667\nact(-102)   # -42.5\n\nact = PiecewiseLinear(kx, ky, Flat())\n\nact(-102)   # 0.0\nact(Inf)    # 1.5\n\nExtrapolations\n\nFlat()\nLine()\nconstant (supply a number as the argument)\nThrow() (throws bounds error)\n\nPiecewiseLinear uses Interpolations.jl.\n\n\n\n\n\n","category":"type"},{"location":"network/#ModelVerification.ReLU","page":"Network","title":"ModelVerification.ReLU","text":"ReLU <: ActivationFunction\n\n(ReLU())(x) -> max.(x, 0)\n\n\n\n\n\n","category":"type"},{"location":"network/#ModelVerification.Sigmoid","page":"Network","title":"ModelVerification.Sigmoid","text":"Sigmoid <: ActivationFunction\n\n(Sigmoid())(x) -> 1 ./ (1 .+ exp.(-x))\n\n\n\n\n\n","category":"type"},{"location":"network/#ModelVerification.Tanh","page":"Network","title":"ModelVerification.Tanh","text":"Tanh <: ActivationFunction\n\n(Tanh())(x) -> tanh.(x)\n\n\n\n\n\n","category":"type"},{"location":"network/#Helper-Functions","page":"Network","title":"Helper Functions","text":"","category":"section"},{"location":"network/","page":"Network","title":"Network","text":"onnx_parse(onnx_model_path)\nget_act(l)\nn_nodes(L::Layer)\nread_nnet(fname::String; last_layer_activation = Id())\nread_layer(output_dim::Int64, f::IOStream, act = ReLU())\nto_comment(txt)\nprint_layer(file::IOStream, layer)\nprint_header(file::IOStream, network; header_text=\"\")\nwrite_nnet(filename, network; header_text)","category":"page"},{"location":"network/#ModelVerification.onnx_parse-Tuple{Any}","page":"Network","title":"ModelVerification.onnx_parse","text":"onnx_parse(onnx_model_path)\n\nCreates the Model from the onnx_model_path. First, the computational graph  of the ONNX model is created. Then, the Model is created using the information retrieved from the computational graph.\n\nArguments\n\nonnx_model_path: String path to the ONNX model.\n\nReturns\n\nmodel_info (Model): Contains network information retrieved from the    computational graph of the ONNX model.\n\n\n\n\n\n","category":"method"},{"location":"network/#ModelVerification.get_act-Tuple{Any}","page":"Network","title":"ModelVerification.get_act","text":"get_act(l)\n\nReturns the activation function of the node l if it exists.\n\nArguments\n\nl: node\n\nReturns\n\nActivation function of the node if it exists.\nOtherwise, return nothing.\n\n\n\n\n\n","category":"method"},{"location":"network/#ModelVerification.n_nodes-Tuple{ModelVerification.Layer}","page":"Network","title":"ModelVerification.n_nodes","text":"n_nodes(L::Layer)\n\nReturns the number of neurons in a layer.\n\n\n\n\n\n","category":"method"},{"location":"network/#ModelVerification.read_nnet-Tuple{String}","page":"Network","title":"ModelVerification.read_nnet","text":"read_nnet(fname::String; last_layer_activation = Id())\n\nRead in neural net from a .nnet file and return Network struct. The .nnet format is borrowed from NNet. The format assumes all hidden layers have ReLU activation. Keyword argument last_layer_activation sets the activation of the last layer, and defaults to Id(), (i.e. a linear output layer).\n\nArguments\n\nfname (String): String path to the .nnet file.\nlast_layer_activation: Keyword argument that sets the activation of the last    layer which defaults to Id().\n\nReturns\n\nA vector of layers saved as Network.\n\n\n\n\n\n","category":"method"},{"location":"network/#ModelVerification.read_layer","page":"Network","title":"ModelVerification.read_layer","text":"read_layer(output_dim::Int64, f::IOStream, act = ReLU())\n\nRead in layer from .nnet file and return a Layer containing its  weights & biases. Optional argument act sets the activation function for the  layer.\n\nArguments\n\noutput_dim (Int64): Output dimension of the layer.\nf (IOStream): IO stream of the .nnet file.\nact: Optional argument specifying the activation function of the layer.    Defaults to ReLU().\n\nReturns\n\nLayer containing the weights and bias values (and the activation function    of the layer).\n\n\n\n\n\n","category":"function"},{"location":"network/#ModelVerification.to_comment-Tuple{Any}","page":"Network","title":"ModelVerification.to_comment","text":"to_comment(txt)\n\nPrepend // to each line of a string.\n\n\n\n\n\n","category":"method"},{"location":"network/#ModelVerification.print_layer-Tuple{IOStream, Any}","page":"Network","title":"ModelVerification.print_layer","text":"print_layer(file::IOStream, layer)\n\nPrint to file an object implementing weights(layer) and bias(layer).\n\nArguments\n\nfile (IOStream): IO stream of the target .nnet file.\nlayer: Layer to be transcribed to file.\n\n\n\n\n\n","category":"method"},{"location":"network/#ModelVerification.print_header-Tuple{IOStream, Any}","page":"Network","title":"ModelVerification.print_header","text":"print_header(file::IOStream, network; header_text=\"\")\n\nThe NNet format has a particular header containing information about the  network size and training data. print_header does not take training-related  information into account (subject to change).\n\nArguments\n\nfile (IOStream): IO stream of the target .nnet file.\nnetwork: Network to be transcribed to file.\nheader_text: Optional header text that comes before the network information.    Defaults to an empty string.\n\n\n\n\n\n","category":"method"},{"location":"network/#ModelVerification.write_nnet-Tuple{Any, Any}","page":"Network","title":"ModelVerification.write_nnet","text":"write_nnet(filename, network; header_text)\n\nWrite network to filename.nnet. Note: Does not perform safety checks on inputs, so use with caution.\n\nBased on python code at https://github.com/sisl/NNet/blob/master/utils/writeNNet.py and follows .nnet format given here: https://github.com/sisl/NNet.\n\nArguments\n\noutfile: String name of the .nnet file.\nnetwork: Network to be transcribed to outfile.nnet.\nheader_text: Optional header text that comes before the network information.\n\n\n\n\n\n","category":"method"},{"location":"existing_implementations/#Existing-Implementations","page":"Existing Implementations","title":"Existing Implementations","text":"","category":"section"},{"location":"existing_implementations/","page":"Existing Implementations","title":"Existing Implementations","text":"MIPVerify\nConvDual\nReluVal\nNeurify\nSherlock\nPlanet\nPLNN\nDLV\nReluplex","category":"page"},{"location":"propagate/","page":"Propagation","title":"Propagation","text":"Pages=[\"propagation.md\"]\nDepth = 3","category":"page"},{"location":"propagate/#Propagation","page":"Propagation","title":"Propagation","text":"","category":"section"},{"location":"propagate/","page":"Propagation","title":"Propagation","text":"Functions for propagating the bound through the model (from start nodes to the end nodes) for a given branch. For a forward propagation method (ForwardProp), the start nodes are the input nodes of the computational graph and the end nodes are the output nodes. For a backward propagation method (BackwardProp), the start nodes are the output nodes and the end nodes are the input nodes. We use BFS (Breadth-first Search) to iterate through the computational graph and propagates the bounds from nodes to nodes.","category":"page"},{"location":"propagate/","page":"Propagation","title":"Propagation","text":"The propagate\\propagate.jl module defines algorithms for propagating bounds from input to output, for both forward propagation and backward propagation.","category":"page"},{"location":"propagate/","page":"Propagation","title":"Propagation","text":"The propagate\\operators folder contains specific propagation algorithms for different operators, such as ReLU, Dense, Identity, Convolution, Bivariate, etc.","category":"page"},{"location":"propagate/","page":"Propagation","title":"Propagation","text":"PropMethod","category":"page"},{"location":"propagate/#ModelVerification.PropMethod","page":"Propagation","title":"ModelVerification.PropMethod","text":"PropMethod\n\n\n\n\n\n","category":"type"},{"location":"propagate/","page":"Propagation","title":"Propagation","text":"Modules=[ModelVerification]\nPages=[\"propagate.jl\"]","category":"page"},{"location":"propagate/#ModelVerification.all_nexts_in-NTuple{4, Any}","page":"Propagation","title":"ModelVerification.all_nexts_in","text":"all_nexts_in(prop_method, model_info, output_node, cnt)\n\nReturns true if all of the next nodes of the output_node have been visited.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.all_prevs_in-NTuple{4, Any}","page":"Propagation","title":"ModelVerification.all_prevs_in","text":"all_prevs_in(prop_method, model_info, output_node, cnt)\n\nReturns true if the output_node has been visited from all the previous nodes. This function checks if all possible connections to the output_node has been  made in the propagation procedure. For example, given a node X, say that there are 5 different nodes that are  mapped to X. Then, if the node X has been visited 5 times, i.e., cnt == 5,  it means that all the previous nodes of X has been outputted to X.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.backward_layer-NTuple{4, Any}","page":"Propagation","title":"ModelVerification.backward_layer","text":"backward_layer(prop_method, layer, batch_bound, batch_info)\n\n(DEPRECATED)\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.backward_layer-Tuple{Any, Any, Any}","page":"Propagation","title":"ModelVerification.backward_layer","text":"backward_layer(prop_method, layer, batch_bound)\n\n(DEPRECATED)\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.enqueue_nodes!-Tuple{ModelVerification.BackwardProp, Any, Any}","page":"Propagation","title":"ModelVerification.enqueue_nodes!","text":"enqueue_nodes!(prop_method::BackwardProp, queue, model_info)\n\nInserts the final nodes into the given queue for BackwardProp methods.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.enqueue_nodes!-Tuple{ModelVerification.ForwardProp, Any, Any}","page":"Propagation","title":"ModelVerification.enqueue_nodes!","text":"enqueue_nodes!(prop_method::ForwardProp, queue, model_info)\n\nInserts the nodes connected from the starting node into the given queue for  ForwardProp methods.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.forward_act_batch-Tuple{ModelVerification.ForwardProp, Any, AbstractArray, AbstractArray}","page":"Propagation","title":"ModelVerification.forward_act_batch","text":"forward_act_batch(prop_method::ForwardProp, σ, batch_reach::AbstractArray, batch_info::AbstractArray)\n\n(DEPRECATED)\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.forward_layer-NTuple{4, Any}","page":"Propagation","title":"ModelVerification.forward_layer","text":"forward_layer(prop_method, layer, batch_bound, batch_info)\n\n(DEPRECATED)\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.forward_linear_batch-Tuple{ModelVerification.ForwardProp, Any, AbstractArray, AbstractArray}","page":"Propagation","title":"ModelVerification.forward_linear_batch","text":"forward_linear_batch(prop_method::ForwardProp, layer, batch_reach::AbstractArray, batch_info::AbstractArray)\n\n(DEPRECATED)\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.forward_skip_batch-Tuple{ModelVerification.ForwardProp, Any, Vararg{AbstractArray, 4}}","page":"Propagation","title":"ModelVerification.forward_skip_batch","text":"forward_skip_batch(prop_method::ForwardProp, layer, batch_reach1::AbstractArray, batch_reach2::AbstractArray, batch_info1::AbstractArray, batch_info2::AbstractArray)\n\n(DEPRECATED)\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.has_two_reach_node-Tuple{Any, Any, Any}","page":"Propagation","title":"ModelVerification.has_two_reach_node","text":"has_two_reach_node(prop_method, model_info, node)\n\nChecks whether there are two nodes connected to the current node, i.e., there  are two previous nodes. This function is used to check if there are skip  connections.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.is_activation-Tuple{Any}","page":"Propagation","title":"ModelVerification.is_activation","text":"is_activation(l)\n\nReturns true if the given layer l is an activation layer.\n\nArguments\n\nl: Layer.\n\nReturns\n\nTrue if l is activation layer.\nFalse otherwise.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.next_nodes-Tuple{ModelVerification.BackwardProp, Any, Any}","page":"Propagation","title":"ModelVerification.next_nodes","text":"next_nodes(prop_method::BackwardProp, model_info, node)\n\nReturns the previous nodes of the node for BackwardProp methods. Since this  is for BackwardProp methods, the previous nodes are the \"next\" nodes.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.next_nodes-Tuple{ModelVerification.ForwardProp, Any, Any}","page":"Propagation","title":"ModelVerification.next_nodes","text":"next_nodes(prop_method::ForwardProp,  model_info, node)\n\nReturns the next nodes of the node for ForwardProp methods.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.output_node-Tuple{ModelVerification.BackwardProp, Any}","page":"Propagation","title":"ModelVerification.output_node","text":"output_node(prop_method::BackwardProp, model_info)\n\nReturns the starting nodes of the model for BackwardProp methods. Since this  is for BackwardProp methods, the starting nodes of the model are the output  nodes.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.output_node-Tuple{ModelVerification.ForwardProp, Any}","page":"Propagation","title":"ModelVerification.output_node","text":"output_node(prop_method::ForwardProp, model_info)\n\nReturns the final nodes of the model.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.prev_nodes-Tuple{ModelVerification.BackwardProp, Any, Any}","page":"Propagation","title":"ModelVerification.prev_nodes","text":"prev_nodes(prop_method::BackwardProp, model_info, node)\n\nReturns the next nodes of the node for BackwardProp methods. Since this is  for BackwardProp methods, the next nodes are the \"previous\" nodes.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.prev_nodes-Tuple{ModelVerification.ForwardProp, Any, Any}","page":"Propagation","title":"ModelVerification.prev_nodes","text":"prev_nodes(prop_method::ForwardProp,  model_info, node)\n\nReturns the previous nodes of the node for ForwardProp methods.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate-Tuple{PropMethod, Any, Any}","page":"Propagation","title":"ModelVerification.propagate","text":"propagate(prop_method::PropMethod, model_info, batch_info)\n\nPropagates through the model using the specified prop_method.  The propagation algorithm is as follows:\n\nAdd the connecting nodes of the start nodes, i.e., nodes after the start \n\nnodes, into a queue.\n\nWhile the queue is not empty:  a. Pop a node from the queue.  b. For each node connected from the current node, i.e., for each output       node:      i. Increment the visit count to the output node.      ii. If the visit count equals the number of nodes connected from the           output node, i.e., visit count == previous nodes of the output node,           add the output node to the queue.  c. Propagate through the current node accordingly.  d. Add information about the bound of the node to batch_info.\nReturn the bound of the output node(s).\n\nIn step 2(a)(ii), the function adds the output node to the queue since all the  previous nodes of the output node have been processed. Thus, the output node is  now the node of interest. In step 2(c), the propagation works based on the  propagation method (prop_method), which depends on the geometric  representation of the safety specifications and the activation function of each  layer.\n\nArguments\n\nprop_method (PropMethod): Propagation method used for the verification    process. This is one of the solvers used to verify the given model.\nmodel_info: Structure containing the information of the neural network to be    verified.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nbatch_bound: Bound of the output node, i.e., the final bound.\nbatch_info: Same as the input batch_info, with additional information on    the bound of each node in the model.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_act_batch-Tuple{ModelVerification.ForwardProp, Any, AbstractArray, Any}","page":"Propagation","title":"ModelVerification.propagate_act_batch","text":"propagate_act_batch(prop_method::ForwardProp, σ, \n                    batch_reach::AbstractArray, batch_info)\n\nPropagates each of the bound in the batch_reach array with the given forward  propagation method, prop_method, through an activation layer. \n\nArguments\n\nprop_method (ForwardProp): Forward propagation method used for the    verification process. This is one of the solvers used to verify the given    model.\nσ: Type of activation function, such as ReLU.\nbatch_reach (AbstractArray): List of input specifications, i.e., bounds,     to be propagated through the given layer.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nbatch_reach_info: List of reachable bounds after propagating the set of    bounds in batch_reach through the given layer, following the propagation    method and the activation layer operation.                        \n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_layer_batch-NTuple{4, Any}","page":"Propagation","title":"ModelVerification.propagate_layer_batch","text":"propagate_layer_batch(prop_method, layer, batch_bound, batch_info)\n\nPropagates through one layer. The given layer identifies what type of  operation is performed. Operations such as Dense, BatchNorm, Convolution, and  ReLU are supported. The prop_method denotes the solver (and thus the geometric  representation for safety specification). The output of the propagation is the  bounds of the given batch. \n\nArguments\n\nprop_method: Propagation method used for the verification process. This is    one of the solvers used to verify the given model.\nlayer: Identifies what type of operation is done at the layer, such as    Dense, BatchNorm, Convolution, or ReLU.\nbatch_bound: Bound of the input node (the previous node).\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nbatch_bound: The output bound after applying the operation of the node.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_layer_method-Tuple{ModelVerification.BackwardProp, Any, Any, Any}","page":"Propagation","title":"ModelVerification.propagate_layer_method","text":"propagate_layer_method(prop_method::BackwardProp, model_info, batch_info, node)\n\nThis function propagates the bounds of the next node from the provided node  using the specified forward propagation method and layer operation. It invokes  propagate_layer_batch, which subsequently calls either  propagate_linear_batch or propagate_act_batch. The function identifies the  next node from the given node in the computational graph, model_info, its  bound, and the layer operation of the node. Then, propagate_layer_batch  ascertains if the layer operation is linear or includes activation functions  like ReLU. Depending on this, propagate_linear_batch or propagate_act_batch  is invoked.\n\nArguments\n\nprop_method (BackwardProp): Backward propagation method used for the    verification process. This is one of the solvers used to verify the given    model.\nmodel_info: Structure containing the information of the neural network to be    verified.\nbatch_info: Dictionary containing information of each node in the model.\nnode: The current node to be propagated through.\n\nReturns\n\nbatch_bound: List of reachable bounds after propagating the set of bounds in    batch_reach through the given node, following the propagation method and    the linear layer operation.\nnothing if the given node is a starting node of the model.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_layer_method-Tuple{ModelVerification.ForwardProp, Any, Any, Any}","page":"Propagation","title":"ModelVerification.propagate_layer_method","text":"propagate_layer_method(prop_method::ForwardProp, model_info, batch_info, node)\n\nThis function propagates the bounds of the preceding node from the provided node  using the specified forward propagation method and layer operation. It invokes  propagate_layer_batch, which subsequently calls either  propagate_linear_batch or propagate_act_batch. The function identifies the  previous node from the given node in the computational graph, model_info, its  bound, and the layer operation of the node. Then, propagate_layer_batch  ascertains if the layer operation is linear or includes activation functions  like ReLU. Depending on this, propagate_linear_batch or propagate_act_batch  is invoked.\n\nArguments\n\nprop_method (ForwardProp): The forward propagation method employed for    verification. It is one of the solvers used to validate the specified model.\nmodel_info: Structure containing the information of the neural network to be    verified.\nbatch_info: Dictionary containing information of each node in the model.\nnode: The current node to be propagated through.\n\nReturns\n\nbatch_bound: List of reachable bounds after propagating the set of input    bounds of the given node, following the propagation method and the linear    layer operation.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_linear_batch-Tuple{ModelVerification.ForwardProp, Any, AbstractArray, Any}","page":"Propagation","title":"ModelVerification.propagate_linear_batch","text":"propagate_linear_batch(prop_method::ForwardProp, layer, \n                       batch_reach::AbstractArray, batch_info)\n\nPropagates each of the bound in the batch_reach array with the given forward  propagation method, prop_method, through a linear layer. \n\nArguments\n\nprop_method (ForwardProp): Forward propagation method used for the    verification process. This is one of the solvers used to verify the given    model.\nlayer: Identifies what type of operation is done at the layer. Here, its a    linear operation.\nbatch_reach (AbstractArray): List of input specifications, i.e., bounds,     to be propagated through the given layer.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nbatch_reach_info: List of reachable bounds after propagating the set of    bounds in batch_reach through the given layer, following the propagation    method and the linear layer operation.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_skip_batch-Tuple{ModelVerification.ForwardProp, Any, AbstractArray, AbstractArray, Any}","page":"Propagation","title":"ModelVerification.propagate_skip_batch","text":"propagate_skip_batch(prop_method::ForwardProp, layer, \n                     batch_reach1::AbstractArray, \n                     batch_reach2::AbstractArray, \n                     batch_info)\n\nPropagates each combination of the bounds from the batch_reach1 and  batch_reach2 arrays with the given forward propagation method, prop_method,  through a skip connection. \n\nArguments\n\nprop_method (ForwardProp): Forward propagation method used for the    verification process. This is one of the solvers used to verify the given    model.\nlayer: Identifies what type of operation is done at the layer. Here's a    bivariate operation is mainly used.\nbatch_reach1 (AbstractArray): First list of input specifications, i.e.,    bounds, to be propagated through the given layer. This is the list of    bounds given by the first of the two previous nodes.\nbatch_reach2 (AbstractArray): Second list of input specifications, i.e.,    bounds, to be propagated through the given layer. This is the list of    bounds given by the second of the two previous nodes.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nbatch_reach_info: List of reachable bounds after propagating the    bounds in batch_reach1 and batch_reach2 through the given layer,    following the propagation method and the layer operation.                         \n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_skip_method-Tuple{ModelVerification.BackwardProp, Any, Any, Any}","page":"Propagation","title":"ModelVerification.propagate_skip_method","text":"propagate_skip_method(prop_method::BackwardProp, model_info, \n                      batch_info, node)\n\nThis function propagates the two sets of bounds of the next nodes from the  provided node using the specified backward propagation method and layer  operation. It invokes propagate_skip_batch, which subsequently calls   propagate_skip. The function identifies the two next nodes from the given node in the computational graph, model_info, their bounds, and the layer  operation of the node. Then, propagate_skip is invoked.\n\nArguments\n\nprop_method (BackwardProp): Backward propagation method used for the    verification process. This is one of the solvers used to verify the given    model.\nmodel_info: Structure containing the information of the neural network to be    verified.\nbatch_info: Dictionary containing information of each node in the model.\nnode: The current node to be propagated through.\n\nReturns\n\nbatch_bound: List of reachable bounds after propagating the two sets of   bounds in batch_reach through the given node, following the propagation    method and the layer operation.                          \n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_skip_method-Tuple{ModelVerification.ForwardProp, Any, Any, Any}","page":"Propagation","title":"ModelVerification.propagate_skip_method","text":"propagate_skip_method(prop_method::ForwardProp, model_info, \n                      batch_info, node)\n\nThis function propagates the two sets of bounds of the preceding nodes from the  provided node using the specified forward propagation method and layer  operation. It invokes propagate_skip_batch, which subsequently calls   propagate_skip. The function identifies the two previous nodes from the given node in the computational graph, model_info, their bounds, and the layer  operation of the node. Then, propagate_skip is invoked.\n\nArguments\n\nprop_method (ForwardProp): Forward propagation method used for the    verification process. This is one of the solvers used to verify the given    model.\nmodel_info: Structure containing the information of the neural network to be    verified.\nbatch_info: Dictionary containing information of each node in the model.\nnode: The current node to be propagated through.\n\nReturns\n\nbatch_bound: List of reachable bounds after propagating the two sets of   bounds in batch_reach through the given node, following the propagation    method and the layer operation.\n\n\n\n\n\n","category":"method"},{"location":"propagate/","page":"Propagation","title":"Propagation","text":"NOTE: Need to include ForwardProp, BackwardProp, ... from solvers\\solver.jl.","category":"page"},{"location":"propagate/#Bivariate","page":"Propagation","title":"Bivariate","text":"","category":"section"},{"location":"propagate/","page":"Propagation","title":"Propagation","text":"Modules=[ModelVerification]\nPages=[\"bivariate.jl\"]","category":"page"},{"location":"propagate/#ModelVerification.propagate_skip-Tuple{Any, typeof(+), ModelVerification.ImageStarBound, ModelVerification.ImageStarBound, Any}","page":"Propagation","title":"ModelVerification.propagate_skip","text":"propagate_skip(prop_method, layer::typeof(+), bound1::ImageStarBound, \n               bound2::ImageStarBound, batch_info)\n\nPropagate the bounds of the two input layers to the output layer for skip  connection. The output layer is of type ImageStarBound. The input layers'  centers, generators, and constraints are concatenated to form the output layer's  center, generators, and constraints.\n\nArguments\n\nprop_method (PropMethod): The propagation method used for the verification \n\nproblem.\n\nlayer (typeof(+)): The layer operation to be used for propagation.\nbound1 (ImageStarBound): The bound of the first input layer.\nbound2 (ImageStarBound): The bound of the second input layer.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nThe bound of the output layer represented in ImageStarBound type.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_skip-Tuple{Any, typeof(+), ModelVerification.ImageZonoBound, ModelVerification.ImageZonoBound, Any}","page":"Propagation","title":"ModelVerification.propagate_skip","text":"propagate_skip(prop_method, layer::typeof(+), bound1::ImageZonoBound, \n               bound2::ImageZonoBound, batch_info)\n\nPropagate the bounds of the two input layers to the output layer for skip  connection. The output layer is of type ImageZonoBound. The input layers'  centers and generators are concatenated to form the output layer's center and generators.\n\nArguments\n\nprop_method (PropMethod): The propagation method used for the verification    problem.\nlayer (typeof(+)): The layer operation to be used for propagation.\nbound1 (ImageZonoBound): The bound of the first input layer.\nbound2 (ImageZonoBound): The bound of the second input layer.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nThe bound of the output layer represented in ImageZonoBound type.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#Convolution","page":"Propagation","title":"Convolution","text":"","category":"section"},{"location":"propagate/","page":"Propagation","title":"Propagation","text":"Modules=[ModelVerification]\nPages=[\"convolution.jl\"]","category":"page"},{"location":"propagate/#ModelVerification.bound_layer-Tuple{Flux.Conv{2, 4, typeof(identity), Array{Float32, 4}, Vector{Float32}}, Vararg{AbstractArray, 4}}","page":"Propagation","title":"ModelVerification.bound_layer","text":"bound_layer(layer::Conv{2, 4, typeof(identity), Array{Float32, 4}, Vector{Float32}}, lower_weight::AbstractArray, upper_weight::AbstractArray, lower_bias::AbstractArray, upper_bias::AbstractArray)\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.bound_onside-Tuple{Flux.Conv{2, 4, typeof(identity), Array{Float32, 4}, Vector{Float32}}, AbstractArray, AbstractArray}","page":"Propagation","title":"ModelVerification.bound_onside","text":"bound_onside(layer::Conv{2, 4, typeof(identity), Array{Float32, 4}, Vector{Float32}}, conv_input_size::AbstractArray, batch_reach::AbstractArray)\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.interval_propagate","page":"Propagation","title":"ModelVerification.interval_propagate","text":"interval_propagate(layer::Conv{2, 4, typeof(identity), Array{Float32, 4}, Vector{Float32}}, interval, C = nothing)\n\n\n\n\n\n","category":"function"},{"location":"propagate/#ModelVerification.propagate_by_small_batch-Tuple{Any, Any}","page":"Propagation","title":"ModelVerification.propagate_by_small_batch","text":"propagate_by_small_batch(f, x; sm_batch=500)\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_linear-Tuple{ImageStar, Flux.Conv, ModelVerification.ImageStarBound, Any}","page":"Propagation","title":"ModelVerification.propagate_linear","text":"propagate_linear(prop_method::ImageStar, layer::Conv, bound::ImageStarBound, batch_info)\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_linear-Tuple{ImageStar, Flux.ConvTranspose, ModelVerification.ImageStarBound, Any}","page":"Propagation","title":"ModelVerification.propagate_linear","text":"propagate_linear(prop_method::ImageStar, layer::ConvTranspose, bound::ImageStarBound, batch_info)\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_linear-Tuple{ImageZono, Flux.Conv, ModelVerification.ImageZonoBound, Any}","page":"Propagation","title":"ModelVerification.propagate_linear","text":"propagate_linear(prop_method::ImageZono, layer::Conv, bound::ImageZonoBound, batch_info)\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_linear-Tuple{ImageZono, Flux.ConvTranspose, ModelVerification.ImageZonoBound, Any}","page":"Propagation","title":"ModelVerification.propagate_linear","text":"propagate_linear(prop_method::ImageZono, layer::ConvTranspose, bound::ImageZonoBound, batch_info)\n\n\n\n\n\n","category":"method"},{"location":"propagate/#Dense","page":"Propagation","title":"Dense","text":"","category":"section"},{"location":"propagate/","page":"Propagation","title":"Propagation","text":"Modules=[ModelVerification]\nPages=[\"dense.jl\"]","category":"page"},{"location":"propagate/#ModelVerification._preprocess","page":"Propagation","title":"ModelVerification._preprocess","text":"_preprocess(node, batch_info, bias = nothing)\n\nPreprocesses the bias of the given node for the BetaCrown solver. If the bias is not nothing, it multiplies the bias with the beta value of the node.\n\nArguments\n\nnode: Node of the model.\nbatch_info: Dictionary containing information of each node in the model.\nbias: Bias of the node, default is nothing.\n\nReturns\n\nbias: Preprocessed bias of the node.\n\n\n\n\n\n","category":"function"},{"location":"propagate/#ModelVerification.batch_interval_map-Union{Tuple{N}, Tuple{AbstractMatrix{N}, AbstractArray, AbstractArray}} where N","page":"Propagation","title":"ModelVerification.batch_interval_map","text":"batch_interval_map(W::AbstractMatrix{N}, l::AbstractArray, \n                   u::AbstractArray) where N\n\nClamps the input to the given bounds and computes the interval map of the  resulting bound using the given weight matrix.\n\nArguments\n\nW (AbstractMatrix{N}): Weight matrix of the layer.\nl (AbstractArray): Lower bound of the input.\nu (AbstractArray): Upper bound of the input.\n\nReturns\n\nTuple of:\n\nl_new (AbstractArray): Lower bound of the output.\nu_new (AbstractArray): Upper bound of the output.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.dense_bound_oneside-NTuple{4, Any}","page":"Propagation","title":"ModelVerification.dense_bound_oneside","text":"dense_bound_oneside(last_A, weight, bias, batch_size)\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_linear-Tuple{Box, Flux.Dense, LazySets.LazySet, Any}","page":"Propagation","title":"ModelVerification.propagate_linear","text":"propagate_linear(prop_method::Box, layer::Dense, reach::LazySet, batch_info)\n\nPropagate the bounds through the dense layer for Ai2 Box solver. It operates  an approximate affine transformation (affine transformation using hyperrectangle  overapproximation) on the given input bound and returns the output bound. \n\nArguments\n\nprop_method (Box): Ai2 Box solver used for the verification process.\nlayer (Dense): Dense layer of the model.\nreach (LazySet): Bound of the input.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nreach (hyperrectangle): Bound of the output after approximate affine    transformation.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_linear-Tuple{ExactReach, Flux.Dense, ModelVerification.ExactReachBound, Any}","page":"Propagation","title":"ModelVerification.propagate_linear","text":"propagate_linear(prop_method::ExactReach, layer::Dense, \n                 reach::ExactReachBound, batch_info)\n\nPropagate the bounds through the dense layer. It operates an affine  transformation on the given input bound and returns the output bound for  ExactReach solver.\n\nArguments\n\nprop_method (ExactReach): Exact reachability method used for the    verification process. This is one of the solvers used to verify the given    model.\nlayer (Dense): Dense layer of the model.\nreach (ExactReachBound): Bound of the input, represented by    ExactReachBound type, which is a vector of LazySet type.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nreach (ExactReachBound): Bound of the output after affine transformation,    which is represented by ExactReachBound type.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_linear-Tuple{ModelVerification.ForwardProp, Flux.Dense, LazySets.LazySet, Any}","page":"Propagation","title":"ModelVerification.propagate_linear","text":"propagate_linear(prop_method::ForwardProp, layer::Dense, \n                 reach::LazySet, batch_info)\n\nPropagate the bounds through the dense layer. It operates an affine  transformation on the given input bound and returns the output bound.\n\nArguments\n\nprop_method (ForwardProp): Forward propagation method used for the    verification process. This is one of the solvers used to verify the given    model.                  \nlayer (Dense): Dense layer of the model.\nreach (LazySet): Bound of the input.\nbatch_info: Dictionary containing information of each node in the    model.\n\nReturns\n\nreach (LazySet): Bound of the output after affine transformation.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_linear_batch-Tuple{BetaCrown, Flux.Dense, ModelVerification.BetaCrownBound, Any}","page":"Propagation","title":"ModelVerification.propagate_linear_batch","text":"propagate_linear_batch(prop_method::BetaCrown, layer::Dense, \n                       bound::BetaCrownBound, batch_info)\n\nPropagates the bounds through the dense layer for BetaCrown solver. It  operates an affine transformation on the given input bound and returns the output bound. It first preprocesses the lower- and upper-bounds of the bias of  the node using _preprocess. Then, it computes the interval map of the  resulting lower- and upper-bounds using dense_bound_oneside function. The  resulting bound is represented by BetaCrownBound type.\n\nArguments\n\nprop_method (BetaCrown): BetaCrown solver used for the verification    process.\nlayer (Dense): Dense layer of the model.\nbound (BetaCrownBound): Bound of the input, represented by    BetaCrownBound type.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nNew_bound (BetaCrownBound): Bound of the output after affine    transformation, which is represented by BetaCrownBound type.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_linear_batch-Tuple{Crown, Flux.Dense, ModelVerification.CrownBound, Any}","page":"Propagation","title":"ModelVerification.propagate_linear_batch","text":"propagate_linear_batch(prop_method::Crown, layer::Dense, \n                       bound::CrownBound, batch_info)\n\nPropagates the bounds through the dense layer for Crown solver. It operates an affine transformation on the given input bound and returns the output bound. It first clamps the input bound and multiplies with the weight matrix using  batch_interval_map function. Then, it adds the bias to the output bound. The resulting bound is represented by CrownBound type.\n\nArguments\n\nprop_method (Crown): Crown solver used for the verification process.\nlayer (Dense): Dense layer of the model.\nbound (CrownBound): Bound of the input, represented by CrownBound type.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nnew_bound (CrownBound): Bound of the output after affine transformation,    which is represented by CrownBound type.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#Identity","page":"Propagation","title":"Identity","text":"","category":"section"},{"location":"propagate/","page":"Propagation","title":"Propagation","text":"Modules=[ModelVerification]\nPages=[\"identity.jl\"]","category":"page"},{"location":"propagate/#ModelVerification.propagate_act-Tuple{Any, typeof(identity), Any, Any}","page":"Propagation","title":"ModelVerification.propagate_act","text":"propagate_act(prop_method, σ::typeof(identity), bound, batch_info)\n\nPropagate the bounds through the identity activation layer.\n\nArguments\n\nprop_method: Propagation method.\nσ: Identity activation function.\nbound: Bounds of the input.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nbound: Bounds of the output, which is equivalent to the bounds of the input.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#Normalise","page":"Propagation","title":"Normalise","text":"","category":"section"},{"location":"propagate/","page":"Propagation","title":"Propagation","text":"Modules=[ModelVerification]\nPages=[\"normalise.jl\"]","category":"page"},{"location":"propagate/#ModelVerification.propagate_linear-Tuple{ImageStar, Flux.BatchNorm, ModelVerification.ImageStarBound, Any}","page":"Propagation","title":"ModelVerification.propagate_linear","text":"propagate_linear(prop_method::ImageStar, layer::BatchNorm, \n                 bound::ImageStarBound, batch_info)\n\nPropagate the ImageStarBound bound through a batch norm layer. I.e., it  applies the batch norm operation to the ImageStarBound bound. The batch norm  operation is decomposed into two operations: centering and scaling. The  centering operation is applied to the center of the ImageStarBound bound. The scaling operation is applied to the generators of the ImageStarBound bound. The resulting bound is also of type ImageStarBound.\n\nArguments\n\nprop_method (ImageStar): The ImageStar propagation method used for the    verification problem.\nlayer (BatchNorm): The batch norm operation to be used for propagation.\nbound (ImageStarBound): The bound of the input node.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nThe batch normed bound of the output layer represented in ImageStarBound    type.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_linear-Tuple{ImageZono, Flux.BatchNorm, ModelVerification.ImageZonoBound, Any}","page":"Propagation","title":"ModelVerification.propagate_linear","text":"propagate_linear(prop_method::ImageZono, layer::BatchNorm, \n                 bound::ImageZonoBound, batch_info)\n\nPropagate the ImageZonoBound bound through a batch norm layer. I.e., it  applies the batch norm operation to the ImageZonoBound bound. The batch norm  operation is decomposed into two operations: centering and scaling. The  centering operation is applied to the center of the ImageZonoBound bound. The scaling operation is applied to the generators of the ImageZonoBound bound. The resulting bound is also of type ImageZonoBound.\n\nArguments\n\nprop_method (ImageZono): The ImageZono propagation method used for the    verification problem.\nlayer (BatchNorm): The batch norm operation to be used for propagation.\nbound (ImageZonoBound): The bound of the input node.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nThe batch normed bound of the output layer represented in ImageZonoBound    type.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_linear_batch-Tuple{Flux.BatchNorm, AbstractArray, Any}","page":"Propagation","title":"ModelVerification.propagate_linear_batch","text":"propagate_linear_batch(layer::BatchNorm, batch_reach::AbstractArray, \n                       batch_info)\n\nPropagate the batch_reach through a batch norm layer. I.e., it applies the  batch norm operation to the batch_reach. The batch norm operation is  decomposed into two operations: centering and scaling. This function supports  input batch with channel dimension.\n\nArguments\n\nlayer (BatchNorm): The batch norm operation to be used for propagation.\nbatch_reach (AbstractArray): The batch of input bounds.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nThe batch normed bound of the output layer.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ReLU","page":"Propagation","title":"ReLU","text":"","category":"section"},{"location":"propagate/","page":"Propagation","title":"Propagation","text":"Modules=[ModelVerification]\nPages=[\"relu.jl\"]","category":"page"},{"location":"propagate/#ModelVerification.ImageStar_to_Star-Tuple{ModelVerification.ImageStarBound}","page":"Propagation","title":"ModelVerification.ImageStar_to_Star","text":"ImageStar_to_Star(bound::ImageStarBound)\n\nConvert the ImageStarBound bound to Star bound.\n\nArguments\n\nbound (ImageStarBound): The bound of the input node, represented using    ImageStarBound type.\n\nReturns\n\nThe bound represented using Star type.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.Star_to_ImageStar-Tuple{LazySets.Star, Any}","page":"Propagation","title":"ModelVerification.Star_to_ImageStar","text":"Star_to_ImageStar(bound::Star, sz)\n\nConverts the Star bound to ImageStarBound bound.\n\nArguments\n\nbound (Star): The bound of the input node, represented using Star type.\nsz: The size of the input image, i.e., the target size.\n\nReturns\n\nThe bound represented using ImageStarBound type.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.fast_overapproximate-Union{Tuple{N}, Tuple{LazySets.Rectification{N, <:LazySets.AbstractZonotope}, Type{<:LazySets.Zonotope}}} where N","page":"Propagation","title":"ModelVerification.fast_overapproximate","text":"fast_overapproximate(r::Rectification{N,<:AbstractZonotope}, \n                     ::Type{<:Zonotope}) where {N}\n\nComputes the overapproximation of the rectified set r using a Zonotope.\n\nArguments\n\nr (Rectification): The rectified set.\n::Type{<:Zonotope}: The type of the overapproximation, default is    Zonotope.\n\nReturns\n\nThe overapproximation of the rectified set r using a Zonotope.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.partition_relu-Tuple{Any}","page":"Propagation","title":"ModelVerification.partition_relu","text":"partition_relu(bound)\n\nPartition the bound into multiple VPolytope objects, each of which is the  intersection of the bound and an orthant. The resulting VPolytope objects  are stored in an array. This is for ReLU propagations in ExactReach solver. Thus, the resulting VPolytope objects are the outputs of rectifying the input  bound. The dimension of the bound must be less than 30, since otherwise the  number of output sets will be too large.\n\nArguments\n\nbound: The bound of the input node.\n\nReturns\n\nAn array of partitioned bounds represented using VPolytope type.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_act-Tuple{Any, typeof(NNlib.relu), LazySets.Star, Any}","page":"Propagation","title":"ModelVerification.propagate_act","text":"propagate_act(prop_method, layer::typeof(relu), bound::Star, batch_info)\n\nPropagate the Star bound through a ReLU layer. I.e., it applies the ReLU  operation to the Star bound. The resulting bound is also of type Star. This  is for Star propagation methods.\n\nArguments\n\nprop_method: The propagation method used for the verification problem.\nlayer (typeof(relu)): The ReLU operation to be used for propagation.\nbound (Star): The bound of the input node, represented using Star type.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nthe relued bound of the output represented in Star type.\n\nReference\n\n[1] HD. Tran, S. Bak, W. Xiang, and T.T. Johnson, \"Verification of Deep Convolutional  Neural Networks Using ImageStars,\" in Computer Aided Verification (CAV), 2020.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_act-Tuple{Any, typeof(NNlib.relu), ModelVerification.ImageStarBound, Any}","page":"Propagation","title":"ModelVerification.propagate_act","text":"propagate_act(prop_method, layer::typeof(relu), \n              bound::ImageStarBound, batch_info)\n\nPropagate the ImageStarBound bound through a ReLU layer. I.e., it applies  the ReLU operation to the ImageStarBound bound. The resulting bound is also  of type ImageStarBound. This is for ImageStar propagation method. It  converts the input bound to Star type, calls propagate_act that propagates  the Star bound through a ReLU layer, and converts the resulting bound back to  ImageStarBound.\n\nArguments\n\nprop_method: The propagation method used for the verification problem.\nlayer (typeof(relu)): The ReLU operation to be used for propagation.\nbound (ImageStarBound): The bound of the input node, represented using    ImageStarBound type.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nThe relued bound of the output represented in ImageStarBound type.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_act-Tuple{Any, typeof(NNlib.relu), ModelVerification.ImageZonoBound, Any}","page":"Propagation","title":"ModelVerification.propagate_act","text":"propagate_act(prop_method, layer::typeof(relu), \n              bound::ImageZonoBound, batch_info)\n\nPropagate the ImageZonoBound bound through a ReLU layer. I.e., it applies  the ReLU operation to the ImageZonoBound bound. The resulting bound is also  of type ImageZonoBound. This is for ImageZono propagation method. It  flattens the input bound into a Zonotope and calls fast_overapproximate that  computes the overapproximation of the rectified set using a Zonotope. It then  converts the resulting Zonotope back to ImageZonoBound.\n\nArguments\n\nprop_method: The propagation method used for the verification problem.\nlayer (typeof(relu)): The ReLU operation to be used for propagation.\nbound (ImageZonoBound): The bound of the input node, represented using    ImageZonoBound type.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nthe relued bound of the output represented in ImageZonoBound type.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_act-Tuple{Box, typeof(NNlib.relu), LazySets.AbstractPolytope, Any}","page":"Propagation","title":"ModelVerification.propagate_act","text":"propagate_act(prop_method::Box, layer::typeof(relu), \n              reach::AbstractPolytope, batch_info)\n\nPropagate the AbstractPolytope bound through a ReLU layer. I.e., it applies  the ReLU operation to the AbstractPolytope bound. The resulting bound is also  of type AbstractPolytope. This is for Ai2's Box propagation method. It calls  rectify that rectifies the input bound.\n\nArguments\n\nprop_method (Box): The propagation method used for the verification    problem.\nlayer (typeof(relu)): The ReLU operation to be used for propagation.\nreach (AbstractPolytope): The bound of the input node.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nthe relued bound of the output represented in AbstractPolytope type.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_act-Tuple{ExactReach, typeof(NNlib.relu), ModelVerification.ExactReachBound, Any}","page":"Propagation","title":"ModelVerification.propagate_act","text":"propagate_act(prop_method::ExactReach, layer::typeof(relu), \n              reach::ExactReachBound, batch_info)\n\nPropagate the ExactReachBound bound through a ReLU layer. I.e., it applies  the ReLU operation to the ExactReachBound bound. The resulting bound is also  of type ExactReachBound. This is for ExactReach propagation method. It calls partition_relu that partitions the resulting rectified bound into  multiple VPolytope objects, each of which is the intersection of the resulting  bound and an orthant. The resulting VPolytope objects are vertically  concatenated and stored in an ExactReachBound object.\n\nArguments\n\nprop_method (ExactReach): The propagation method used for the verification    problem.\nlayer (typeof(relu)): The ReLU operation to be used for propagation.\nreach (ExactReachBound): The bound of the input node, represented using    ExactReachBound type.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nthe relued bound of the output represented in ExactReachBound type.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_act-Tuple{Union{ImageZono, Ai2z}, typeof(NNlib.relu), LazySets.AbstractPolytope, Any}","page":"Propagation","title":"ModelVerification.propagate_act","text":"propagate_act(prop_method::Union{Ai2z, ImageZono}, layer::typeof(relu), \n              reach::AbstractPolytope, batch_info)\n\nPropagate the AbstractPolytope bound through a ReLU layer. I.e., it applies  the ReLU operation to the AbstractPolytope bound. The resulting bound is also of type AbstractPolytope. This is for either Ai2z or ImageZono propagation  methods, which both use Zonotope-like representation for the safety  specifications. After rectifying the input bound, it overapproximates the  resulting bound using a Zonotope.\n\nArguments\n\nprop_method (Union{Ai2z, ImageZono}): The propagation method used for the    verification problem. It can be either Ai2z or ImageZono, which both use    Zonotope-like representation for the safety specifications.\nlayer (typeof(relu)): The ReLU operation to be used for propagation.\nreach (AbstractPolytope): The bound of the input node.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nthe relued bound of the output represented in Zonotope type.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_act_batch-Tuple{Crown, typeof(NNlib.relu), ModelVerification.CrownBound, Any}","page":"Propagation","title":"ModelVerification.propagate_act_batch","text":"propagate_act_batch(prop_method::Crown, layer::typeof(relu), \n                    bound::CrownBound, batch_info)\n\nPropagate the CrownBound bound through a ReLU layer. I.e., it applies the ReLU operation to the CrownBound bound. The resulting bound is also of type  CrownBound. This is for Crown propagation method. It calls compute_bound  that computes the lower- and upper-bounds of the input bound. It then computes \n\n\n\n\n\n","category":"method"},{"location":"propagate/#Stateless","page":"Propagation","title":"Stateless","text":"","category":"section"},{"location":"propagate/","page":"Propagation","title":"Propagation","text":"Modules=[ModelVerification]\nPages=[\"stateless.jl\"]","category":"page"},{"location":"propagate/#ModelVerification.propagate_linear-Tuple{Any, Flux.MeanPool, ModelVerification.ImageStarBound, Any}","page":"Propagation","title":"ModelVerification.propagate_linear","text":"propagate_linear(prop_method, layer::MeanPool, \n                 bound::ImageStarBound, batch_info)\n\nPropagate the ImageStarBound bound through a mean pool layer. I.e., it applies the mean pool operation to the ImageStarBound bound. The resulting bound is  also of type ImageStarBound.\n\nArguments\n\nprop_method: The propagation method used for the verification problem.\nlayer (MeanPool): The mean pool operation to be used for propagation.\nbound (ImageStarBound): The bound of the input node.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nThe mean pooled bound of the output layer represented in ImageStarBound    type.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_linear-Tuple{Any, Flux.MeanPool, ModelVerification.ImageZonoBound, Any}","page":"Propagation","title":"ModelVerification.propagate_linear","text":"propagate_linear(prop_method, layer::MeanPool, \n                 bound::ImageZonoBound, batch_info)\n\nPropagate the ImageZonoBound bound through a mean pool layer. I.e., it applies the mean pool operation to the ImageZonoBound bound. The resulting bound is  also of type ImageZonoBound.\n\nArguments\n\nprop_method: The propagation method used for the verification problem.\nlayer (MeanPool): The mean pool operation to be used for propagation.\nbound (ImageZonoBound): The bound of the input node.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nThe mean pooled bound of the output layer represented in ImageZonoBound    type.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_linear-Tuple{Any, typeof(Flux.flatten), ModelVerification.ImageStarBound, Any}","page":"Propagation","title":"ModelVerification.propagate_linear","text":"propagate_linear(prop_method, layer::typeof(flatten), \n                 bound::ImageStarBound, batch_info)\n\nPropagate the ImageStarBound bound through a flatten layer. I.e., it flattens  the ImageStarBound into a Star type.\n\nArguments\n\nprop_method: The propagation method used for the verification problem.\nlayer (typeof(flatten)): The layer operation to be used for propagation.\nbound (ImageStarBound): The bound of the input node.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nThe flattened bound of the output layer represented in Star type.\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_linear-Tuple{Any, typeof(Flux.flatten), ModelVerification.ImageZonoBound, Any}","page":"Propagation","title":"ModelVerification.propagate_linear","text":"propagate_linear(prop_method, layer::typeof(flatten), \n                 bound::ImageZonoBound, batch_info)\n\nPropagate the ImageZonoBound bound through a flatten layer. I.e., it flattens  the ImageZonoBound into a Zonotope type.\n\nArguments\n\nprop_method: The propagation method used for the verification problem.\nlayer (typeof(flatten)): The layer operation to be used for propagation.\nbound (ImageZonoBound): The bound of the input node.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nThe flattened bound of the output layer represented in Zonotope type.\n\n\n\n\n\n","category":"method"},{"location":"about/#About","page":"About","title":"About","text":"","category":"section"},{"location":"about/","page":"About","title":"About","text":"This toolbox is developed by the Intelligent Control Lab at the Robotics Institute at Carnegie Mellon University. It is an extension of the NeuralVerification.jl.","category":"page"},{"location":"about/#Credit","page":"About","title":"Credit","text":"","category":"section"},{"location":"about/#Developers","page":"About","title":"Developers","text":"","category":"section"},{"location":"about/","page":"About","title":"About","text":"Changliu Liu, Carnegie Mellon University\nTianhao Wei, Carnegie Mellon University","category":"page"},{"location":"about/#Contributors","page":"About","title":"Contributors","text":"","category":"section"},{"location":"about/","page":"About","title":"About","text":"Luca Marzari, Carnegie Mellon University\nKai Yun, Carnegie Mellon University","category":"page"},{"location":"about/#Acknowledgements","page":"About","title":"Acknowledgements","text":"","category":"section"},{"location":"solvers/","page":"Solvers","title":"Solvers","text":"CurrentModule = ModelVerification","category":"page"},{"location":"solvers/","page":"Solvers","title":"Solvers","text":"Pages=[\"solvers.md\"]\nDepth = 3","category":"page"},{"location":"solvers/#Solvers","page":"Solvers","title":"Solvers","text":"","category":"section"},{"location":"solvers/","page":"Solvers","title":"Solvers","text":"For most of the functions below, each solver has a unique dispatch defined.","category":"page"},{"location":"solvers/#Variations-of-propagation-methods","page":"Solvers","title":"Variations of propagation methods","text":"","category":"section"},{"location":"solvers/","page":"Solvers","title":"Solvers","text":"All the solvers are based on one of the following propagation methods.","category":"page"},{"location":"solvers/","page":"Solvers","title":"Solvers","text":"ForwardProp\nBackwardProp\nSequentialForwardProp\nSequentialBackwardProp\nBatchForwardProp\nBatchBackwardProp","category":"page"},{"location":"solvers/#ModelVerification.ForwardProp","page":"Solvers","title":"ModelVerification.ForwardProp","text":"ForwardProp <: PropMethod\n\nAbstract type representing solvers that use forward propagation.\n\n\n\n\n\n","category":"type"},{"location":"solvers/#ModelVerification.BackwardProp","page":"Solvers","title":"ModelVerification.BackwardProp","text":"BackwardProp <: PropMethod\n\nAbstract type representing solvers that use backward propagation.\n\n\n\n\n\n","category":"type"},{"location":"solvers/#ModelVerification.SequentialForwardProp","page":"Solvers","title":"ModelVerification.SequentialForwardProp","text":"SequentialForwardProp <: ForwardProp\n\n\n\n\n\n","category":"type"},{"location":"solvers/#ModelVerification.SequentialBackwardProp","page":"Solvers","title":"ModelVerification.SequentialBackwardProp","text":"SequentialBackwardProp <: ForwardProp\n\n\n\n\n\n","category":"type"},{"location":"solvers/#ModelVerification.BatchForwardProp","page":"Solvers","title":"ModelVerification.BatchForwardProp","text":"BatchForwardProp <: ForwardProp\n\n\n\n\n\n","category":"type"},{"location":"solvers/#ModelVerification.BatchBackwardProp","page":"Solvers","title":"ModelVerification.BatchBackwardProp","text":"BatchBackwardProp <: BackwardProp\n\n\n\n\n\n","category":"type"},{"location":"solvers/#Bound-types","page":"Solvers","title":"Bound types","text":"","category":"section"},{"location":"solvers/","page":"Solvers","title":"Solvers","text":"The bounds are based on the following abstract type Bound.","category":"page"},{"location":"solvers/","page":"Solvers","title":"Solvers","text":"Bound","category":"page"},{"location":"solvers/#ModelVerification.Bound","page":"Solvers","title":"ModelVerification.Bound","text":"Bound\n\nAbstract type representing bounds.\n\n\n\n\n\n","category":"type"},{"location":"solvers/#Preprocessing-for-the-solver","page":"Solvers","title":"Preprocessing for the solver","text":"","category":"section"},{"location":"solvers/","page":"Solvers","title":"Solvers","text":"prepare_method is the first step called in search_branches. It initializes the bounds of the start node of the computational graph based on the given branch and the geometric representation used by the solver, which is specified with the prop_method. For each solver, there is a unique prepare_method defined. For more information, refer to the documentation for each solver.","category":"page"},{"location":"solvers/","page":"Solvers","title":"Solvers","text":"prepare_method(prop_method::PropMethod, batch_input::AbstractVector, batch_output::AbstractVector, model_info)","category":"page"},{"location":"solvers/#ModelVerification.prepare_method-Tuple{PropMethod, AbstractVector, AbstractVector, Any}","page":"Solvers","title":"ModelVerification.prepare_method","text":"prepare_method(prop_method::PropMethod, batch_input::AbstractVector, batch_output::AbstractVector, model_info)\n\nInitialize the bound of the start node of the computational graph based on the  solver (prop_method).\n\nAgruments\n\nprop_method (PropMethod): Propagation method, i.e., the solver.\nbatch_input (AbstractVector): Batch of inputs.\nbatch_output (AbstractVector): Batch of outputs.\nmodel_info: Structure containing the information of the neural network to   be verified.\n\nReturns\n\nbatch_output: Batch of outputs.\nbatch_info: Dictionary containing information of each node in the model.\n\n\n\n\n\n","category":"method"},{"location":"solvers/","page":"Solvers","title":"Solvers","text":"The following functions are used to retrieve information regarding each node in the model.","category":"page"},{"location":"solvers/","page":"Solvers","title":"Solvers","text":"init_propagation(prop_method::ForwardProp, batch_input, batch_output, model_info)\ninit_propagation(prop_method::BackwardProp, batch_input, batch_output, model_info)","category":"page"},{"location":"solvers/#ModelVerification.init_propagation-Tuple{ModelVerification.ForwardProp, Any, Any, Any}","page":"Solvers","title":"ModelVerification.init_propagation","text":"init_propagation(prop_method::ForwardProp, batch_input, batch_output, model_info)\n\nReturns a dictionary containing the information of each node in the model. This  function is for ForwardProp solvers, and is mainly concerned with initializing  the dictionary, batch_info, and populating it with the initial bounds for the  starting node. For the starting node of the model, the :bound key is mapped  to the list of input specifications.\n\nArguments\n\nprop_method (ForwardProp): Solver that uses forward propagation.\nbatch_input: List of inputs.\nbatch_output: List of outputs.\nmodel_info: Structure containing the information of the neural network to    be verified.\n\nReturns\n\nbatch_info: Dictionary containing information of each node in the model.\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.init_propagation-Tuple{ModelVerification.BackwardProp, Any, Any, Any}","page":"Solvers","title":"ModelVerification.init_propagation","text":"init_propagation(prop_method::BackwardProp, batch_input, batch_output, model_info)\n\nReturns a dictionary containing the information of each node in the model. This  function is for BackwardProp solvers, and is mainly concerned with  initializing the dictionary, batch_info, and populating it with the initial  bounds for the starting node. For the starting node of the model, the :bound  key is mapped to the list of input specifications.\n\nArguments\n\nprop_method (BackwardProp): Solver that uses backward propagation.\nbatch_input: List of inputs.\nbatch_output: List of outputs.\nmodel_info: Structure containing the information of the neural network to    be verified.\n\nReturns\n\nbatch_info: Dictionary containing information of each node in the model.\n\n\n\n\n\n","category":"method"},{"location":"solvers/","page":"Solvers","title":"Solvers","text":"The following functions are used to either retrieve or process the safety specification.","category":"page"},{"location":"solvers/","page":"Solvers","title":"Solvers","text":"init_batch_bound(prop_method::ForwardProp, batch_input, batch_output)\ninit_batch_bound(prop_method::BackwardProp, batch_input, batch_output)\ninit_bound(prop_method::ForwardProp, input)\ninit_bound(prop_method::BackwardProp, output)\nprocess_bound","category":"page"},{"location":"solvers/#ModelVerification.init_batch_bound-Tuple{ModelVerification.ForwardProp, Any, Any}","page":"Solvers","title":"ModelVerification.init_batch_bound","text":"init_batch_bound(prop_method::ForwardProp, batch_input, batch_output)\n\nReturns a list of the input specifications (geometries) for the given batch of  inputs. This is for ForwardProp solvers. Each input specification is  processed to fit the geometric representation used by the solver.\n\nArguments\n\nprop_method (ForwardProp): Solver that uses forward propagation method.\nbatch_input: Array of inputs.\nbatch_output: Array of outputs.\n\nReturns\n\nList of the input specifications for the given batch of inputs.\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.init_batch_bound-Tuple{ModelVerification.BackwardProp, Any, Any}","page":"Solvers","title":"ModelVerification.init_batch_bound","text":"init_batch_bound(prop_method::BackwardProp, batch_input, batch_output)\n\nReturns a list of the output specifications (geometries) for the given batch of  outputs. This is for BackwardProp solvers. Each input specification is  processed to fit the geometric representation used by the solver.\n\nArguments\n\nprop_method (BackwardProp): Solver that uses backward propagation method.\nbatch_input: Array of inputs.\nbatch_output: Array of outputs.\n\nReturns\n\nList of the output specifications for the given batch of outputs.\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.init_bound-Tuple{ModelVerification.ForwardProp, Any}","page":"Solvers","title":"ModelVerification.init_bound","text":"init_bound(prop_method::ForwardProp, input)\n\nReturns the geometry representation used to encode the input specification. This is for ForwardProp solvers. \n\nArguments\n\nprop_method (ForwardProp): Solver that uses forward propagation method. \ninput: Geometry representation used to encode the input specification.\n\nReturns\n\ninput: Geometry representation used to encode the input specification.\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.init_bound-Tuple{ModelVerification.BackwardProp, Any}","page":"Solvers","title":"ModelVerification.init_bound","text":"init_bound(prop_method::BackwardProp, output)\n\nReturns the geometry representation used to encode the output specification.  This is for BackwardProp solvers.\n\nArguments\n\nprop_method (BackwardProp): Solver that uses backward propagation method. \noutput: Geometry representation used to encode the output specification.\n\nReturns\n\noutput: Geometry representation used to encode the output specification.\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.process_bound","page":"Solvers","title":"ModelVerification.process_bound","text":"process_bound(prop_method::PropMethod, batch_bound, batch_out_spec, model_info, batch_info)\n\nReturns the list of bounds resulting from the propagation and the information of the batch.\n\nArguments\n\nprop_method (PropMethod): Solver.\nbatch_bound: List of the bounds for the given batch.\nbatch_out_spec: List of the output specifications for the given batch of    outputs.\nmodel_info: Structure containing the information of the neural network to be    verified.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nbatch_bound: List of the bounds for the given batch.\nbatch_info: Dictionary containing information of each node in the model.\n\n\n\n\n\nprocess_bound(prop_method::BetaCrown, batch_bound::BetaCrownBound, batch_out_spec, model_info, batch_info)\n\n\n\n\n\n","category":"function"},{"location":"solvers/#Checking-inclusion","page":"Solvers","title":"Checking inclusion","text":"","category":"section"},{"location":"solvers/","page":"Solvers","title":"Solvers","text":"check_inclusion(prop_method::ForwardProp, model, batch_input::AbstractArray, batch_reach::AbstractArray, batch_output::AbstractArray)","category":"page"},{"location":"solvers/#ModelVerification.check_inclusion-Tuple{ModelVerification.ForwardProp, Any, AbstractArray, AbstractArray, AbstractArray}","page":"Solvers","title":"ModelVerification.check_inclusion","text":"check_inclusion(prop_method::ForwardProp, model, batch_input::AbstractArray, batch_reach::AbstractArray, batch_output::AbstractArray)\n\nDetermines whether the reachable sets, batch_reach, are within the respective  valid output sets, batch_output.\n\nArguments\n\nprop_method (ForwardProp): Solver being used.\nmodel: Neural network model that is to be verified.\ninput (AbstractArray): List of input specifications.\nreach (AbstractArray): List of reachable sets.\noutput (AbstractArray) : List of sets of valid outputs.\n\nReturns\n\nList of a combination of the following components:\n\nReachabilityResult(:holds, [reach]) if reach is a subset of output.\nCounterExampleResult(:unknown) if reach is not a subset of output, but    cannot find a counterexample.\nCounterExampleResult(:violated, x) if reach is not a subset of output,    and there is a counterexample.\n\n\n\n\n\n","category":"method"},{"location":"solvers/#Ai2","page":"Solvers","title":"Ai2","text":"","category":"section"},{"location":"solvers/","page":"Solvers","title":"Solvers","text":"Ai2\nStarSet\nprepare_method(prop_method::StarSet, batch_input::AbstractVector, batch_output::AbstractVector, model_info)\ncompute_bound(bound::Zonotope)\ncompute_bound(bound::Star)\ninit_bound(prop_method::StarSet, input::Hyperrectangle) \ncheck_inclusion(prop_method::ForwardProp, model, input::LazySet, reach::LazySet, output::LazySet)\ncheck_inclusion(prop_method::ForwardProp, model, input::LazySet, reach::LazySet, output::Complement)","category":"page"},{"location":"solvers/#ModelVerification.Ai2","page":"Solvers","title":"ModelVerification.Ai2","text":"Ai2{T<:Union{Hyperrectangle, Zonotope, HPolytope, Star}} <: SequentialForwardProp\n\nAi2 performs over-approximated reachability analysis to compute the over- approximated output reachable set for a network. T can be Hyperrectangle,  Zonotope, Star, or HPolytope. Different geometric representations impact the verification performance due to different over-approximation sizes.  We use Zonotope as \"benchmark\" geometry, as in the original implementation[1],  due to improved scalability and precision (similar results can be achieved using  Star). On the other hand, using a HPolytope representation potentially  leads to a more precise but less scalable result, and the opposite holds for  Hyperrectangle.\n\nNote that initializing Ai2() defaults to Ai2{Zonotope}. The following aliases also exist for convenience:\n\nconst Ai2h = Ai2{HPolytope}\nconst Ai2z = Ai2{Zonotope}\nconst Ai2s = Ai2{Star}\nconst Box = Ai2{Hyperrectangle}\n\nReference\n\n[1] T. Gehr, M. Mirman, D. Drashsler-Cohen, P. Tsankov, S. Chaudhuri, and  M. Vechev, \"Ai2: Safety and Robustness Certification of Neural Networks with  Abstract Interpretation,\" in 2018 IEEE Symposium on Security and Privacy (SP), \n\n\n\n\n\n\n\n","category":"type"},{"location":"solvers/#ModelVerification.StarSet","page":"Solvers","title":"ModelVerification.StarSet","text":"StarSet\n\nCovers supported Ai2 variations: Ai2h, Ai2z, Ai2s, Box.\n\nFields\n\npre_bound_method (Union{SequentialForwardProp, Nothing}): The geometric    representation used to compute the over-approximation of the input bounds.\n\n\n\n\n\n","category":"type"},{"location":"solvers/#ModelVerification.prepare_method-Tuple{StarSet, AbstractVector, AbstractVector, Any}","page":"Solvers","title":"ModelVerification.prepare_method","text":"prepare_method(prop_method::StarSet, batch_input::AbstractVector, \nbatch_output::AbstractVector, model_info)\n\nInitialize the bound of the start node of the computational graph for the  StarSet solvers.\n\nArguments\n\nprop_method (StarSet) : Propagation method of type StarSet.\nbatch_input (AbstractVector) : Batch of inputs.\nbatch_output (AbstractVector) : Batch of outputs.\nmodel_info: Structure containing the information of the neural network to   be verified.\n\nReturns\n\nbatch_output: batch of outputs.\nbatch_info:\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.compute_bound-Tuple{LazySets.Zonotope}","page":"Solvers","title":"ModelVerification.compute_bound","text":"compute_bound(bound::Zonotope)\n\nComputes the lower- and upper-bounds of a zonotope.  This function is used when propagating through the layers of the model. Radius is the sum of the absolute value of the generators of the given zonotope.\n\nArguments\n\nbound (Zonotope) : zonotope of which the bounds need to be computed\n\nReturns\n\nLower- and upper-bounds of the Zonotope.\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.compute_bound-Tuple{LazySets.Star}","page":"Solvers","title":"ModelVerification.compute_bound","text":"compute_bound(bound::Star)\n\nComputes the lower- and upper-bounds of a star set.  This function is used when propagating through the layers of the model. It overapproximates the given star set with a hyperrectangle.\n\nArguments\n\nbound (Star): Star set of which the bounds need to be computed.\n\nReturns\n\nLower- and upper-bounds of the overapproximated hyperrectangle.\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.init_bound-Tuple{StarSet, LazySets.Hyperrectangle}","page":"Solvers","title":"ModelVerification.init_bound","text":"init_bound(prop_method::StarSet, input::Hyperrectangle)\n\nGiven a hyperrectangle as input, this function returns a star set that  encompasses the hyperrectangle. This helps a more precise computation of bounds.\n\nArguments\n\nprop_method (StarSet): StarSet-type solver; includes Ai2h, Ai2z,    Ai2s, Box.\ninput (Hyperrectangle): Hyperrectangle to be converted into a star set\n\nReturns\n\nStar set that encompasses the given hyperrectangle.\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.check_inclusion-Tuple{ModelVerification.ForwardProp, Any, LazySets.LazySet, LazySets.LazySet, LazySets.LazySet}","page":"Solvers","title":"ModelVerification.check_inclusion","text":"check_inclusion(prop_method::ForwardProp, model, input::LazySet, \nreach::LazySet, output::LazySet)\n\nDetermines whether the reachable set, reach, is within the valid  output specified by a LazySet. This function achieves this by directly  checking if the reachable set reach is a subset of the set of valid outputs  output. If not, it attempts to find a counterexample and returns the  appropriate Result.\n\nArguments\n\nprop_method (ForwardProp): Solver being used.\nmodel: Neural network model that is to be verified.\ninput (LazySet): Input specification supported by LazySet.\nreach (LazySet): Reachable set resulting from the propagation of input    through the model.\noutput (LazySet) : Set of valid outputs represented with a LazySet.\n\nReturns\n\nReachabilityResult(:holds, [reach]) if reach is a subset of output.\nCounterExampleResult(:unknown) if reach is not a subset of output, but    cannot find a counterexample.\nCounterExampleResult(:violated, x) if reach is not a subset of output,    and there is a counterexample.\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.check_inclusion-Tuple{ModelVerification.ForwardProp, Any, LazySets.LazySet, LazySets.LazySet, LazySets.Complement}","page":"Solvers","title":"ModelVerification.check_inclusion","text":"check_inclusion(prop_method::ForwardProp, model, input::LazySet, \nreach::LazySet, output::Complement)\n\nDetermines whether the reachable set, R(input, model), is within the valid  output specified by a LazySet. This function achieves this by checking if the box approximation (overapproximation with hyperrectangle) of the reach set is disjoint with the unsafe_output. If the box approximation is a subset of the  unsafe_output, then the safety property is violated. \n\nArguments\n\nprop_method (ForwardProp): Solver being used.\nmodel: Neural network model that is to be verified.\ninput (LazySet): Input specification supported by Lazyset.\nreach (LazySet): Reachable set resulting from the propagation of input    through the model.\noutput (Complement): Set of valid outputs represented with a complement    set. For problems using this check_inclusion method, the unsafe region is    specified. Then, the complement of the unsafe region is given as the desired    output specification.\n\nReturns\n\nReachabilityResult(:holds, [reach]) if box_reach is disjoint with the   complement of the output.\nCounterExampleResult(:violated, x) if the center of the input set results    in a state that belongs to the unsafe_output.\nCounterExampleResult(:unknown) if either the two cases above are true.\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ImageStar","page":"Solvers","title":"ImageStar","text":"","category":"section"},{"location":"solvers/","page":"Solvers","title":"Solvers","text":"ImageStar\nImageStarBound\nprepare_problem(search_method::SearchMethod, split_method::SplitMethod, prop_method::ImageStar, problem::Problem)\nprepare_method(prop_method::ImageStar, batch_input::AbstractVector, batch_output::AbstractVector, model_info)\ninit_bound(prop_method::ImageStar, ch::ImageConvexHull) \nassert_zono_star(bound::ImageStarBound)\ncompute_bound(bound::ImageStarBound)\ncenter(bound::ImageStarBound)\ncheck_inclusion(prop_method::ImageStar, model, input::ImageStarBound, reach::LazySet, output::LazySet)","category":"page"},{"location":"solvers/#ModelVerification.ImageStar","page":"Solvers","title":"ModelVerification.ImageStar","text":"ImageStar <: SequentialForwardProp\n\nImageStar is a verification approach that can verify the robustness of  Convolutional Neural Network (CNN). This toolbox uses the term, ImageStar, as  the verification method itself that uses the ImageStar set. In terms of  geometric representation, an ImageStar is an extension of the generalized star set such that the center and generators are images with multiple channels.\n\nΘ =  x  x = c + _i=1^m (α_i v_i)  Cα  d \n\nwhere c is the center image, V =  v_1  v_m  is the set of generator images, and Cα  d represent the predicate with α's as the free  parameters. This set representation enables efficient over-approximative  analysis of CNNs. ImageStar is less conservative and faster than ImageZono [1].\n\nNote that initializing ImageStar() defaults to ImageStar(nothing).\n\nFields\n\npre_bound_method (Union{SequentialForwardProp, Nothing}): The geometric    representation used to compute the over-approximation of the input bounds.\n\nReference\n\n[1] HD. Tran, S. Bak, W. Xiang, and T.T. Johnson, \"Verification of Deep Convolutional  Neural Networks Using ImageStars,\" in Computer Aided Verification (CAV), 2020.\n\n\n\n\n\n","category":"type"},{"location":"solvers/#ModelVerification.ImageStarBound","page":"Solvers","title":"ModelVerification.ImageStarBound","text":"ImageStarBound{T<:Real} <: Bound\n\nImageStarBound is used to represent the bounded set for ImageStar.  It is an extension of the geometric representation, StarSet.\n\nFields\n\ncenter (AbstractArray{T, 4}): center image (\"anchor\" image in literature),    of size heigth x width x number of channels x 1.\ngenerators (AbstractArray{T, 4}): matrix of generator images, of size   height x width x number of channels x number of generators.\nA (AbstractArray{T, 2}): normal direction of the predicate, of size    number of constraints x number of generators.\nb (AbstractArray{T, 1}): constraints of the predicate, of size    number of constraints x number of generators.\n\n\n\n\n\n","category":"type"},{"location":"solvers/#ModelVerification.prepare_problem-Tuple{SearchMethod, SplitMethod, ImageStar, Problem}","page":"Solvers","title":"ModelVerification.prepare_problem","text":"prepare_problem(search_method::SearchMethod, split_method::SplitMethod, \n                prop_method::ImageStar, problem::Problem)\n\nPreprocessing of the Problem to be solved. This method converts the model to a  bounded computational graph, makes the input specification compatible with the  solver, and returns the model information and preprocessed Problem. This in  turn also initializes the branch bank.\n\nArguments\n\nsearch_method (SearchMethod): Method to search the branches.\nsplit_method (SplitMethod): Method to split the branches.\nprop_method (ImageStar): Solver to be used, specifically the ImageStar.\nproblem (Problem): Problem to be preprocessed to better fit the solver.\n\nReturns\n\nmodel_info, a structure containing the information of the neural network to    be verified.\nProblem after processing the initial input specification and model.\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.prepare_method-Tuple{ImageStar, AbstractVector, AbstractVector, Any}","page":"Solvers","title":"ModelVerification.prepare_method","text":"prepare_method(prop_method::ImageStar, batch_input::AbstractVector,\n               batch_output::AbstractVector, model_info)\n\nInitialize the bound of the start node of the computational graph based on the  pre_bound_method specified in the given ImageStar solver.\n\nAgruments\n\nprop_method (ImageStar): ImageStar solver.\nbatch_input (AbstractVector): Batch of inputs.\nbatch_output (AbstractVector): Batch of outputs.\nmodel_info: Structure containing the information of the neural network to   be verified.\n\nReturns\n\nbatch_output: Batch of outputs.\nbatch_info: Dictionary containing information of each node in the model.\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.init_bound-Tuple{ImageStar, ImageConvexHull}","page":"Solvers","title":"ModelVerification.init_bound","text":"init_bound(prop_method::ImageStar, ch::ImageConvexHull)\n\nFor the ImageStar solver, this function converts the input set, represented  with an ImageConvexHull, to an ImageStarBound representation. This serves as  a preprocessing step for the ImageStar solver. \n\nArguments\n\nprop_method (ImageStar): ImageStar solver.\nch (ImageConvexHull): Convex hull, type ImageConvexHull, is used for the    input specification.\n\nReturns\n\nImageStarBound set that encompasses the given ImageConvexHull.\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.assert_zono_star-Tuple{ModelVerification.ImageStarBound}","page":"Solvers","title":"ModelVerification.assert_zono_star","text":"assert_zono_star(bound::ImageStarBound)\n\nAsserts whether the given ImageStarBound set is a Zonotope. This is done by checking whether the free parameter belongs to a unit hypercube.\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.compute_bound-Tuple{ModelVerification.ImageStarBound}","page":"Solvers","title":"ModelVerification.compute_bound","text":"compute_bound(bound::ImageStarBound)\n\nComputes the lower- and upper-bounds of an image star set. This function is used when propagating through the layers of the model. It converts the image star set to a star set. Then, it overapproximates this  star set with a hyperrectangle.\n\nArguments\n\nbound (ImageStarBound): Image star set of which the bounds need to be    computed.\n\nReturns\n\nLower- and upper-bounds of the overapproximated hyperrectangle.\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.center-Tuple{ModelVerification.ImageStarBound}","page":"Solvers","title":"ModelVerification.center","text":"center(bound::ImageStarBound)\n\nReturns the center image of the ImageStarBound bound.\n\nArguments\n\nbound (ImageStarBound): Geometric representation of the specification    using ImageStarBound.\n\nReturns\n\nImageStarBound.center image of type AbstractArray{T, 4}.\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.check_inclusion-Tuple{ImageStar, Any, ModelVerification.ImageStarBound, LazySets.LazySet, LazySets.LazySet}","page":"Solvers","title":"ModelVerification.check_inclusion","text":"check_inclusion(prop_method::ImageStar, model, input::ImageStarBound, \n                reach::LazySet, output::LazySet)\n\nDetermines whether the reachable set, reach, is within the valid output  specified by a LazySet. \n\nAgruments\n\nprop_method (ImageStar): Solver being used.\nmodel: Neural network model that is to be verified.\ninput (ImageStarBound): Input specification supported by ImageStarBound.\nreach (LazySet): Reachable set resulting from the propagation of input    through the model.\noutput (LazySet) : Set of valid outputs represented with a LazySet.\n\nReturns\n\nReachabilityResult(:holds, box_reach) if reach is a subset of output,    the function returns :holds with the box approximation (overapproximation    with hyperrectangle) of the reach set.\nCounterExampleResult(:unknown) if reach is not a subset of output, but    cannot find a counterexample.\nCounterExampleResult(:violated, x) if reach is not a subset of output,    and there is a counterexample.\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ImageZono","page":"Solvers","title":"ImageZono","text":"","category":"section"},{"location":"solvers/","page":"Solvers","title":"Solvers","text":"ImageZono\nImageZonoBound\nprepare_problem(search_method::SearchMethod, split_method::SplitMethod, prop_method::ImageZono, problem::Problem)\ninit_bound(prop_method::ImageZono, ch::ImageConvexHull) \ninit_bound(prop_method::ImageZono, bound::ImageStarBound)\ncompute_bound(bound::ImageZonoBound)\ncenter(bound::ImageZonoBound)\ncheck_inclusion(prop_method::ImageZono, model, input::ImageZonoBound, reach::LazySet, output::LazySet)","category":"page"},{"location":"solvers/#ModelVerification.ImageZono","page":"Solvers","title":"ModelVerification.ImageZono","text":"ImageZono <: SequentialForwardProp\n\nImageZono is a verification approach that uses Image Zonotope as the geometric  representation. It is an extension of ImageStar where there is no linear  constraints on the free parameters, α:\n\nΘ =  x  x = c + _i=1^m (α_i v_i) \n\nwhere c is the center image, V =  v_1  v_m  is the set of generator images, and α's are the free parameters.\n\n\n\n\n\n","category":"type"},{"location":"solvers/#ModelVerification.ImageZonoBound","page":"Solvers","title":"ModelVerification.ImageZonoBound","text":"ImageZonoBound{T<:Real} <: Bound\n\nImageZonoBound is used to represent the bounded set for ImageZono.\n\nFields\n\ncenter (AbstractArray{T, 4}): center image (\"anchor\" image in literature),    of size heigth x width x number of channels x 1.\ngenerators (AbstractArray{T, 4}): matrix of generator images, of size   height x width x number of channels x number of generators.\n\n\n\n\n\n","category":"type"},{"location":"solvers/#ModelVerification.prepare_problem-Tuple{SearchMethod, SplitMethod, ImageZono, Problem}","page":"Solvers","title":"ModelVerification.prepare_problem","text":"prepare_problem(search_method::SearchMethod, split_method::SplitMethod, \n                prop_method::ImageZono, problem::Problem)\n\nConverts the model to a bounded computational graph and makes input  specification compatible with the solver, prop_method. This in turn also  initializes the branch bank.\n\nArguments\n\nsearch_method (SearchMethod): Method to search the branches.\nsplit_method (SplitMethod): Method to split the branches.\nprop_method (ImageZono): Solver to be used, specifically the ImageZono.\nproblem (Problem): Problem to be preprocessed to better fit the solver.\n\nReturns\n\nmodel_info, a structure containing the information of the neural network to    be verified.\nProblem after processing the initial input specification and model.\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.init_bound-Tuple{ImageZono, ImageConvexHull}","page":"Solvers","title":"ModelVerification.init_bound","text":"init_bound(prop_method::ImageZono, ch::ImageConvexHull)\n\nFor the ImageZono solver, this function converts the input set, represented  with an ImageConvexHull, to an ImageZonoBound representation. This serves as  a preprocessing step for the ImageZono solver. \n\nArguments\n\nprop_method (ImageZono): ImageZono solver.\nch (ImageConvexHull): Convex hull, type ImageConvexHull, is used as the    input specification.\n\nReturns\n\nImageZonoBound set that encompasses the given ImageConvexHull.\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.init_bound-Tuple{ImageZono, ModelVerification.ImageStarBound}","page":"Solvers","title":"ModelVerification.init_bound","text":"init_bound(prop_method::ImageZono, bound::ImageStarBound)\n\nFor the ImageZono solver, if the input set, represented with an  ImageStarBound, is a zonotope, this function converts it to an  ImageZonoBound representation.\n\nArguments\n\nprop_method (ImageZono): ImageZono solver.\nch (ImageStarBound): ImageStarBound is used for the input specification.\n\nReturns\n\nImageZonoBound representation.\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.compute_bound-Tuple{ModelVerification.ImageZonoBound}","page":"Solvers","title":"ModelVerification.compute_bound","text":"compute_bound(bound::ImageZonoBound)\n\nComputes the lower- and upper-bounds of an image zono set. This function is used when propagating through the layers of the model. It converts the image zono set to a zonotope. Then, it computes the bounds using  compute_bound(bound::Zonotope).\n\nArguments\n\nbound (ImageZonoBound): Image zono set of which the bounds need to be    computed.\n\nReturns\n\nLower- and upper-bounds of the flattened zonotope.\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.center-Tuple{ModelVerification.ImageZonoBound}","page":"Solvers","title":"ModelVerification.center","text":"center(bound::ImageZonoBound)\n\nReturns the center image of the ImageZonoBound bound.\n\nArguments\n\nbound (ImageZonoBound): Geometric representation of the specification    using ImageZonoBound.\n\nReturns\n\nImageZonoBound.center image of type AbstractArray{T, 4}.\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.check_inclusion-Tuple{ImageZono, Any, ModelVerification.ImageZonoBound, LazySets.LazySet, LazySets.LazySet}","page":"Solvers","title":"ModelVerification.check_inclusion","text":"check_inclusion(prop_method::ImageZono, model, input::ImageZonoBound, \n                reach::LazySet, output::LazySet)\n\nDetermines whether the reachable set, reach, is within the valid output  specified by a LazySet.\n\nAgruments\n\nprop_method (ImageZono): Solver being used.\nmodel: Neural network model that is to be verified.\ninput (ImageZonoBound): Input specification supported by ImageZonoBound.\nreach (LazySet): Reachable set resulting from the propagation of input    through the model.\noutput (LazySet) : Set of valid outputs represented with a LazySet.\n\nReturns\n\nReachabilityResult(:holds, box_reach) if reach is a subset of output,    the function returns :holds with the box approximation (overapproximation    with hyperrectangle) of the reach set.\nCounterExampleResult(:unknown) if reach is not a subset of output, but    cannot find a counterexample.\nCounterExampleResult(:violated, x) if reach is not a subset of output,    and there is a counterexample.\n\n\n\n\n\n","category":"method"},{"location":"solvers/#Crown","page":"Solvers","title":"Crown","text":"","category":"section"},{"location":"solvers/#\\alpha-Crown","page":"Solvers","title":"alpha-Crown","text":"","category":"section"},{"location":"solvers/#\\beta-Crown","page":"Solvers","title":"beta-Crown","text":"","category":"section"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"CurrentModule = ModelVerification","category":"page"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"Pages=[\"safety_spec.md\"]\nDepth=3","category":"page"},{"location":"safety_spec/#Input-Output-Specification","page":"Input-Output Specification","title":"Input-Output Specification","text":"","category":"section"},{"location":"safety_spec/#Safety-Property","page":"Input-Output Specification","title":"Safety Property","text":"","category":"section"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"A safety property is essentially an input-output relationship for the model we want to verify. In general, the constraints for the input set mathcalX and the output set mathcalY can have any geometry. For the sake of simplicity, ModelVerification.jl uses convex polytopes and the complement of a polytope to encode the input and output specifications. Specifically, our implementation utilizes the geometric definitions of LazySets, a Julia package for calculus with convex sets. The following section dives into the geometric representations ModelVerification.jl uses and the representations required for each solver. ","category":"page"},{"location":"safety_spec/#Geometric-Representation","page":"Input-Output Specification","title":"Geometric Representation","text":"","category":"section"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"Different solvers implemented in ModelVerification.jl require the input-output specification formulated with particular geometries. We report here a brief overview of the sets we use. For specifics, please read Algorithms for Verifying Deep Neural Networks by C. Liu, et al.  and Sets in LazySets.jl.","category":"page"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"HR = Hyperrectangle\nHS = HalfSpace\nHP = HPolytope\nSS = StarSet\nZT = Zonotope\nIS = ImageStar\nIZ = ImageZono\nPC = PolytopeComplement","category":"page"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"Solver Input Set Output Set\nAi2 HR, ZT, HP, SS HP (bounded)\nCROWN HR HP (bounded)\nalpha-CROWN HR HP (bounded)\nbeta-CROWN HR HP (bounded)\nalpha-beta-CROWN HR HP (bounded)","category":"page"},{"location":"safety_spec/#Hyperrectangle-([Hyperrectangle](https://juliareach.github.io/LazySets.jl/dev/lib/sets/Hyperrectangle/#def_Hyperrectangle))","page":"Input-Output Specification","title":"Hyperrectangle (Hyperrectangle)","text":"","category":"section"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"Corresponds to a high-dimensional rectangle, defined by","category":"page"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"x-c le r","category":"page"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"where cinmathbbR^k_0 is the center of the hyperrectangle and rinmathbbR^k_0 is the radius of the hyperrectangle.","category":"page"},{"location":"safety_spec/#HalfSpace-([HalfSpace](https://juliareach.github.io/LazySets.jl/dev/lib/sets/HalfSpace/))","page":"Input-Output Specification","title":"HalfSpace (HalfSpace)","text":"","category":"section"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"Represented by a single linear inequality constraint","category":"page"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"a^top x le b","category":"page"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"where ainmathbbR^k_0 and binmathbbR.","category":"page"},{"location":"safety_spec/#Halfspace-Polytope-([HPolytope](https://juliareach.github.io/LazySets.jl/dev/lib/sets/HPolytope/#def_HPolytope))","page":"Input-Output Specification","title":"Halfspace-Polytope (HPolytope)","text":"","category":"section"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"HPolytope uses a set of linear inequality constraints to represent a convex polytope, i.e., it is a bounded set defined using an intersection of half-spaces.","category":"page"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"Ax le b","category":"page"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"where AinmathbbR^ktimes k_0 binmathbbR^k with k representing the number of inequality constraints.","category":"page"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"<center><img src=\"./assets/halfspace_polytope.png\" width=\"300\"/></center> <center>Polytope made of halfspaces.</center>","category":"page"},{"location":"safety_spec/#StarSet-([Star](https://juliareach.github.io/LazySets.jl/dev/lib/sets/Star/#def_Star))","page":"Input-Output Specification","title":"StarSet (Star)","text":"","category":"section"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"Only convex star set is considered in this toolbox. A convex star set is an affine transformation of an arbitrary convex polytope,","category":"page"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"x = c + beginbmatrix r_1  r_2  cdots  r_l endbmatrix alpha Calpha le d","category":"page"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"where cinmathbbR^k_0 is the center of the star set, r_iinmathbbR^k_0 iin1dotsl are generators of the star set, CinmathbbR^ktimes l, dinmathbbR^k, alphainmathbbR^l is the free parameter that belongs to a unit hypercube, and k is the number of inequality constraints on alpha. l is the degree of freedom of the star set.","category":"page"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"<center><img src=\"./assets/star_domaim.png\" width=\"300\"/></center> <center>The general starset, on the left, is not necessarily convex. We only consider convex starsets.</center>","category":"page"},{"location":"safety_spec/#Zonotope-([Zonotope](https://juliareach.github.io/LazySets.jl/dev/lib/sets/Zonotope/#def_Zonotope))","page":"Input-Output Specification","title":"Zonotope (Zonotope)","text":"","category":"section"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"Zonotope is basically as star set in which all predicate variables are in the range of -1 1. Zonotope represents polytopes that can be written as affine transformations of a unit hypercube, defined as","category":"page"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"x = c + beginbmatrix r_1  r_2  cdots  r_l endbmatrix alpha alpha le 1","category":"page"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"where cinmathbbR^k_0 is the center of the zonotope, r_iinmathbbR^k_0 iin1dotsl are generators of the zonotope, and alphainmathbbR^l is the free parameter that belongs to a unit hypercube. l is the degree of freedom of the zonotope.","category":"page"},{"location":"safety_spec/#ImageStar","page":"Input-Output Specification","title":"ImageStar","text":"","category":"section"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"ImageStar is an extension of the star set where the center and generators are images with multiple channels.","category":"page"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"x = c + beginbmatrix r_1  r_2  cdots  r_l endbmatrix alpha Calpha le d","category":"page"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"where cinmathbbR^htimes w times k_0 is the center image, r_iinmathbbR^h times w times k_0 iin1dotsl are the generator iamges, CinmathbbR^ktimes l, dinmathbbR^k, and hwk are the height, width, and number of channels (input dimension) of the images respectively. alphainmathbbR^l is the free parameter that belongs to a unit hypercube, and k is the number of inequality constraints on alpha. l is the degree of freedom of the star set.","category":"page"},{"location":"safety_spec/#ImageZono","page":"Input-Output Specification","title":"ImageZono","text":"","category":"section"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"ImageZono is an extension of the zonotope where the center and generators are images with multiple channels.","category":"page"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"x = c + beginbmatrix r_1  r_2  cdots  r_l endbmatrix alpha","category":"page"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"where cinmathbbR^htimes w times k_0 is the center image, r_iinmathbbR^h times w times k_0 iin1dotsl are the generator iamges, and hwk are the height, width, and number of channels (input dimension) of the images respectively. alphainmathbbR^l is the free parameter that belongs to a unit hypercube and l is the degree of freedom of the zonotope.","category":"page"},{"location":"safety_spec/#PolytopeComplement-([Complement](https://juliareach.github.io/LazySets.jl/stable/lib/lazy_operations/Complement/))","page":"Input-Output Specification","title":"PolytopeComplement (Complement)","text":"","category":"section"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"PolytopeComplement is a type that represents the complement of a polytope, that is the set","category":"page"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"Y = X^c =  yinmathbbR^n  y notin X ","category":"page"},{"location":"safety_spec/#References","page":"Input-Output Specification","title":"References","text":"","category":"section"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"[1] C. Liu, T. Arnon, C. Lazarus, C. Strong, C. Barret, and M. J. Kochenderfer, \"Algorithms for Verifying Deep Neural Networks,\" in Foundations and Trends in Optimization, 2021.","category":"page"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"[2] T. Gehr, M. Mirman, D. Drashsler-Cohen, P. Tsankov, S. Chaudhuri, and M. Vechev, \"Ai2: Safety and Robustness Certification of Neural Networks with Abstract Interpretation,\" in 2018 IEEE Symposium on Security and Privacy (SP), 2018.","category":"page"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"[3] M. Forets and C. Schilling, \"LazySets.jl: Scalable Symbolic-Numeric Set Computations,\" in Proceeds of the JuliaCon Conferences, 2021.","category":"page"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"[4] HD. Tran, S. Bak, W. Xiang, and T.T. Johnson, \"Verification of Deep Convolutional Neural Networks Using ImageStars,\" in Computer Aided Verification (CAV), 2020.","category":"page"},{"location":"safety_spec/#Spec","page":"Input-Output Specification","title":"Spec","text":"","category":"section"},{"location":"safety_spec/#Specifications","page":"Input-Output Specification","title":"Specifications","text":"","category":"section"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"Spec\nInputSpec\nOutputSpec","category":"page"},{"location":"safety_spec/#ModelVerification.Spec","page":"Input-Output Specification","title":"ModelVerification.Spec","text":"Spec\n\nAbstract super-type for input-output specifications.\n\n\n\n\n\n","category":"type"},{"location":"safety_spec/#ModelVerification.InputSpec","page":"Input-Output Specification","title":"ModelVerification.InputSpec","text":"InputSpec\n\nInput specification can be of any type supported by LazySet or ImageConvexHull.\n\n\n\n\n\n","category":"type"},{"location":"safety_spec/#ModelVerification.OutputSpec","page":"Input-Output Specification","title":"ModelVerification.OutputSpec","text":"OutputSpec\n\nOutput specification can be of any type supported by LazySet or LinearSpec.\n\n\n\n\n\n","category":"type"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"ImageConvexHull\nLinearSpec\nclassification_spec(n::Int64, target::Int64)","category":"page"},{"location":"safety_spec/#ModelVerification.ImageConvexHull","page":"Input-Output Specification","title":"ModelVerification.ImageConvexHull","text":"ImageConvexHull <: Spec\n\nConvex hull for images used to specify safety property for images.  It is the smallest convex polytope that contains all the images given in the imgs array.\n\nFields\n\nimgs (AbstractArray): List of images in AbstractArray. Image is    represented as a matrix of height x weight x channels.\n\n\n\n\n\n","category":"type"},{"location":"safety_spec/#ModelVerification.LinearSpec","page":"Input-Output Specification","title":"ModelVerification.LinearSpec","text":"LinearSpec <: Spec\n\nSafety specification defined as the set  x x = A x - b  0 .\n\nFields\n\nA (AbstractArray{Float64, 3}): Normal dierction of size    spec_dim x out_dim x batch_size.\nb (AbstractArray{Float64, 2}): Constraints of size    spec_dim x batch_size.\nis_complement (Bool): Boolean flag for whether this specification is a    complement or not.\n\n\n\n\n\n","category":"type"},{"location":"safety_spec/#ModelVerification.classification_spec-Tuple{Int64, Int64}","page":"Input-Output Specification","title":"ModelVerification.classification_spec","text":"classification_spec(n::Int64, target::Int64)\n\nGenerates an output specification constructed with a convex polyhedron,  HPolyhedron, for classification tasks. Given n-number of labels with  target as the correct label, the resulting polyhedron is the finite  intersection of halfspaces:\n\nP = bigcap_i=1^n H_i\n\nwhere H_i = x  a_i^T x leq 0   iin1n is a halfspace,  a_i is a row vector where the n-th element is 1.0, the target-th  element is -1.0, and the rest are 0's.\n\nArguments\n\nn (Int64): Number of labels.\ntarget (Int64): Target label.\n\nReturns\n\nHPolyhedron specified as above such that the output specification captures    the target label.\n\n\n\n\n\n","category":"method"},{"location":"safety_spec/#Functions","page":"Input-Output Specification","title":"Functions","text":"","category":"section"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"get_size(input_spec::LazySet)\nget_size(input_spec::ImageConvexHull)\nget_linear_spec(batch_out_set::AbstractVector)","category":"page"},{"location":"safety_spec/#ModelVerification.get_size-Tuple{LazySets.LazySet}","page":"Input-Output Specification","title":"ModelVerification.get_size","text":"get_size(input_spec::LazySet)\n\nGiven a LazySet, it determines the size.\n\n\n\n\n\n","category":"method"},{"location":"safety_spec/#ModelVerification.get_size-Tuple{ImageConvexHull}","page":"Input-Output Specification","title":"ModelVerification.get_size","text":"get_size(input_spec::ImageConvexHull)\n\nGiven an ImageConvexHull, it determines the size.\n\n\n\n\n\n","category":"method"},{"location":"safety_spec/#ModelVerification.get_linear_spec-Tuple{AbstractVector}","page":"Input-Output Specification","title":"ModelVerification.get_linear_spec","text":"get_linear_spec(batch_out_set::AbstractVector)\n\nRetrieves the linear specifications of the batch of output sets and returns a LinearSpec structure. \n\nArguments\n\nbatch_out_set (AbstractVector): Batch of output sets.\n\nReturns\n\nLinearSpec of the batch of output sets.\n\n\n\n\n\n","category":"method"},{"location":"utils/#Helper-Functions","page":"Helper Functions","title":"Helper Functions","text":"","category":"section"},{"location":"utils/#Flux-to-Network,-Network-to-Flux","page":"Helper Functions","title":"Flux-to-Network, Network-to-Flux","text":"","category":"section"},{"location":"utils/","page":"Helper Functions","title":"Helper Functions","text":"network(c::Chain) = Network([layer.(c.layers)...])","category":"page"},{"location":"utils/","page":"Helper Functions","title":"Helper Functions","text":"Converts Flux.Chain to a Network.","category":"page"},{"location":"utils/","page":"Helper Functions","title":"Helper Functions","text":"Flux.Chain(m::Network) = _flux(m)","category":"page"},{"location":"utils/","page":"Helper Functions","title":"Helper Functions","text":"Converts Network to a Flux.Chain.","category":"page"},{"location":"utils/#Testing-Functions","page":"Helper Functions","title":"Testing Functions","text":"","category":"section"},{"location":"utils/","page":"Helper Functions","title":"Helper Functions","text":"Modules=[ModelVerification]\nPages=[\"testing_utils.jl\"]","category":"page"},{"location":"nnet_converter/#NNet-Converter","page":"NNet Converter","title":"NNet Converter","text":"","category":"section"},{"location":"python_interface/#Python-Interface","page":"Python Interface","title":"Python Interface","text":"","category":"section"},{"location":"python_interface/","page":"Python Interface","title":"Python Interface","text":"PyJulia - for Luca","category":"page"},{"location":"problem/","page":"Problem Outline","title":"Problem Outline","text":"CurrentModule = ModelVerification","category":"page"},{"location":"problem/","page":"Problem Outline","title":"Problem Outline","text":"Pages=[\"problem.md\"]\nDepth = 3","category":"page"},{"location":"problem/#Problem-Outline","page":"Problem Outline","title":"Problem Outline","text":"","category":"section"},{"location":"problem/","page":"Problem Outline","title":"Problem Outline","text":"Verification checks if the input-output relationships of a function, specifically deep neural networks (DNN) mathcalF in this case, hold. For an input specification imposed by a set mathcalXsubseteq mathcalD_x, we would like to check if the corresponding output of the function is contained in an output specification imposed by a set mathcalYsubseteq mathcalD_y:","category":"page"},{"location":"problem/","page":"Problem Outline","title":"Problem Outline","text":"xinmathcalX Longrightarrow y = mathcalF(x) in mathcalY","category":"page"},{"location":"problem/","page":"Problem Outline","title":"Problem Outline","text":"Thus, a DNN-Verification problem consists of two main components:","category":"page"},{"location":"problem/","page":"Problem Outline","title":"Problem Outline","text":"model (DNN) : mathcalF\nsafety property (input-output specification) : mathcalX mathcalY.","category":"page"},{"location":"problem/","page":"Problem Outline","title":"Problem Outline","text":"(Image: )","category":"page"},{"location":"problem/","page":"Problem Outline","title":"Problem Outline","text":"Due to the nonlinear and nonconvex nature of DNNs, estimating the exact reachable set is impractical, although there are algorithms that allow us to do this such as ExactReach. Thus, we preform an over-approximation of the reachable set, called mathcalR. We check its containment in the desired reachable set mathcalY which if ture, we can assert that the safety property holds.","category":"page"},{"location":"problem/","page":"Problem Outline","title":"Problem Outline","text":"Once we instantiate ","category":"page"},{"location":"problem/","page":"Problem Outline","title":"Problem Outline","text":"Below, we give a brief overview of models (Network), safety property, and outputs (verification results).","category":"page"},{"location":"problem/#Network","page":"Problem Outline","title":"Network","text":"","category":"section"},{"location":"problem/","page":"Problem Outline","title":"Problem Outline","text":"Details on Network","category":"page"},{"location":"problem/#Safety-Property","page":"Problem Outline","title":"Safety Property","text":"","category":"section"},{"location":"problem/","page":"Problem Outline","title":"Problem Outline","text":"Details on Input-Output Specification","category":"page"},{"location":"problem/#Output-(Verification-Results)","page":"Problem Outline","title":"Output (Verification Results)","text":"","category":"section"},{"location":"problem/","page":"Problem Outline","title":"Problem Outline","text":"Output result Explanation\n[BasicResult::hold] The input-output constraint is always satisfied.\n[BasicResult::violated] The input-output constraint is violated, i.e., it exists a single point in the input constraint that violates the property.\n[BasicResult::timeout] Could not be determined if the property holds due to timeout in the computation.\n[CounterExampleResult] Like BasicResult, but also returns a counterexample if one is found (if status = :violated). The counterexample is a point in the input set that, after the NN, lies outside the output constraint set.\n[AdversarialResult] Like BasicResult, but also returns the maximum allowable disturbance in the input (if status = :violated).\n[ReachabilityResult] Like BasicResult, but also returns the output reachable set given the input constraint (if status = :violated).\n[EnumerationResult] Set of all the (un)safe regions in the safety property's domain.","category":"page"},{"location":"problem/","page":"Problem Outline","title":"Problem Outline","text":"(Image: )","category":"page"},{"location":"problem/#Problem","page":"Problem Outline","title":"Problem","text":"","category":"section"},{"location":"problem/","page":"Problem Outline","title":"Problem Outline","text":"Problem\nprepare_problem(search_method::SearchMethod, split_method::SplitMethod, prop_method::PropMethod, problem::Problem)","category":"page"},{"location":"problem/#ModelVerification.Problem","page":"Problem Outline","title":"ModelVerification.Problem","text":"Problem{P, Q}(network::Network, input::P, output::Q)\n\nProblem definition for neural verification. The verification problem consists of: for all  points in the input set, the corresponding output of the network must belong to the output set.\n\nThere are three ways to construct a Problem:\n\nProblem(path::String, model::Chain, input_data, output_data) if both the    .onnx model path and Flux_model are given.\nProblem(path::String, input_data, output_data) if only the .onnx model   path is given.\nProblem(model::Chain, input_data, output_data) if only the Flux_model is   given.\n\nFields\n\nnetwork : Network that can be constructed either using the path to an onnx   model or a Flux.Chain structure.\ninput : input specification defined using a LazySet.\noutput : output specification defined using a LazySet.\n\n\n\n\n\n","category":"type"},{"location":"problem/#ModelVerification.prepare_problem-Tuple{SearchMethod, SplitMethod, PropMethod, Problem}","page":"Problem Outline","title":"ModelVerification.prepare_problem","text":"prepare_problem(search_method::SearchMethod, split_method::SplitMethod, \n                prop_method::PropMethod, problem::Problem)\n\nConverts the given Problem into a form that is compatible with the verification process of the toolbox. In particular, it retrieves information about the ONNX  model to be verified and stores them into a Model. It returns the Problem  itself and the Model structure. \n\nArguments\n\nsearch_method (SearchMethod): Search method for the verification process.\nsplit_method (SplitMethod): Split method for the verification process.\nprop_method (PropMethod): Propagation method for the verification process.\nproblem (Problem): Problem definition for model verification.\n\nReturns\n\nmodel_info (Model): Information about the model to be verified.\nproblem (Problem): The given problem definition for model verification.\n\n\n\n\n\n","category":"method"},{"location":"problem/#Result","page":"Problem Outline","title":"Result","text":"","category":"section"},{"location":"problem/","page":"Problem Outline","title":"Problem Outline","text":"Result\nBasicResult\nCounterExampleResult\nAdversarialResult\nReachabilityResult","category":"page"},{"location":"problem/#ModelVerification.Result","page":"Problem Outline","title":"ModelVerification.Result","text":"Result\n\nSupertype of all result types.\n\nSee also: \n\nBasicResult \nCounterExampleResult\nAdversarialResult\nReachabilityResult\n\n\n\n\n\n","category":"type"},{"location":"problem/#ModelVerification.BasicResult","page":"Problem Outline","title":"ModelVerification.BasicResult","text":"BasicResult(status::Symbol)\n\nResult type that captures whether the input-output constraint is satisfied. Possible status values:\n\n:holds (io constraint is satisfied always)\n\n:violated (io constraint is violated)\n\n:unknown (could not be determined)\n\n\n\n\n\n","category":"type"},{"location":"problem/#ModelVerification.CounterExampleResult","page":"Problem Outline","title":"ModelVerification.CounterExampleResult","text":"CounterExampleResult(status, counter_example)\n\nLike BasicResult, but also returns a counter_example if one is found (if status = :violated). The counter_example is a point in the input set that, after the NN, lies outside the output set.\n\n\n\n\n\n","category":"type"},{"location":"problem/#ModelVerification.AdversarialResult","page":"Problem Outline","title":"ModelVerification.AdversarialResult","text":"AdversarialResult(status, max_disturbance)\n\nLike BasicResult, but also returns the maximum allowable disturbance in the input (if status = :violated).\n\n\n\n\n\n","category":"type"},{"location":"problem/#ModelVerification.ReachabilityResult","page":"Problem Outline","title":"ModelVerification.ReachabilityResult","text":"ReachabilityResult(status, reachable)\n\nLike BasicResult, but also returns the output reachable set given the input constraint (if status = :violated).\n\n\n\n\n\n","category":"type"},{"location":"attack/#Attacks","page":"Attacks","title":"Attacks","text":"","category":"section"},{"location":"attack/","page":"Attacks","title":"Attacks","text":"Modules=[ModelVerification]\nPages=[\"pgd.jl\"]","category":"page"},{"location":"attack/#ModelVerification.APGD-NTuple{4, Any}","page":"Attacks","title":"ModelVerification.APGD","text":"APGD(model, loss, x, y; ϵ = 10, step_size = 0.1, iters = 100, clamp_range = (0, 1))\n\nAuto Projected Gradient Descent (APGD) (https://arxiv.org/pdf/2003.01690.pdf)\n\nArguments:\n\nmodel: The model to base teh attack upon.\nloss: the loss function to use, assuming that it includes the prediction function   i.e. loss(x, y) = crossentropy(m(x), y)\nx: The input to be perturbed.\nstep_size: The ϵ value in the FGSM step.\nrho: PGD success rate threshold to reduce the step size.\na: momentum.\niters: The maximum number of iterations to run the algorithm for.\n\n\n\n\n\n","category":"method"},{"location":"attack/#ModelVerification.FGSM-Tuple{Any, Any, Any}","page":"Attacks","title":"ModelVerification.FGSM","text":"FGSM(model, loss, x, y; ϵ = 0.1, clamp_range = (0, 1))\n\nFast Gradient Sign Method (FGSM) is a method of creating adversarial examples by pushing the input in the direction of the gradient and bounded by the ε parameter.\n\nThis method was proposed by Goodfellow et al. 2014 (https://arxiv.org/abs/1412.6572)\n\nArguments:\n\nmodel: The model to base the attack upon.\nloss: The loss function to use. This assumes that the loss function includes   the predict function, i.e. loss(x, y) = crossentropy(model(x), y).\nx: The input to be perturbed by the FGSM algorithm.\nϵ: The amount of perturbation to apply.\n\n\n\n\n\n","category":"method"},{"location":"attack/#ModelVerification.PGD-NTuple{4, Any}","page":"Attacks","title":"ModelVerification.PGD","text":"PGD(model, loss, x, y; ϵ = 10, step_size = 0.1, iters = 100, clamp_range = (0, 1))\n\nProjected Gradient Descent (PGD) is an itrative variant of FGSM with a random point. For every step the FGSM algorithm moves the input in the direction of the gradient bounded in the l∞ norm. (https://arxiv.org/pdf/1706.06083.pdf)\n\nArguments:\n\nmodel: The model to base teh attack upon.\nloss: the loss function to use, assuming that it includes the prediction function   i.e. loss(x, y) = crossentropy(m(x), y)\nx: The input to be perturbed.\nstep_size: The ϵ value in the FGSM step.\niters: The maximum number of iterations to run the algorithm for.\n\n\n\n\n\n","category":"method"},{"location":"attack/#ModelVerification.attack-Tuple{Any, Any, Any}","page":"Attacks","title":"ModelVerification.attack","text":"attack(model, input, output; restart=100)\n\n\n\n\n\n","category":"method"},{"location":"attack/#ModelVerification.attack-Tuple{Any}","page":"Attacks","title":"ModelVerification.attack","text":"attack(problem; restart=100)\n\n\n\n\n\n","category":"method"},{"location":"attack/#ModelVerification.project-Tuple{Any, AbstractVector, LazySets.Hyperrectangle}","page":"Attacks","title":"ModelVerification.project","text":"project(x, dir::AbstractVector, set::Hyperrectangle)\n\n\n\n\n\n","category":"method"},{"location":"attack/#ModelVerification.project-Tuple{Any, AbstractVector, LazySets.LazySet}","page":"Attacks","title":"ModelVerification.project","text":"project(x, dir::AbstractVector, set::LazySet)\n\n\n\n\n\n","category":"method"},{"location":"attack/#ModelVerification.project-Tuple{Any, LazySets.Hyperrectangle}","page":"Attacks","title":"ModelVerification.project","text":"project(p, rect::Hyperrectangle)\n\n\n\n\n\n","category":"method"},{"location":"attack/#ModelVerification.project-Tuple{Any, LazySets.LazySet}","page":"Attacks","title":"ModelVerification.project","text":"project(p, polytope::LazySet)\n\n\n\n\n\n","category":"method"},{"location":"benchmark/#Benchmark","page":"Benchmark","title":"Benchmark","text":"","category":"section"},{"location":"#ModelVerification.jl","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"","category":"section"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Pages=[\"index.md\"]","category":"page"},{"location":"#Introduction","page":"ModelVerification.jl","title":"Introduction","text":"","category":"section"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Deep Neural Network (DNN) is crucial in approximating nonlinear functions across diverse applications, such as computer vision and control. Verifying specific input-output properties can be a highly challenging task. To this end, we present ModelVerification.jl, the only cutting-edge toolbox that contains a suite of state-of-the-art methods for verifying DNNs. This toolbox significantly extends and improves the previous version (NeuralVerification.jl) and is designed to empower developers and machine learning practioners with robust tools for verifying and ensuring the trustworthiness of their DNN models.","category":"page"},{"location":"#Key-features:","page":"ModelVerification.jl","title":"Key features:","text":"","category":"section"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Julia and Python integration: Built on Julia programming language, ModelVerification.jl leverages Julia's high-performance capabilities, ensuring efficient and scalable verification processes. Moreover, we provide the user with an easy, ready-to-use Python interface to exploit the full potential of the toolbox even without knowledge of the Julia language.\nDifferent types of verification: ModelVerification.jl enables verification of several input-output specifications, such as reacability analysis, behavioral properties (e.g., to verify Deep Reinforcement Learning policies), or even robustness properties for Convolutional Neural Network (CNN). It also introduces new types of verification, not only for finding individual adversarial input, but for enumerating the entire set of unsafe zones for a given network and safety properties.\nVerification benchmarks: Compare our or your verification toolboxes against state-of-the-art benchmarks and evaluation criteria (VNN-Comp 2023). ModelVerification.jl includes a collection of solvers and standard benchmarks to perform this evaluation efficiently.","category":"page"},{"location":"#Setup","page":"ModelVerification.jl","title":"Setup","text":"","category":"section"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"This toolbox requires Julia v1.5 or later. Refer the official Julia documentation to install it for your system.","category":"page"},{"location":"#Installation","page":"ModelVerification.jl","title":"Installation","text":"","category":"section"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"To download this toolbox, clone it from the Julia package manager like so:","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"pkg> add https://github.com/intelligent-control-lab/ModelVerification.jl/","category":"page"},{"location":"#Develop-the-toolbox-(for-development)","page":"ModelVerification.jl","title":"Develop the toolbox (for development)","text":"","category":"section"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Deprecated once project is done and should be changed to \"Building the package\".","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Go to the toolbox directory and start the Julia REPL. ","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"julia > ]\n(@v1.9) > develop .\n(@v1.9) > activate .\n(@v1.9) > instantiate","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"This will enable development mode for the toolbox. The dependency packages will also be installed. Some of the important ones are listed below. ","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Flux\nLazySets\nJuMP\nZygote","category":"page"},{"location":"#Overview-of-the-toolbox","page":"ModelVerification.jl","title":"Overview of the toolbox","text":"","category":"section"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"(Image: )","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"ModelVerification.jl receives input as a set consisting of:","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Model to be verified,\nA safety property encoded as input-output specifications for the neural network,\nThe solver to be used for the formal verification process.","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"The toolbox's output varies depending on the type of verification we are performing. Nonetheless, at the end of the verification process, the response of the toolbox potentially allows us to obtain provable guarantees that a given safety property holds (or does not hold) for the model tested.","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"For more details on how the toolbox works, please refer to the tutorial below.","category":"page"},{"location":"#Quickstart","page":"ModelVerification.jl","title":"Quickstart","text":"","category":"section"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Here is a simple example for verifying that the user-given safety property holds for a small deep neural network (DNN) with a single input node, two hidden layers with two ReLU nodes, and a single output node. We use the formal verification results obtained through the reachability analysis to get a provable answer whether the safety property holds.","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"First, we load the relevant libraries and the ModelVerification.jl toolbox.","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"using ModelVerification\nusing Flux\nusing LazySets","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"First, load the model.","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"onnx_path = \"models/small_nnet.onnx\"\ntoy_model = build_flux_model(onnx_path)","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Suppose we want to verify that all inputs in mathcalX=-25 25 are mapped into mathcalY=185 1145. We encode this safety property using convex sets, provided by LazySets. ","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"X = Hyperrectangle(low = [-2.5], high = [2.5]) # expected out: [18.5, 114.5]\nY = Hyperrectangle(low = [18.5], high = [114.5]) # here we expect the property holds","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Now, we construct a Problem instance. Note that ModelVerification.jl converts the .onnx model into a Flux model.","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"problem = Problem(toy_model, X, Y)","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Instantiate the solver, which in this case is CROWN. We also need search, split, and propagation methods in addition to the solver and Problem.","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"search_method = BFS(max_iter=100, batch_size=1)\nsplit_method = Bisect(1)\n\nuse_gpu = false\nlower_bound = true\nupper_bound = true\nsolver = Crown(use_gpu, lower_bound, upper_bound)","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Finally, we can verify that the safety property holds for this simple example!","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"result = verify(search_method, split_method, solver, problem)\nprintln(result)\nprintln(result.status)","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"CROWN verifies that the input-output relationship holds!","category":"page"},{"location":"#Tutorials","page":"ModelVerification.jl","title":"Tutorials","text":"","category":"section"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Tutorials\nExample 1: Verifying a toy DNN with reachability analysis\nExample 2: Verifying a CNN for robustness safety property\nExample 3: Verifying a Deep Reinforcement Learning (DRL) policy for collision avoidance safety property","category":"page"},{"location":"#Toolbox-Outline","page":"ModelVerification.jl","title":"Toolbox Outline","text":"","category":"section"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"(Image: )","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Pages = [\"problem.md\", \"network.md\", \"safety_spec.md\", \"branching.md\", \"propagate.md\", \"solvers.md\", \"attack.md\", \"utils.md\"]\nDepth = 3","category":"page"},{"location":"#Python-Interface","page":"ModelVerification.jl","title":"Python Interface","text":"","category":"section"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Pages = [\"nnet_converter.md\", \"python_interface.md\"]\nDepth = 3","category":"page"}]
}
