var documenterSearchIndex = {"docs":
[{"location":"branching.html","page":"Branching","title":"Branching","text":"CurrentModule = ModelVerification","category":"page"},{"location":"branching.html","page":"Branching","title":"Branching","text":"Pages=[\"branching.md\"]\nDepth = 3","category":"page"},{"location":"branching.html#Branching","page":"Branching","title":"Branching","text":"","category":"section"},{"location":"branching.html","page":"Branching","title":"Branching","text":"The \"branch\" part of the Branch and Bound paradigm for verification algorithms. The branching folder contains algorithms for dividing the input set into searchable smaller sets, which we call \"branches.\" ","category":"page"},{"location":"branching.html","page":"Branching","title":"Branching","text":"The search.jl module includes algorithms to iterate over all branches, such as BFS (Breadth-first Search) and DFS (Depth-first Search). The search.jl\\search_branches function is of particular importance since it executes the verification procedure.","category":"page"},{"location":"branching.html","page":"Branching","title":"Branching","text":"The split.jl module includes algorithms to split an unknown branch, such as bisect, sensitivity analysis, etc. The split.jl\\split_branch function divides the unknown branches into smaller pieces and put them back to the branch bank for future verification. This is done so that we can get a more concrete answer by refining the problem in case the over-approximation introduced in the verification process prevents us from getting a firm result.","category":"page"},{"location":"branching.html#Search","page":"Branching","title":"Search","text":"","category":"section"},{"location":"branching.html","page":"Branching","title":"Branching","text":"SearchMethod\nBFS","category":"page"},{"location":"branching.html#ModelVerification.SearchMethod","page":"Branching","title":"ModelVerification.SearchMethod","text":"SearchMethod\n\nAlgorithm for iterating through the branches, such as BFS (breadth-first search)  and DFS (depth-first search). For an example, see the documentation on  BFS.\n\n\n\n\n\n","category":"type"},{"location":"branching.html#ModelVerification.BFS","page":"Branching","title":"ModelVerification.BFS","text":"BFS <: SearchMethod\n\nBreadth-first Search (BFS) used to iteratively go through the branches in the  branch bank.\n\nFields\n\nmax_iter (Int64): Maximum number of iterations to go through the branches    in the branch bank.\nbatch_size (Int64): Size of the batch. Defaults to 1. If batch_size is    greater than 1, GPU is used for parallel analysis of the nodes in the BaB.\n\n\n\n\n\n","category":"type"},{"location":"branching.html#Split","page":"Branching","title":"Split","text":"","category":"section"},{"location":"branching.html","page":"Branching","title":"Branching","text":"SplitMethod","category":"page"},{"location":"branching.html#ModelVerification.SplitMethod","page":"Branching","title":"ModelVerification.SplitMethod","text":"SplitMethod\n\nAlgorithm to split an unknown branch into smaller pieces for further refinement. Includes methods such as Bisect and BaBSR. For an example, see the  documentation on Bisect.\n\n\n\n\n\n","category":"type"},{"location":"branching.html#Bisection","page":"Branching","title":"Bisection","text":"","category":"section"},{"location":"branching.html","page":"Branching","title":"Branching","text":"Bisect\nsplit_branch(split_method::Bisect, model::Chain, input::Hyperrectangle, output, model_info, batch_info)\nsplit_branch(split_method::Bisect, model::Chain, input::LazySet, output, model_info, batch_info)\nsplit_branch(split_method::Bisect, model::Chain, input::ImageStarBound, output)\nsplit_branch(split_method::Bisect, model::Chain, input::ImageStarBound, output, model_info, batch_info)\nsplit_branch(split_method::Bisect, model::Chain, input::ImageZonoBound, output, model_info, batch_info)\nsplit_interval(dom::Hyperrectangle, i::Int64)","category":"page"},{"location":"branching.html#ModelVerification.Bisect","page":"Branching","title":"ModelVerification.Bisect","text":"Bisect <: SplitMethod\n\nBisection method for splitting branches.\n\nFields\n\nnum_split (Int64): Number of splits to be called.\n\n\n\n\n\n","category":"type"},{"location":"branching.html#ModelVerification.split_branch-Tuple{Bisect, Flux.Chain, LazySets.Hyperrectangle, Any, Any, Any}","page":"Branching","title":"ModelVerification.split_branch","text":"split_branch(split_method::Bisect, model::Chain, input::Hyperrectangle, \n             output, model_info, batch_info)\n\nRecursively bisects the hyperrectangle input specification at the center for  split_method.num_split number of times.\n\nArguments\n\nsplit_method (Bisect): Bisection split method.\nmodel (Chain): Model to be verified.\ninput (Hyperrectangle): Input specification represented with a    Hyperrectangle.\noutput: Output specification.\nmodel_info: Structure containing the information of the neural network to be    verified.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nList of subtrees split from the input.\n\n\n\n\n\n","category":"method"},{"location":"branching.html#ModelVerification.split_branch-Tuple{Bisect, Flux.Chain, LazySets.LazySet, Any, Any, Any}","page":"Branching","title":"ModelVerification.split_branch","text":"split_branch(split_method::Bisect, model::Chain, input::LazySet, \n             output, model_info, batch_info)\n\nGiven an input specification represented with any geometry, this function  converts it to a hyperrectangle. Then, it calls split_branch(...,  input::Hyperrectangle, ...) to recursively bisect the input specification for a  split_method.num_split number of times.\n\nArguments\n\nsplit_method (Bisect): Bisection split method.\nmodel (Chain): Model to be verified.\ninput (LazySet): Input specification represented with any LazySet.\noutput: Output specification.\nmodel_info: Structure containing the information of the neural network to be    verified.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nList of subtrees split from the input.\n\n\n\n\n\n","category":"method"},{"location":"branching.html#ModelVerification.split_branch-Tuple{Bisect, Flux.Chain, ModelVerification.ImageStarBound, Any}","page":"Branching","title":"ModelVerification.split_branch","text":"split_branch(split_method::Bisect, model::Chain, \n             input::ImageStarBound, output)\n\nGiven an input specification represented with an ImageStarBound, this function  converts it \n\nArguments\n\nsplit_method (Bisect): Bisection split method.\nmodel (Chain): Model to be verified.\ninput (ImageStarBound): Input specification represented with an    ImageStarBound.\noutput: Output specification.\n\n\n\n\n\n","category":"method"},{"location":"branching.html#ModelVerification.split_branch-Tuple{Bisect, Flux.Chain, ModelVerification.ImageStarBound, Any, Any, Any}","page":"Branching","title":"ModelVerification.split_branch","text":"split_branch(split_method::Bisect, model::Chain, \n             input::ImageStarBound, output, model_info, batch_info)\n\nTO-BE-IMPLEMENTED\n\n\n\n\n\n","category":"method"},{"location":"branching.html#ModelVerification.split_branch-Tuple{Bisect, Flux.Chain, ModelVerification.ImageZonoBound, Any, Any, Any}","page":"Branching","title":"ModelVerification.split_branch","text":"split_branch(split_method::Bisect, model::Chain, input::ImageZonoBound, \n             output, model_info, batch_info)\n\n\n\n\n\n","category":"method"},{"location":"branching.html#ModelVerification.split_interval-Tuple{LazySets.Hyperrectangle, Int64}","page":"Branching","title":"ModelVerification.split_interval","text":"split_interval(dom::Hyperrectangle, i::Int64)\n\nSplit a set into two at the given index.\n\nArguments\n\ndom (Hyperrectangle): The set in hyperrectangle to be split.\ni (Int64): The index to split at.\n\nReturns\n\n(left, right)::Tuple{Hyperrectangle, Hyperrectangle}: Two sets after split.\n\n\n\n\n\n","category":"method"},{"location":"branching.html#Branch-and-bound","page":"Branching","title":"Branch-and-bound","text":"","category":"section"},{"location":"branching.html","page":"Branching","title":"Branching","text":"BaBSR\nsplit_branch(split_method::BaBSR, model::Chain, input::ReLUConstrainedDomain, output, model_info, batch_info)\nsplit_beta(S_dict, score, split_relu_node, i, split_neurons_index_in_node, j, input, output)\nvecsign_convert_to_original_size(index, vector, original)\nvecmask_convert_to_original_size(index, original)\nbranching_scores_kfsb(model_info, batch_info, input)\ntopk(score, k, model_info)","category":"page"},{"location":"branching.html#ModelVerification.BaBSR","page":"Branching","title":"ModelVerification.BaBSR","text":"BaBSR <: SplitMethod\n\nBranch-and-Bound method for splitting branches.\n\nFields\n\nnum_split (Int64): Number of splits to be called.\n\n\n\n\n\n","category":"type"},{"location":"branching.html#ModelVerification.split_branch-Tuple{BaBSR, Flux.Chain, ModelVerification.ReLUConstrainedDomain, Any, Any, Any}","page":"Branching","title":"ModelVerification.split_branch","text":"split_branch(split_method::BaBSR, model::Chain, \n             input::ReLUConstrainedDomain, output, model_info, batch_info)\n\n\n\n\n\n","category":"method"},{"location":"branching.html#ModelVerification.split_beta-NTuple{8, Any}","page":"Branching","title":"ModelVerification.split_beta","text":"split_beta(relu_con_dict, score, split_relu_node, i, split_neurons_index_in_node, j, input, output)\n\n\n\n\n\n","category":"method"},{"location":"branching.html#ModelVerification.vecsign_convert_to_original_size-Tuple{Any, Any, Any}","page":"Branching","title":"ModelVerification.vecsign_convert_to_original_size","text":"vecsign_convert_to_original_size(index, vector, original)\n\nArguments\n\nReturns\n\n\n\n\n\n","category":"method"},{"location":"branching.html#ModelVerification.vecmask_convert_to_original_size-Tuple{Any, Any}","page":"Branching","title":"ModelVerification.vecmask_convert_to_original_size","text":"vecmask_convert_to_original_size(index, original)\n\nArguments\n\nReturns\n\n\n\n\n\n","category":"method"},{"location":"branching.html#ModelVerification.branching_scores_kfsb-Tuple{Any, Any, Any}","page":"Branching","title":"ModelVerification.branching_scores_kfsb","text":"branching_scores_kfsb(model_info, batch_info, input)\n\n\"Kernel Function Split Branch\"\n\n\n\n\n\n","category":"method"},{"location":"branching.html#ModelVerification.topk-Tuple{Any, Any, Any}","page":"Branching","title":"ModelVerification.topk","text":"topk(score, k, model_info)\n\n\"Top Kernel\"\n\n\n\n\n\n","category":"method"},{"location":"branching.html#Input-Gradient-Split","page":"Branching","title":"Input Gradient Split","text":"","category":"section"},{"location":"branching.html","page":"Branching","title":"Branching","text":"InputGradSplit","category":"page"},{"location":"branching.html#ModelVerification.InputGradSplit","page":"Branching","title":"ModelVerification.InputGradSplit","text":"InputGradSplit <: SplitMethod\n\nFields\n\nnum_split (Int64): Number of splits to be called.\n\n\n\n\n\n","category":"type"},{"location":"network.html","page":"Network","title":"Network","text":"CurrentModule = ModelVerification","category":"page"},{"location":"network.html","page":"Network","title":"Network","text":"Pages = [\"network.md\"]\nDepth = 3","category":"page"},{"location":"network.html#Network","page":"Network","title":"Network","text":"","category":"section"},{"location":"network.html#Model","page":"Network","title":"Model","text":"","category":"section"},{"location":"network.html","page":"Network","title":"Network","text":"Model","category":"page"},{"location":"network.html#ModelVerification.Model","page":"Network","title":"ModelVerification.Model","text":"Model\n\nStructure containing the information of the neural network to be verified.\n\nFields\n\nstart_nodes (Array{String, 1}): List of input layer nodes' names.\nfinal_nodes (Array{String, 1}): List of output layer nodes' names.\nall_nodes (Array{String, 1}): List of all the nodes's names.\nnode_layer (Dict): Dictionary of all the nodes. The key is the name of the    node and the value is the operation performed at the node.\nnode_prevs (Dict): Dictionary of the nodes connected to the current node.   The key is the name of the node and the value is the list of nodes.\nnode_nexts (Dict): Dictionary of the nodes connected from the current    node. The key is the name of the node and the value is the list of nodes.\nactivation_nodes (Array{String, 1}): List of all the activation nodes'    names.\nactivation_number (Int): Number of activation nodes (deprecated in the    future).\n\n\n\n\n\n","category":"type"},{"location":"network.html#Network-2","page":"Network","title":"Network","text":"","category":"section"},{"location":"network.html","page":"Network","title":"Network","text":"Network\nLayer{F<:ActivationFunction, N<:Number}","category":"page"},{"location":"network.html#ModelVerification.Network","page":"Network","title":"ModelVerification.Network","text":"Network\n\nA vector of layers.\n\nFields\n\nlayers (Vector{Layer}): Layers of the network, including the output layer.\n\nSee also: Layer\n\n\n\n\n\n","category":"type"},{"location":"network.html#ModelVerification.Layer","page":"Network","title":"ModelVerification.Layer","text":"Layer{F<:ActivationFunction, N<:Number}\n\nConsists of weights and bias for linear mapping, and activation for  nonlinear mapping.\n\nFields\n\nweights::Matrix{N}\nbias::Vector{N}\nactivation::F\n\nSee also: Network\n\n\n\n\n\n","category":"type"},{"location":"network.html#Activation-Functions","page":"Network","title":"Activation Functions","text":"","category":"section"},{"location":"network.html","page":"Network","title":"Network","text":"Modules=[ModelVerification]\nPages=[\"activation.jl\"]","category":"page"},{"location":"network.html#ModelVerification.ActivationFunction","page":"Network","title":"ModelVerification.ActivationFunction","text":"ActivationFunction\n\nFunction that calculates the output of the node. Supported activation functions are:\n\nReLU (ReLU)\nMax (Max)\nIdentity (Id)\nSigmoid (Sigmoid)\nTanh (Tanh)\n\n\n\n\n\n","category":"type"},{"location":"network.html#ModelVerification.GeneralAct","page":"Network","title":"ModelVerification.GeneralAct","text":"GeneralAct <: ActivationFunction\n\nWrapper type for a general activation function.\n\nUsage\n\nact = GeneralAct(tanh)\n\nact(0) == tanh(0)           # true\nact(10.0) == tanh(10.0)     # true\n\nact = GeneralAct(x->tanh.(x))\n\njulia> act(-2:2)\n5-element Array{Float64,1}:\n -0.9640275800758169\n -0.7615941559557649\n  0.0\n  0.7615941559557649\n  0.9640275800758169\n\n\n\n\n\n","category":"type"},{"location":"network.html#ModelVerification.Id","page":"Network","title":"ModelVerification.Id","text":"Id <: ActivationFunction\n\nIdentity operator\n\n(Id())(x) -> x\n\n\n\n\n\n","category":"type"},{"location":"network.html#ModelVerification.Max","page":"Network","title":"ModelVerification.Max","text":"Max <: ActivationFunction\n\n(Max())(x) -> max(maximum(x), 0)\n\n\n\n\n\n","category":"type"},{"location":"network.html#ModelVerification.PiecewiseLinear","page":"Network","title":"ModelVerification.PiecewiseLinear","text":"PiecewiseLinear <: ActivationFunction\n\nActivation function that uses linear interpolation between supplied knots. An extrapolation condition can be set for values outside the set of knots. Default is Linear.\n\nPiecewiseLinear(knots_x, knots_y, [extrapolation = Line()])\n\nUsage\n\nkx = [0.0, 1.2, 1.7, 3.1]\nky = [0.0, 0.5, 1.0, 1.5]\nact = PiecewiseLinear(kx, ky)\n\nact(first(kx)) == first(ky) == 0.0\nact(last(kx))  == last(ky)  == 1.5\n\nact(1.0)    # 0.4166666666666667\nact(-102)   # -42.5\n\nact = PiecewiseLinear(kx, ky, Flat())\n\nact(-102)   # 0.0\nact(Inf)    # 1.5\n\nExtrapolations\n\nFlat()\nLine()\nconstant (supply a number as the argument)\nThrow() (throws bounds error)\n\nPiecewiseLinear uses Interpolations.jl.\n\n\n\n\n\n","category":"type"},{"location":"network.html#ModelVerification.ReLU","page":"Network","title":"ModelVerification.ReLU","text":"ReLU <: ActivationFunction\n\n(ReLU())(x) -> max.(x, 0)\n\n\n\n\n\n","category":"type"},{"location":"network.html#ModelVerification.Sigmoid","page":"Network","title":"ModelVerification.Sigmoid","text":"Sigmoid <: ActivationFunction\n\n(Sigmoid())(x) -> 1 ./ (1 .+ exp.(-x))\n\n\n\n\n\n","category":"type"},{"location":"network.html#ModelVerification.Tanh","page":"Network","title":"ModelVerification.Tanh","text":"Tanh <: ActivationFunction\n\n(Tanh())(x) -> tanh.(x)\n\n\n\n\n\n","category":"type"},{"location":"network.html#Helper-Functions","page":"Network","title":"Helper Functions","text":"","category":"section"},{"location":"network.html","page":"Network","title":"Network","text":"Below are the helper functions regarding network loading (from file) & dumping (to file), property-related, activation function operations, gradient-related operations, and bound & specification related operations.","category":"page"},{"location":"network.html#Network-loading-and-dumping","page":"Network","title":"Network loading and dumping","text":"","category":"section"},{"location":"network.html","page":"Network","title":"Network","text":"onnx_parse(onnx_model_path)\nread_nnet(fname::String; last_layer_activation = Id())\nread_layer(output_dim::Int64, f::IOStream, act = ReLU())\nto_comment(txt)\nprint_layer(file::IOStream, layer)\nprint_header(file::IOStream, network; header_text=\"\")\nwrite_nnet(filename, network; header_text)\nbuild_flux_model(onnx_model_path)\nget_chain(vertex)\npurify_flux_model(model::Chain)\nremove_flux_start_flatten(model::Chain)\nbuild_onnx_model(path, model::Chain, input::InputSpec)","category":"page"},{"location":"network.html#ModelVerification.onnx_parse-Tuple{Any}","page":"Network","title":"ModelVerification.onnx_parse","text":"onnx_parse(onnx_model_path)\n\nCreates the Model from the onnx_model_path. First, the computational graph  of the ONNX model is created. Then, the Model is created using the information retrieved from the computational graph.\n\nArguments\n\nonnx_model_path: String path to the ONNX model.\n\nReturns\n\nmodel_info (Model): Contains network information retrieved from the    computational graph of the ONNX model.\n\n\n\n\n\n","category":"method"},{"location":"network.html#ModelVerification.read_nnet-Tuple{String}","page":"Network","title":"ModelVerification.read_nnet","text":"read_nnet(fname::String; last_layer_activation = Id())\n\nRead in neural net from a .nnet file and return Network struct. The .nnet format is borrowed from NNet. The format assumes all hidden layers have ReLU activation. Keyword argument last_layer_activation sets the activation of the last layer, and defaults to Id(), (i.e. a linear output layer).\n\nArguments\n\nfname (String): String path to the .nnet file.\nlast_layer_activation: Keyword argument that sets the activation of the last    layer which defaults to Id().\n\nReturns\n\nA vector of layers saved as Network.\n\n\n\n\n\n","category":"method"},{"location":"network.html#ModelVerification.read_layer","page":"Network","title":"ModelVerification.read_layer","text":"read_layer(output_dim::Int64, f::IOStream, act = ReLU())\n\nRead in layer from .nnet file and return a Layer containing its  weights & biases. Optional argument act sets the activation function for the  layer.\n\nArguments\n\noutput_dim (Int64): Output dimension of the layer.\nf (IOStream): IO stream of the .nnet file.\nact: Optional argument specifying the activation function of the layer.    Defaults to ReLU().\n\nReturns\n\nLayer containing the weights and bias values (and the activation function    of the layer).\n\n\n\n\n\n","category":"function"},{"location":"network.html#ModelVerification.to_comment-Tuple{Any}","page":"Network","title":"ModelVerification.to_comment","text":"to_comment(txt)\n\nPrepend // to each line of a string.\n\n\n\n\n\n","category":"method"},{"location":"network.html#ModelVerification.print_layer-Tuple{IOStream, Any}","page":"Network","title":"ModelVerification.print_layer","text":"print_layer(file::IOStream, layer)\n\nPrint to file an object implementing weights(layer) and bias(layer).\n\nArguments\n\nfile (IOStream): IO stream of the target .nnet file.\nlayer: Layer to be transcribed to file.\n\n\n\n\n\n","category":"method"},{"location":"network.html#ModelVerification.print_header-Tuple{IOStream, Any}","page":"Network","title":"ModelVerification.print_header","text":"print_header(file::IOStream, network; header_text=\"\")\n\nThe NNet format has a particular header containing information about the  network size and training data. print_header does not take training-related  information into account (subject to change).\n\nArguments\n\nfile (IOStream): IO stream of the target .nnet file.\nnetwork: Network to be transcribed to file.\nheader_text: Optional header text that comes before the network information.    Defaults to an empty string.\n\n\n\n\n\n","category":"method"},{"location":"network.html#ModelVerification.write_nnet-Tuple{Any, Any}","page":"Network","title":"ModelVerification.write_nnet","text":"write_nnet(filename, network; header_text)\n\nWrite network to filename.nnet. Note: Does not perform safety checks on inputs, so use with caution.\n\nBased on python code at https://github.com/sisl/NNet/blob/master/utils/writeNNet.py and follows .nnet format given here: https://github.com/sisl/NNet.\n\nArguments\n\noutfile: String name of the .nnet file.\nnetwork: Network to be transcribed to outfile.nnet.\nheader_text: Optional header text that comes before the network information.\n\n\n\n\n\n","category":"method"},{"location":"network.html#ModelVerification.build_flux_model-Tuple{Any}","page":"Network","title":"ModelVerification.build_flux_model","text":"build_flux_model(onnx_model_path)\n\nBuilds a Flux.Chain from the given ONNX model path.\n\nArguments\n\nonnx_model_path: String path to ONNX model in .onnx file.\n\nReturns\n\nmodel: Flux.Chain constructed from the .onnx file.\n\n\n\n\n\n","category":"method"},{"location":"network.html#ModelVerification.get_chain-Tuple{Any}","page":"Network","title":"ModelVerification.get_chain","text":"get_chain(vertex)\n\nReturns a Flux.Chain constructed from the given vertex. This is a helper  function for build_flux_model. \n\nArguments\n\nvertex: Vertex from the NaiveNASflux computation graph.\n\nReturns\n\nmodel: Flux.Chain constructed from the given vertex.\ncurr_vertex: The last vertex in the chain.\n\n\n\n\n\n","category":"method"},{"location":"network.html#ModelVerification.purify_flux_model-Tuple{Flux.Chain}","page":"Network","title":"ModelVerification.purify_flux_model","text":"purify_flux_model(model::Chain)\n\nRemoves the starting Flatten layer from the model. This is a wrapper function  for remove_flux_start_flatten.\n\nArguments\n\nmodel (Chain): Flux.Chain model.\n\nReturns\n\nmodel (Chain): Flux.Chain model with the starting Flatten layer    removed.\n\n\n\n\n\n","category":"method"},{"location":"network.html#ModelVerification.remove_flux_start_flatten-Tuple{Flux.Chain}","page":"Network","title":"ModelVerification.remove_flux_start_flatten","text":"remove_flux_start_flatten(model::Chain)\n\nRemoves the starting Flatten layer from the model.\n\nArguments\n\nmodel (Chain): Flux.Chain model.\n\nReturns\n\nmodel (Chain): Flux.Chain model with the starting Flatten layer    removed.\n\n\n\n\n\n","category":"method"},{"location":"network.html#ModelVerification.build_onnx_model-Tuple{Any, Flux.Chain, InputSpec}","page":"Network","title":"ModelVerification.build_onnx_model","text":"build_onnx_model(path, model::Chain, input::InputSpec)\n\nBuilds an ONNX model from the given Flux.Chain model and input specification.  The ONNX model is saved to the given path.\n\nArguments\n\npath (String): Path to save the ONNX model.\nmodel (Chain): Flux.Chain model.\ninput (InputSpec): Input specification.\n\nReturns\n\npath (String): Path to the saved ONNX model.\n\n\n\n\n\n","category":"method"},{"location":"network.html#Network-properties","page":"Network","title":"Network properties","text":"","category":"section"},{"location":"network.html","page":"Network","title":"Network","text":"get_act(l)\nn_nodes(L::Layer)\nget_sub_model(model_info, end_node)\ncompute_output(nnet::Network, input)","category":"page"},{"location":"network.html#ModelVerification.get_act-Tuple{Any}","page":"Network","title":"ModelVerification.get_act","text":"get_act(l)\n\nReturns the activation function of the node l if it exists.\n\nArguments\n\nl: node\n\nReturns\n\nActivation function of the node if it exists.\nOtherwise, return nothing.\n\n\n\n\n\n","category":"method"},{"location":"network.html#ModelVerification.n_nodes-Tuple{ModelVerification.Layer}","page":"Network","title":"ModelVerification.n_nodes","text":"n_nodes(L::Layer)\n\nReturns the number of neurons in a layer.\n\nArguments\n\nL (Layer): Layer of a network.\n\nReturns\n\nn (Int): Number of nodes in the layer L which is equivalent to the    number of biases in the layer.\n\n\n\n\n\n","category":"method"},{"location":"network.html#ModelVerification.get_sub_model-Tuple{Any, Any}","page":"Network","title":"ModelVerification.get_sub_model","text":"get_sub_model(model_info, end_node)\n\n\n\n\n\n","category":"method"},{"location":"network.html#ModelVerification.compute_output-Tuple{ModelVerification.Network, Any}","page":"Network","title":"ModelVerification.compute_output","text":"compute_output(nnet::Network, input)\n\nPropagates a given vector through a Network and computes the output.\n\nArguments\n\nnnet (Network): Network to be propagated.\ninput: Vector to be propagated through nnet.\n\nReturns\n\nVector of the output of nnet given input.\n\n\n\n\n\n","category":"method"},{"location":"network.html#Activation-function-operations","page":"Network","title":"Activation function operations","text":"","category":"section"},{"location":"network.html","page":"Network","title":"Network","text":"get_activation(L::Layer{ReLU}, x::Vector)\nget_activation(L::Layer{Id}, args...)\nget_activation(nnet::Network, x::Vector{Float64})\nget_activation(nnet::Network, input::Hyperrectangle)\nget_activation(nnet::Network, bounds::Vector{Hyperrectangle})\nget_activation(L::Layer{ReLU}, bounds::Hyperrectangle)\napproximate_act_map(act::ActivationFunction, input::Hyperrectangle)\napproximate_act_map(layer::Layer, input::Hyperrectangle)","category":"page"},{"location":"network.html#ModelVerification.get_activation-Tuple{ModelVerification.Layer{ModelVerification.ReLU}, Vector}","page":"Network","title":"ModelVerification.get_activation","text":"get_activation(L::Layer{ReLU}, x::Vector)\n\nFinds the activation pattern of a vector x subject to the activation function  given by the layer L. Returns a Vector{Bool} where true denotes the node is  \"active\". In the sense of ReLU, this would be x[i] >= 0.\n\nArguments\n\nL (Layer{ReLU}): Layer with ReLU activation function.\nx (Vector): Vector to be propagated through the ReLU activation function.\n\nReturns\n\nVector{Bool} where true denotes the node is element-wise \"active\".\n\n\n\n\n\n","category":"method"},{"location":"network.html#ModelVerification.get_activation-Tuple{ModelVerification.Layer{ModelVerification.Id}, Vararg{Any}}","page":"Network","title":"ModelVerification.get_activation","text":"get_activation(L::Layer{Id}, args...)\n\nFinds the activation pattern of a vector x subject to the activation function  given by the layer L. Returns a Vector{Bool} where true denotes the node is  \"active\". In the sense of Identity, this would be a vector of true's for all  nodes in the layer L.\n\nArguments\n\nL (Layer{Id}): Layer with Identity activation function.\nx (Vector): Vector to be propagated through the Identity activation    function.\n\nReturns\n\nVector{Bool} where true denotes the node is element-wise \"active\".\n\n\n\n\n\n","category":"method"},{"location":"network.html#ModelVerification.get_activation-Tuple{ModelVerification.Network, Vector{Float64}}","page":"Network","title":"ModelVerification.get_activation","text":"get_activation(nnet::Network, x::Vector{Float64})\n\nGiven a network, find the activation pattern of all neurons at a given point x. Returns Vector{Vector{Bool}}. Each Vector{Bool} refers to the activation pattern  of a particular layer.\n\nArguments\n\nnnet (Network): Network to be propagated.\nx (Vector{Float64}): Vector to be propagated through nnet.\n\nReturns\n\nVector{Vector{Bool}} where each Vector{Bool} refers to the activation    pattern of a particular layer.\n\n\n\n\n\n","category":"method"},{"location":"network.html#ModelVerification.get_activation-Tuple{ModelVerification.Network, LazySets.Hyperrectangle}","page":"Network","title":"ModelVerification.get_activation","text":"get_activation(nnet::Network, input::Hyperrectangle)\n\nGiven a network, find the activation pattern of all neurons for a given input  set. Assume ReLU activation function for all layers. This function first  computes the node-wise bounds of the input set, and then computes the  activation pattern using get_activation(nnet, bounds).\n\nArguments\n\nnnet (Network): Network to be propagated, with the activation function    assumed to be ReLU for all layers.\ninput (Hyperrectangle): Input set to be propagated through nnet,        represented as a Hyperrectangle.\n\nReturns\n\nVector{Vector{Bool}} where each Vector{Bool} refers to the activation    pattern of a particular layer. Each element in each Vector{Bool} specifies    the activation pattern of a particular neuron. 1 means activated, 0    means undetermined, and -1 means not activated.\n\n\n\n\n\n","category":"method"},{"location":"network.html#ModelVerification.get_activation-Tuple{ModelVerification.Network, Vector{LazySets.Hyperrectangle}}","page":"Network","title":"ModelVerification.get_activation","text":"get_activation(nnet::Network, bounds::Vector{Hyperrectangle})\n\nGiven a network, find the activation pattern of all neurons given the node-wise  bounds. Assume ReLU activation function for all layers. Assume pre-activation  bounds where the bounds on the input are given by the first hyperrectangle, the  first hidden layer by the second hyperrectangle, and so on.\n\nArguments\n\nnnet (Network): Network to be propagated, with the activation function    assumed to be ReLU for all layers.\nbounds (Vector{Hyperrectangle}): Vector of node-wise bounds, where the    bounds on the input are given by the first hyperrectangle, the first hidden    layer by the second hyperrectangle, and so on.\n\nReturns\n\nVector{Vector{Bool}} where each Vector{Bool} refers to the activation    pattern of a particular layer. Each element in each Vector{Bool} specifies    the activation pattern of a particular neuron. 1 means activated, 0    means undetermined, and -1 means not activated.\n\n\n\n\n\n","category":"method"},{"location":"network.html#ModelVerification.get_activation-Tuple{ModelVerification.Layer{ModelVerification.ReLU}, LazySets.Hyperrectangle}","page":"Network","title":"ModelVerification.get_activation","text":"get_activation(L::Layer{ReLU}, bounds::Hyperrectangle)\n\nGiven a layer, find the activation pattern of all neurons in the layer given the  node-wise bounds. Assume ReLU activation function for the given layer. Assume  bounds is the pre-activation bounds for each ReLU in the layer.\n\nArguments\n\nL (Layer{ReLU}): Layer to be propagated, with the activation function    assumed to be ReLU.\nbounds (Hyperrectangle): Node-wise pre-activation bounds for the layer.\n\nReturns\n\nVector{Bool} where each element refers to the activation pattern of a    particular neuron. 1 means activated, 0 means undetermined, and -1    means not activated.\n\n\n\n\n\n","category":"method"},{"location":"network.html#ModelVerification.approximate_act_map-Tuple{ModelVerification.ActivationFunction, LazySets.Hyperrectangle}","page":"Network","title":"ModelVerification.approximate_act_map","text":"approximate_act_map(act::ActivationFunction, input::Hyperrectangle)\n\nReturns a Hyperrectangle overapproximation of the activation map of the input. act must be monotonic.\n\nArguments\n\nact (ActivationFunction): Activation function to be propagated.\ninput (Hyperrectangle): Input set to be propagated through act.\n\nReturns\n\nHyperrectangle overapproximation of the activation map of the input.\n\n\n\n\n\n","category":"method"},{"location":"network.html#ModelVerification.approximate_act_map-Tuple{ModelVerification.Layer, LazySets.Hyperrectangle}","page":"Network","title":"ModelVerification.approximate_act_map","text":"approximate_act_map(layer::Layer, input::Hyperrectangle)\n\nReturns a Hyperrectangle overapproximation of the activation map of the input  for the given layer. The activation function of the layer must be monotonic. \n\nArguments\n\nlayer (Layer): Layer to be propagated for the activation map.\ninput (Hyperrectangle): Input set to be propagated through layer.\n\nReturns\n\nHyperrectangle overapproximation of the activation map of the input.\n\n\n\n\n\n","category":"method"},{"location":"network.html#Gradient-operations","page":"Network","title":"Gradient operations","text":"","category":"section"},{"location":"network.html","page":"Network","title":"Network","text":"get_gradient(nnet::Network, x::Vector)\nact_gradient(act::ReLU, z_hat::Vector)\nact_gradient(act::Id, z_hat::Vector)\nrelaxed_relu_gradient(l::Real, u::Real)\nact_gradient_bounds(nnet::Network, input::AbstractPolytope)\nget_gradient_bounds(nnet::Network, input::AbstractPolytope)\nget_gradient_bounds(nnet::Network, LΛ::Vector{<:AbstractVector}, UΛ::Vector{<:AbstractVector})","category":"page"},{"location":"network.html#ModelVerification.get_gradient-Tuple{ModelVerification.Network, Vector}","page":"Network","title":"ModelVerification.get_gradient","text":"get_gradient(nnet::Network, x::Vector)\n\nGiven a network, find the gradient for the input x. The function propagates  through the layers of the network, and computes the gradient at each layer.  The gradient at each layer is computed by multiplying the gradient at the  previous layer with the gradient of the current layer.\n\nArguments\n\nnnet (Network): Network to be propagated.\nx (Vector): Vector to be propagated through nnet.\n\nReturns\n\nMatrix of the gradient for the input x after propagating through nnet.\n\n\n\n\n\n","category":"method"},{"location":"network.html#ModelVerification.act_gradient-Tuple{ModelVerification.ReLU, Vector}","page":"Network","title":"ModelVerification.act_gradient","text":"act_gradient(act::ReLU, z_hat::Vector)\n\nCompute the gradient of an ReLU activation function at point zhat. For each  element in `zhat, ifzhat[i] > 0, thenactgradient[i] = 1, elseact_gradient[i] = 0`.\n\nArguments\n\nact (ReLU): ReLU activation function.\nz_hat (Vector): Vector to be propagated through act.\n\nReturns\n\nVector of the gradient of act at z_hat. Each element in the vector    corresponds to the gradient of a particular neuron.\n\n\n\n\n\n","category":"method"},{"location":"network.html#ModelVerification.act_gradient-Tuple{ModelVerification.Id, Vector}","page":"Network","title":"ModelVerification.act_gradient","text":"act_gradient(act::Id, z_hat::Vector)\n\nCompute the gradient of an Identity activation function at point zhat. For  each element in `zhat,act_gradient[i] = 1`. \n\nArguments\n\nact (Id): Identity activation function.\nz_hat (Vector): Vector to be propagated through act.\n\nReturns\n\nVector of the gradient of act at z_hat. Each element in the vector    corresponds to the gradient of a particular neuron. \n\n\n\n\n\n","category":"method"},{"location":"network.html#ModelVerification.relaxed_relu_gradient-Tuple{Real, Real}","page":"Network","title":"ModelVerification.relaxed_relu_gradient","text":"relaxed_relu_gradient(l::Real, u::Real)\n\nReturn the relaxed slope of a ReLU activation based on its lower and upper  bounds. The relaxed ReLU function allows for a smooth approximation of the  gradient of the ReLU function. The relaxed ReLU function is defined as follows: \n\nf'(x) = 0 if upper-bound < 0, \nf'(x) = 1 if lower-bound > 0, \nand f'(x) = x/(u-l) if lower-bound < x < upper-bound which is the slope of    the line connecting the points (l, ReLU(l)) and (u, ReLU(u)).\n\nThis provides a differentiable approximation of the ReLU function within the  interval [l, u].\n\nArguments\n\nl (Real): Lower-bound of the input to the ReLU activation function.\nu (Real): Upper-bound of the input to the ReLU activation function.\n\nReturns\n\n0.0 if u <= 0.0, \n1.0 if l >= 0.0,\nu/(u-l) otherwise.\n\n\n\n\n\n","category":"method"},{"location":"network.html#ModelVerification.act_gradient_bounds-Tuple{ModelVerification.Network, LazySets.AbstractPolytope}","page":"Network","title":"ModelVerification.act_gradient_bounds","text":"act_gradient_bounds(nnet::Network, input::AbstractPolytope)\n\nCompute the bit-wise bounds on the gradient post activation operation given an  input  set. Currently only support ReLU activation function. It first calculates  the bounds of the input for each layer using get_bounds function (this  function propagates through each layer and computes the bounds of each layer).  Then, it computes the bit-wise lower and upper gradient for each layer using  act_gradient. The final output is a tuple of two vectors, where each vector is  a vector of bit-vectors. Each element in the vector corresponds to the gradient  of a particular neuron which can be either 0 (not activated) or  1 (activated).\n\nArguments\n\nnnet (Network): Network to be propagated.\ninput (AbstractPolytope): Input set to be propagated through nnet.\n\nReturns\n\nLΛ, UΛ::NTuple{2, Vector{BitVector}}: lower and upper bit-wsie bounds on the    activation gradients for each layer.\n\n\n\n\n\n","category":"method"},{"location":"network.html#ModelVerification.get_gradient_bounds-Tuple{ModelVerification.Network, LazySets.AbstractPolytope}","page":"Network","title":"ModelVerification.get_gradient_bounds","text":"get_gradient_bounds(nnet::Network, input::AbstractPolytope)\n\nGet lower and upper bounds on network gradient for given gradient bounds on  activations, or given an input set. It first calculates the bit-wise lower and upper gradient bounds for each layer  using  act_gradient_bounds. Then, it computes the gradient bounds of the  entire network for the weights using get_gradient_bounds.\n\nArguments\n\nnnet (Network): Network to be propagated.\ninput (AbstractPolytope): Input set to be propagated through nnet.\n\nReturns\n\n(LG, UG): NTuple{2, Matrix{Float64} of the lower and upper bounds of the    entire network.\n\n\n\n\n\n","category":"method"},{"location":"network.html#ModelVerification.get_gradient_bounds-Tuple{ModelVerification.Network, Vector{<:AbstractVector}, Vector{<:AbstractVector}}","page":"Network","title":"ModelVerification.get_gradient_bounds","text":"get_gradient_bounds(nnet::Network, LΛ::Vector{AbstractVector}, \n                    UΛ::Vector{AbstractVector})\n\nGiven bit-wise lower and upper gradient bounds for each layer (LΛ and UΛ),  compute the lower and upper bounds of the entire network for the weights of the  layers. \n\nArguments\n\nnnet (Network): Network to be propagated.\nLΛ (Vector{AbstractVector}): Vector of bit-wise lower gradient bounds for    each layer. \nUΛ (Vector{AbstractVector}): Vector of bit-wise upper gradient bounds for   each layer.    \n\nReturns\n\n(LG, UG): NTuple{2, Matrix{Float64} of the lower and upper bounds of the    entire network.\n\n\n\n\n\n","category":"method"},{"location":"network.html#Bound-and-Specification-operations","page":"Network","title":"Bound & Specification operations","text":"","category":"section"},{"location":"network.html","page":"Network","title":"Network","text":"interval_map(W::Matrix, l::AbstractVecOrMat, u::AbstractVecOrMat)\nget_bounds(nnet::Network, input; before_act::Bool = false)\nget_bounds(problem::Problem; kwargs...)\nisbounded(input)\nis_hypercube(set::Hyperrectangle)\nis_halfspace_equivalent(set)\nUnboundedInputError","category":"page"},{"location":"network.html#ModelVerification.interval_map-Tuple{Matrix, AbstractVecOrMat, AbstractVecOrMat}","page":"Network","title":"ModelVerification.interval_map","text":"interval_map(W::Matrix, l::AbstractVecOrMat, u::AbstractVecOrMat)\n\nSimple linear mapping of the weights on intervals. L, U := ([W]₊*l + [W]₋*u), ([W]₊*u + [W]₋*l)\n\nArguments\n\nW (AbstractMatrix): Matrix of weights.\nl (AbstractVecOrMat): Vector or matrix of lower bounds.\nu (AbstractVecOrMat): Vector or matrix of upper bounds.\n\nReturns\n\n(l_new, u_new): New bounds after the linear mapping.\n\n\n\n\n\n","category":"method"},{"location":"network.html#ModelVerification.get_bounds-Tuple{ModelVerification.Network, Any}","page":"Network","title":"ModelVerification.get_bounds","text":"get_bounds(nnet::Network, input; before_act::Bool = false)\n\nComputes node-wise bounds given a input set. The optional last argument determines whether the bounds are pre- or post-activation.\n\nArguments\n\nnnet (Network): Network to be propagated.\ninput (AbstractPolytope): Input set to be propagated through nnet.\nbefore_act: Optional argument that determines whether the bounds are    pre- or post-activation. Defaults to false.\n\nReturns\n\nVector{Hyperrectangle}: bounds for all nodes. bounds[1] is the    input set overapproximated with a Hyperrectangle.\n\n\n\n\n\n","category":"method"},{"location":"network.html#ModelVerification.get_bounds-Tuple{Problem}","page":"Network","title":"ModelVerification.get_bounds","text":"get_bounds(problem::Problem; kwargs...)\n\nCompute node-wise bounds for a given Problem using get_bounds(nnet, input).\n\nArguments\n\nproblem (Problem): Problem to be propagated.\nkwargs: Keyword arguments to be passed to get_bounds(nnet, input) such as    the optional boolean argument before_act.\n\nReturns\n\nVector{Hyperrectangle}: bounds for all nodes. bounds[1] is the input set.\n\n\n\n\n\n","category":"method"},{"location":"network.html#ModelVerification.isbounded-Tuple{Any}","page":"Network","title":"ModelVerification.isbounded","text":"isbounded(input)\n\nCheck if input set is bounded. If the input is of type HPolytope, then  LazySets.isbounded converts the HPolytope to a HPolyhedron and checks if  that is bounded. Otherwise, LazySets.isbounded is called directly.\n\nArguments\n\ninput: Input set to be checked for boundedness.\n\nReturns\n\ntrue if input is bounded, false otherwise.\n\n\n\n\n\n","category":"method"},{"location":"network.html#ModelVerification.is_hypercube-Tuple{LazySets.Hyperrectangle}","page":"Network","title":"ModelVerification.is_hypercube","text":"is_hypercube(set::Hyperrectangle)\n\nCheck if set is a is_hypercube. This is done by checking if all the radii of  the Hyperrectangle are equal in all directions.\n\nArguments\n\nset (Hyperrectangle): Set to be checked for hypercube-ness.\n\nReturns\n\ntrue if set is a hypercube, false otherwise.\n\n\n\n\n\n","category":"method"},{"location":"network.html#ModelVerification.is_halfspace_equivalent-Tuple{Any}","page":"Network","title":"ModelVerification.is_halfspace_equivalent","text":"is_halfspace_equivalent(set)\n\nCheck if set is halfspace equivalent. This is done by checking if the number  of constraints in the set is equal to 1.\n\nArguments\n\nset: Set to be checked for halfspace equivalence.\n\nReturns\n\ntrue if set is halfspace equivalent, false otherwise.\n\n\n\n\n\n","category":"method"},{"location":"network.html#ModelVerification.UnboundedInputError","page":"Network","title":"ModelVerification.UnboundedInputError","text":"UnboundedInputError <: Exception\n\nException thrown when an input set is unbounded.\n\nFields\n\nmsg (String): Error message.\n\n\n\n\n\n","category":"type"},{"location":"existing_implementations.html#Existing-Implementations","page":"Existing Implementations","title":"Existing Implementations","text":"","category":"section"},{"location":"existing_implementations.html","page":"Existing Implementations","title":"Existing Implementations","text":"MIPVerify\nConvDual\nReluVal\nNeurify\nSherlock\nPlanet\nPLNN\nDLV\nReluplex","category":"page"},{"location":"propagate.html","page":"Propagation","title":"Propagation","text":"CurrentModule = ModelVerification","category":"page"},{"location":"propagate.html","page":"Propagation","title":"Propagation","text":"Pages=[\"propagation.md\"]\nDepth = 3","category":"page"},{"location":"propagate.html#Propagation","page":"Propagation","title":"Propagation","text":"","category":"section"},{"location":"propagate.html","page":"Propagation","title":"Propagation","text":"Functions for propagating the bound through the model (from start nodes to the end nodes) for a given branch. For a forward propagation method (ForwardProp), the start nodes are the input nodes of the computational graph and the end nodes are the output nodes. For a backward propagation method (BackwardProp), the start nodes are the output nodes and the end nodes are the input nodes. We use BFS (Breadth-first Search) to iterate through the computational graph and propagate the bounds from nodes to nodes.","category":"page"},{"location":"propagate.html","page":"Propagation","title":"Propagation","text":"The propagate\\propagate.jl module defines algorithms for propagating bounds from input to output, for both forward propagation and backward propagation.","category":"page"},{"location":"propagate.html","page":"Propagation","title":"Propagation","text":"The propagate\\operators folder contains specific propagation algorithms for different operators, such as ReLU, Dense, Identity, Convolution, Bivariate, etc.","category":"page"},{"location":"propagate.html","page":"Propagation","title":"Propagation","text":"propagate\npropagate_skip_method(prop_method::ForwardProp, model_info, batch_info, node)\npropagate_skip_method(prop_method::BackwardProp, model_info, batch_info, node)\npropagate_layer_method(prop_method::ForwardProp, model_info, batch_info, node)\npropagate_layer_method(prop_method::BackwardProp, model_info, batch_info, node)\npropagate_linear_batch(prop_method::ForwardProp, layer, batch_reach::AbstractArray, batch_info)\npropagate_act_batch(prop_method::ForwardProp, σ, batch_reach::AbstractArray, batch_info)\npropagate_skip_batch(prop_method::ForwardProp, layer, batch_reach1::AbstractArray, batch_reach2::AbstractArray, batch_info)\nis_activation(l)\npropagate_layer_batch(prop_method, layer, batch_bound, batch_info)\nenqueue_nodes!(prop_method::ForwardProp, queue, model_info)\nenqueue_nodes!(prop_method::BackwardProp, queue, model_info)\noutput_node(prop_method::ForwardProp, model_info)\nnext_nodes(prop_method::ForwardProp,  model_info, node)\nnext_nodes(prop_method::BackwardProp, model_info, node)\nprev_nodes(prop_method::ForwardProp,  model_info, node)\nprev_nodes(prop_method::BackwardProp, model_info, node)\nall_nexts_in(prop_method, model_info, output_node, cnt)\nall_prevs_in(prop_method, model_info, output_node, cnt)\nhas_two_reach_node(prop_method, model_info, node)","category":"page"},{"location":"propagate.html#ModelVerification.propagate","page":"Propagation","title":"ModelVerification.propagate","text":"propagate(prop_method::PropMethod, model_info, batch_info)\n\nPropagates through the model using the specified prop_method.  The propagation algorithm is as follows:\n\nAdd the connecting nodes of the start nodes, i.e., nodes after the start \n\nnodes, into a queue.\n\nWhile the queue is not empty:\nPop a node from the queue.\nFor each node connected from the current node, i.e., for each output   node:\nIncrement the visit count to the output node.\nIf the visit count equals the number of nodes connected from the   output node, i.e., visit count == previous nodes of the output node,   add the output node to the queue.\nPropagate through the current node accordingly.\nAdd information about the bound of the node to batch_info.\nReturn the bound of the output node(s).\n\nIn step 2(1)(2), the function adds the output node to the queue since all the  previous nodes of the output node have been processed. Thus, the output node is  now the node of interest. In step 2(3), the propagation works based on the  propagation method (prop_method), which depends on the geometric  representation of the safety specifications and the activation function of each  layer.\n\nArguments\n\nprop_method (PropMethod): Propagation method used for the verification    process. This is one of the solvers used to verify the given model.\nmodel_info: Structure containing the information of the neural network to be    verified.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nbatch_bound: Bound of the output node, i.e., the final bound.\nbatch_info: Same as the input batch_info, with additional information on    the bound of each node in the model.\n\n\n\n\n\n","category":"function"},{"location":"propagate.html#ModelVerification.propagate_skip_method-Tuple{ModelVerification.ForwardProp, Any, Any, Any}","page":"Propagation","title":"ModelVerification.propagate_skip_method","text":"propagate_skip_method(prop_method::ForwardProp, model_info, \n                      batch_info, node)\n\nThis function propagates the two sets of bounds of the preceding nodes from the  provided node using the specified forward propagation method and layer  operation. It invokes propagate_skip_batch, which subsequently calls   propagate_skip. The function identifies the two previous nodes from the given node in the computational graph, model_info, their bounds, and the layer  operation of the node. Then, propagate_skip is invoked.\n\nArguments\n\nprop_method (ForwardProp): Forward propagation method used for the    verification process. This is one of the solvers used to verify the given    model.\nmodel_info: Structure containing the information of the neural network to be    verified.\nbatch_info: Dictionary containing information of each node in the model.\nnode: The current node to be propagated through.\n\nReturns\n\nbatch_bound: List of reachable bounds after propagating the two sets of   bounds in batch_reach through the given node, following the propagation    method and the layer operation.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.propagate_skip_method-Tuple{ModelVerification.BackwardProp, Any, Any, Any}","page":"Propagation","title":"ModelVerification.propagate_skip_method","text":"propagate_skip_method(prop_method::BackwardProp, model_info, \n                      batch_info, node)\n\nThis function propagates the two sets of bounds of the next nodes from the  provided node using the specified backward propagation method and layer  operation. It invokes propagate_skip_batch, which subsequently calls   propagate_skip. The function identifies the two next nodes from the given node in the computational graph, model_info, their bounds, and the layer  operation of the node. Then, propagate_skip is invoked.\n\nArguments\n\nprop_method (BackwardProp): Backward propagation method used for the    verification process. This is one of the solvers used to verify the given    model.\nmodel_info: Structure containing the information of the neural network to be    verified.\nbatch_info: Dictionary containing information of each node in the model.\nnode: The current node to be propagated through.\n\nReturns\n\nbatch_bound: List of reachable bounds after propagating the two sets of   bounds in batch_reach through the given node, following the propagation    method and the layer operation.                          \n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.propagate_layer_method-Tuple{ModelVerification.ForwardProp, Any, Any, Any}","page":"Propagation","title":"ModelVerification.propagate_layer_method","text":"propagate_layer_method(prop_method::ForwardProp, model_info, batch_info, node)\n\nThis function propagates the bounds of the preceding node from the provided node  using the specified forward propagation method and layer operation. It invokes  propagate_layer_batch, which subsequently calls either  propagate_linear_batch or propagate_act_batch. The function identifies the  previous node from the given node in the computational graph, model_info, its  bound, and the layer operation of the node. Then, propagate_layer_batch  ascertains if the layer operation is linear or includes activation functions  like ReLU. Depending on this, propagate_linear_batch or propagate_act_batch  is invoked.\n\nArguments\n\nprop_method (ForwardProp): The forward propagation method employed for    verification. It is one of the solvers used to validate the specified model.\nmodel_info: Structure containing the information of the neural network to be    verified.\nbatch_info: Dictionary containing information of each node in the model.\nnode: The current node to be propagated through.\n\nReturns\n\nbatch_bound: List of reachable bounds after propagating the set of input    bounds of the given node, following the propagation method and the linear    layer operation.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.propagate_layer_method-Tuple{ModelVerification.BackwardProp, Any, Any, Any}","page":"Propagation","title":"ModelVerification.propagate_layer_method","text":"propagate_layer_method(prop_method::BackwardProp, model_info, batch_info, node)\n\nThis function propagates the bounds of the next node from the provided node  using the specified forward propagation method and layer operation. It invokes  propagate_layer_batch, which subsequently calls either  propagate_linear_batch or propagate_act_batch. The function identifies the  next node from the given node in the computational graph, model_info, its  bound, and the layer operation of the node. Then, propagate_layer_batch  ascertains if the layer operation is linear or includes activation functions  like ReLU. Depending on this, propagate_linear_batch or propagate_act_batch  is invoked.\n\nArguments\n\nprop_method (BackwardProp): Backward propagation method used for the    verification process. This is one of the solvers used to verify the given    model.\nmodel_info: Structure containing the information of the neural network to be    verified.\nbatch_info: Dictionary containing information of each node in the model.\nnode: The current node to be propagated through.\n\nReturns\n\nbatch_bound: List of reachable bounds after propagating the set of bounds in    batch_reach through the given node, following the propagation method and    the linear layer operation.\nnothing if the given node is a starting node of the model.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.propagate_linear_batch-Tuple{ModelVerification.ForwardProp, Any, AbstractArray, Any}","page":"Propagation","title":"ModelVerification.propagate_linear_batch","text":"propagate_linear_batch(prop_method::ForwardProp, layer, \n                       batch_reach::AbstractArray, batch_info)\n\nPropagates each of the bound in the batch_reach array with the given forward  propagation method, prop_method, through a linear layer. \n\nArguments\n\nprop_method (ForwardProp): Forward propagation method used for the    verification process. This is one of the solvers used to verify the given    model.\nlayer: Identifies what type of operation is done at the layer. Here, its a    linear operation.\nbatch_reach (AbstractArray): List of input specifications, i.e., bounds,     to be propagated through the given layer.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nbatch_reach_info: List of reachable bounds after propagating the set of    bounds in batch_reach through the given layer, following the propagation    method and the linear layer operation.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.propagate_act_batch-Tuple{ModelVerification.ForwardProp, Any, AbstractArray, Any}","page":"Propagation","title":"ModelVerification.propagate_act_batch","text":"propagate_act_batch(prop_method::ForwardProp, σ, \n                    batch_reach::AbstractArray, batch_info)\n\nPropagates each of the bound in the batch_reach array with the given forward  propagation method, prop_method, through an activation layer. \n\nArguments\n\nprop_method (ForwardProp): Forward propagation method used for the    verification process. This is one of the solvers used to verify the given    model.\nσ: Type of activation function, such as ReLU.\nbatch_reach (AbstractArray): List of input specifications, i.e., bounds,     to be propagated through the given layer.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nbatch_reach_info: List of reachable bounds after propagating the set of    bounds in batch_reach through the given layer, following the propagation    method and the activation layer operation.                        \n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.propagate_skip_batch-Tuple{ModelVerification.ForwardProp, Any, AbstractArray, AbstractArray, Any}","page":"Propagation","title":"ModelVerification.propagate_skip_batch","text":"propagate_skip_batch(prop_method::ForwardProp, layer, \n                     batch_reach1::AbstractArray, \n                     batch_reach2::AbstractArray, \n                     batch_info)\n\nPropagates each combination of the bounds from the batch_reach1 and  batch_reach2 arrays with the given forward propagation method, prop_method,  through a skip connection. \n\nArguments\n\nprop_method (ForwardProp): Forward propagation method used for the    verification process. This is one of the solvers used to verify the given    model.\nlayer: Identifies what type of operation is done at the layer. Here's a    bivariate operation is mainly used.\nbatch_reach1 (AbstractArray): First list of input specifications, i.e.,    bounds, to be propagated through the given layer. This is the list of    bounds given by the first of the two previous nodes.\nbatch_reach2 (AbstractArray): Second list of input specifications, i.e.,    bounds, to be propagated through the given layer. This is the list of    bounds given by the second of the two previous nodes.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nbatch_reach_info: List of reachable bounds after propagating the    bounds in batch_reach1 and batch_reach2 through the given layer,    following the propagation method and the layer operation.                         \n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.is_activation-Tuple{Any}","page":"Propagation","title":"ModelVerification.is_activation","text":"is_activation(l)\n\nReturns true if the given layer l is an activation layer.\n\nArguments\n\nl: Layer.\n\nReturns\n\nTrue if l is activation layer.\nFalse otherwise.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.propagate_layer_batch-NTuple{4, Any}","page":"Propagation","title":"ModelVerification.propagate_layer_batch","text":"propagate_layer_batch(prop_method, layer, batch_bound, batch_info)\n\nPropagates through one layer. The given layer identifies what type of  operation is performed. Operations such as Dense, BatchNorm, Convolution, and  ReLU are supported. The prop_method denotes the solver (and thus the geometric  representation for safety specification). The output of the propagation is the  bounds of the given batch. \n\nArguments\n\nprop_method: Propagation method used for the verification process. This is    one of the solvers used to verify the given model.\nlayer: Identifies what type of operation is done at the layer, such as    Dense, BatchNorm, Convolution, or ReLU.\nbatch_bound: Bound of the input node (the previous node).\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nbatch_bound: The output bound after applying the operation of the node.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.enqueue_nodes!-Tuple{ModelVerification.ForwardProp, Any, Any}","page":"Propagation","title":"ModelVerification.enqueue_nodes!","text":"enqueue_nodes!(prop_method::ForwardProp, queue, model_info)\n\nInserts the nodes connected from the starting node into the given queue for  ForwardProp methods.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.enqueue_nodes!-Tuple{ModelVerification.BackwardProp, Any, Any}","page":"Propagation","title":"ModelVerification.enqueue_nodes!","text":"enqueue_nodes!(prop_method::BackwardProp, queue, model_info)\n\nInserts the final nodes into the given queue for BackwardProp methods.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.output_node-Tuple{ModelVerification.ForwardProp, Any}","page":"Propagation","title":"ModelVerification.output_node","text":"output_node(prop_method::ForwardProp, model_info)\n\nReturns the final nodes of the model.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.next_nodes-Tuple{ModelVerification.ForwardProp, Any, Any}","page":"Propagation","title":"ModelVerification.next_nodes","text":"next_nodes(prop_method::ForwardProp,  model_info, node)\n\nReturns the next nodes of the node for ForwardProp methods.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.next_nodes-Tuple{ModelVerification.BackwardProp, Any, Any}","page":"Propagation","title":"ModelVerification.next_nodes","text":"next_nodes(prop_method::BackwardProp, model_info, node)\n\nReturns the previous nodes of the node for BackwardProp methods. Since this  is for BackwardProp methods, the previous nodes are the \"next\" nodes.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.prev_nodes-Tuple{ModelVerification.ForwardProp, Any, Any}","page":"Propagation","title":"ModelVerification.prev_nodes","text":"prev_nodes(prop_method::ForwardProp,  model_info, node)\n\nReturns the previous nodes of the node for ForwardProp methods.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.prev_nodes-Tuple{ModelVerification.BackwardProp, Any, Any}","page":"Propagation","title":"ModelVerification.prev_nodes","text":"prev_nodes(prop_method::BackwardProp, model_info, node)\n\nReturns the next nodes of the node for BackwardProp methods. Since this is  for BackwardProp methods, the next nodes are the \"previous\" nodes.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.all_nexts_in-NTuple{4, Any}","page":"Propagation","title":"ModelVerification.all_nexts_in","text":"all_nexts_in(prop_method, model_info, output_node, cnt)\n\nReturns true if all of the next nodes of the output_node have been visited.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.all_prevs_in-NTuple{4, Any}","page":"Propagation","title":"ModelVerification.all_prevs_in","text":"all_prevs_in(prop_method, model_info, output_node, cnt)\n\nReturns true if the output_node has been visited from all the previous nodes. This function checks if all possible connections to the output_node has been  made in the propagation procedure. For example, given a node X, say that there are 5 different nodes that are  mapped to X. Then, if the node X has been visited 5 times, i.e., cnt == 5,  it means that all the previous nodes of X has been outputted to X.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.has_two_reach_node-Tuple{Any, Any, Any}","page":"Propagation","title":"ModelVerification.has_two_reach_node","text":"has_two_reach_node(prop_method, model_info, node)\n\nChecks whether there are two nodes connected to the current node, i.e., there  are two previous nodes. This function is used to check if there are skip  connections.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#Bivariate","page":"Propagation","title":"Bivariate","text":"","category":"section"},{"location":"propagate.html","page":"Propagation","title":"Propagation","text":"Modules=[ModelVerification]\nPages=[\"bivariate.jl\"]","category":"page"},{"location":"propagate.html#ModelVerification.propagate_skip-Tuple{Any, typeof(+), ModelVerification.ImageStarBound, ModelVerification.ImageStarBound, Any}","page":"Propagation","title":"ModelVerification.propagate_skip","text":"propagate_skip(prop_method, layer::typeof(+), bound1::ImageStarBound, \n               bound2::ImageStarBound, batch_info)\n\nPropagate the bounds of the two input layers to the output layer for skip  connection. The output layer is of type ImageStarBound. The input layers'  centers, generators, and constraints are concatenated to form the output layer's  center, generators, and constraints.\n\nArguments\n\nprop_method (PropMethod): The propagation method used for the verification \n\nproblem.\n\nlayer (typeof(+)): The layer operation to be used for propagation.\nbound1 (ImageStarBound): The bound of the first input layer.\nbound2 (ImageStarBound): The bound of the second input layer.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nThe bound of the output layer represented in ImageStarBound type.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.propagate_skip-Tuple{Any, typeof(+), ModelVerification.ImageZonoBound, ModelVerification.ImageZonoBound, Any}","page":"Propagation","title":"ModelVerification.propagate_skip","text":"propagate_skip(prop_method, layer::typeof(+), bound1::ImageZonoBound, \n               bound2::ImageZonoBound, batch_info)\n\nPropagate the bounds of the two input layers to the output layer for skip  connection. The output layer is of type ImageZonoBound. The input layers'  centers and generators are concatenated to form the output layer's center and generators.\n\nArguments\n\nprop_method (PropMethod): The propagation method used for the verification    problem.\nlayer (typeof(+)): The layer operation to be used for propagation.\nbound1 (ImageZonoBound): The bound of the first input layer.\nbound2 (ImageZonoBound): The bound of the second input layer.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nThe bound of the output layer represented in ImageZonoBound type.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#Convolution","page":"Propagation","title":"Convolution","text":"","category":"section"},{"location":"propagate.html","page":"Propagation","title":"Propagation","text":"Modules=[ModelVerification]\nPages=[\"convolution.jl\"]","category":"page"},{"location":"propagate.html#ModelVerification.bound_layer-Tuple{Flux.Conv{2, 4, typeof(identity), Array{Float32, 4}, Vector{Float32}}, Vararg{AbstractArray, 4}}","page":"Propagation","title":"ModelVerification.bound_layer","text":"bound_layer(layer::Conv{2, 4, typeof(identity), \n                        Array{Float32, 4}, Vector{Float32}}, \n            lower_weight::AbstractArray, upper_weight::AbstractArray, \n            lower_bias::AbstractArray, upper_bias::AbstractArray)\n\nPropagates the bounds of weight and bias through a convolutional layer. It  applies the convolution operation with Conv to the weight and bias bounds: upper_weight, lower_weight, upper_bias, and lower_bias. \n\nArguments\n\nlayer (Conv): The convolutional layer to be used for propagation.\nlower_weight (AbstractArray): The lower bound of the weight.\nupper_weight (AbstractArray): The upper bound of the weight.\nlower_bias (AbstractArray): The lower bound of the bias.\nupper_bias (AbstractArray): The upper bound of the bias.\n\nReturns\n\nThe bounds of the weight and bias after convolution operation represented in    a tuple of [lowerweight, lowerbias, upperweight, upperbias].\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.bound_onside-Tuple{Flux.Conv{2, 4, typeof(identity), Array{Float32, 4}, Vector{Float32}}, AbstractArray, AbstractArray}","page":"Propagation","title":"ModelVerification.bound_onside","text":"bound_onside(layer::Conv{2, 4, typeof(identity), \n                        Array{Float32, 4}, Vector{Float32}}, \n             conv_input_size::AbstractArray, batch_reach::AbstractArray)\n\nTransforms the batch reachable set to the input size of the convolutional layer  using a ConvTranspose layer. First, it extracts the layer properties such as  weight, bias, and stride. Then, it computes the output bias by summing  over the batch reach and multiplying by the bias. Then, it flips the weights  horizontally and vertically. Then, it computes the padding needed for the output  based on the input size and the convolutional layer properties. Then, it creates  a ConvTranspose layer with the calculated parameters and applies it to the  batch reach. If additional padding is needed, it pads the output using the  PaddedView function.\n\nArguments\n\nlayer (Conv): The convolutional layer to be used for propagation.\nconv_input_size (AbstractArray): The size of the input to the convolutional    layer.\nbatch_reach (AbstractArray): The batch reachable set of the input to the    convolutional layer.\n\nReturns\n\nThe batch reachable set and batch bias in dimension equal to the input size of    the convolutional layer.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.interval_propagate","page":"Propagation","title":"ModelVerification.interval_propagate","text":"interval_propagate(layer::Conv{2, 4, typeof(identity), \n                               Array{Float32, 4}, Vector{Float32}}, \n                   interval, C = nothing)\n\nPropagates the interval bounds through a convolutional layer. This is used in  the interval arithmetic for neural network verification, where the goal is to  compute the range of possible output values given a range of input values,  represented with interval. It applies the convolution operation with Conv  to the center of the interval and the deviation of the interval.\n\nArguments\n\nlayer (Conv): The convolutional layer to be used for propagation.\ninterval (Tuple): The interval bounds of the input to the convolutional    layer.\nC (nothing): Optional argument for the center of the interval, default is    nothing.\n\nReturns\n\nThe interval bounds after convolution operation represented in an array of    [lower, upper, C = nothing].\n\n\n\n\n\n","category":"function"},{"location":"propagate.html#ModelVerification.propagate_by_small_batch-Tuple{Any, Any}","page":"Propagation","title":"ModelVerification.propagate_by_small_batch","text":"propagate_by_small_batch(f, x; sm_batch=500)\n\nPropagate the input x through f by small batches. This is useful when the  input x is too large to fit into GPU memory.\n\nArguments\n\nf (function): Function to be applied to the input x.\nx (AbstractArray): Input to be propagated through f.\nsm_batch (Int): Optional argument for the size of the small batch, default    is 500.\n\nReturns\n\nOutput of f applied to the input x.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.propagate_linear-Tuple{ImageStar, Flux.Conv, ModelVerification.ImageStarBound, Any}","page":"Propagation","title":"ModelVerification.propagate_linear","text":"propagate_linear(prop_method::ImageStar, layer::Conv, \n                 bound::ImageStarBound, batch_info)\n\nPropagate the ImageStarBound bound through a convolution layer. I.e., it  applies the convolution operation to the ImageStarBound bound. The convolution  operation is applied to both the center and the generators of the  ImageStarBound bound. Using the Flux.Conv, a convolutional layer is made in  Flux with the given layer properties. While cen_Conv (convolutional layer  for the center image) uses the bias, the gen_Conv (convolutional layer for the  generators) does not. The resulting bound is also of type ImageStarBound.\n\nArguments\n\nprop_method (ImageStar): The ImageStar propagation method used for the    verification problem.\nlayer (Conv): The convolution operation to be used for propagation.\nbound (ImageStarBound): The bound of the input node.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nThe convolved bound of the output layer represented in ImageStarBound type.                     \n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.propagate_linear-Tuple{ImageStar, Flux.ConvTranspose, ModelVerification.ImageStarBound, Any}","page":"Propagation","title":"ModelVerification.propagate_linear","text":"propagate_linear(prop_method::ImageStar, layer::ConvTranspose, \n                 bound::ImageStarBound, batch_info)\n\nPropagate the ImageStarBound bound through a convolutional transpose layer.  I.e., it applies the convolutional transpose operation to the ImageStarBound  bound. While a regular convolution reduces the spatial dimensions of an input, a  convolutional transpose expands the spatial dimensions of an input. The convolutional transpose operation is applied to both the center and  the generators of the ImageStarBound bound. Using the Flux.ConvTranspose, a  convolutional tranpose layer is made in Flux with the given layer  properties. While cen_Conv (convolutional transpose layer for the center  image) uses the bias, the gen_Conv (convolutional transpose layer for the  generators) does not. The resulting bound is also of type ImageStarBound.\n\nArguments\n\nprop_method (ImageStar): The ImageStar propagation method used for the    verification problem.\nlayer (ConvTranspose): The convolutional transpose operation to be used    for propagation.\nbound (ImageStarBound): The bound of the input node.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nThe convolved bound of the output layer represented in ImageStarBound type.                          \n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.propagate_linear-Tuple{ImageZono, Flux.ConvTranspose, ModelVerification.ImageZonoBound, Any}","page":"Propagation","title":"ModelVerification.propagate_linear","text":"propagate_linear(prop_method::ImageZono, layer::ConvTranspose, \n                 bound::ImageZonoBound, batch_info)\n\nPropagate the ImageZonoBound bound through a convolutional transpose layer.  I.e., it applies the convolutional transpose operation to the ImageZonoBound  bound. While a regular convolution reduces the spatial dimensions of an input, a  convolutional transpose expands the spatial dimensions of an input. The convolutional transpose operation is applied to both the center and  the generators of the ImageZonoBound bound. Using the Flux.ConvTranspose, a  convolutional tranpose layer is made in Flux with the given layer  properties. While cen_Conv (convolutional transpose layer for the center  image) uses the bias, the gen_Conv (convolutional transpose layer for the  generators) does not. The resulting bound is also of type ImageZonoBound.\n\nArguments\n\nprop_method (ImageZono): The ImageZono propagation method used for the    verification problem.\nlayer (ConvTranspose): The convolutional transpose operation to be used    for propagation.\nbound (ImageZonoBound): The bound of the input node.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nThe convolved bound of the output layer represented in ImageZonoBound type.              \n\n\n\n\n\n","category":"method"},{"location":"propagate.html#Dense","page":"Propagation","title":"Dense","text":"","category":"section"},{"location":"propagate.html","page":"Propagation","title":"Propagation","text":"Modules=[ModelVerification]\nPages=[\"dense.jl\"]","category":"page"},{"location":"propagate.html#ModelVerification._preprocess","page":"Propagation","title":"ModelVerification._preprocess","text":"_preprocess(node, batch_info, bias = nothing)\n\nPreprocesses the bias of the given node for the BetaCrown solver. If the bias is not nothing, it multiplies the bias with the beta value of the node.\n\nArguments\n\nnode: Node of the model.\nbatch_info: Dictionary containing information of each node in the model.\nbias: Bias of the node, default is nothing.\n\nReturns\n\nbias: Preprocessed bias of the node.\n\n\n\n\n\n","category":"function"},{"location":"propagate.html#ModelVerification.batch_interval_map-Union{Tuple{N}, Tuple{AbstractMatrix{N}, AbstractArray, AbstractArray}} where N","page":"Propagation","title":"ModelVerification.batch_interval_map","text":"batch_interval_map(W::AbstractMatrix{N}, l::AbstractArray, \n                   u::AbstractArray) where N\n\nClamps the input to the given bounds and computes the interval map of the  resulting bound using the given weight matrix.\n\nArguments\n\nW (AbstractMatrix{N}): Weight matrix of the layer.\nl (AbstractArray): Lower bound of the input.\nu (AbstractArray): Upper bound of the input.\n\nReturns\n\nTuple of:\n\nl_new (AbstractArray): Lower bound of the output.\nu_new (AbstractArray): Upper bound of the output.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.dense_bound_oneside-NTuple{4, Any}","page":"Propagation","title":"ModelVerification.dense_bound_oneside","text":"dense_bound_oneside(last_A, weight, bias, batch_size)\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.propagate_linear-Tuple{Box, Flux.Dense, LazySets.LazySet, Any}","page":"Propagation","title":"ModelVerification.propagate_linear","text":"propagate_linear(prop_method::Box, layer::Dense, reach::LazySet, batch_info)\n\nPropagate the bounds through the dense layer for Ai2 Box solver. It operates  an approximate affine transformation (affine transformation using hyperrectangle  overapproximation) on the given input bound and returns the output bound. \n\nArguments\n\nprop_method (Box): Ai2 Box solver used for the verification process.\nlayer (Dense): Dense layer of the model.\nreach (LazySet): Bound of the input.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nreach (hyperrectangle): Bound of the output after approximate affine    transformation.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.propagate_linear-Tuple{ExactReach, Flux.Dense, ModelVerification.ExactReachBound, Any}","page":"Propagation","title":"ModelVerification.propagate_linear","text":"propagate_linear(prop_method::ExactReach, layer::Dense, \n                 reach::ExactReachBound, batch_info)\n\nPropagate the bounds through the dense layer. It operates an affine  transformation on the given input bound and returns the output bound for  ExactReach solver.\n\nArguments\n\nprop_method (ExactReach): Exact reachability method used for the    verification process. This is one of the solvers used to verify the given    model.\nlayer (Dense): Dense layer of the model.\nreach (ExactReachBound): Bound of the input, represented by    ExactReachBound type, which is a vector of LazySet type.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nreach (ExactReachBound): Bound of the output after affine transformation,    which is represented by ExactReachBound type.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.propagate_linear-Tuple{ModelVerification.ForwardProp, Flux.Dense, LazySets.LazySet, Any}","page":"Propagation","title":"ModelVerification.propagate_linear","text":"propagate_linear(prop_method::ForwardProp, layer::Dense, \n                 reach::LazySet, batch_info)\n\nPropagate the bounds through the dense layer. It operates an affine  transformation on the given input bound and returns the output bound.\n\nArguments\n\nprop_method (ForwardProp): Forward propagation method used for the    verification process. This is one of the solvers used to verify the given    model.                  \nlayer (Dense): Dense layer of the model.\nreach (LazySet): Bound of the input.\nbatch_info: Dictionary containing information of each node in the    model.\n\nReturns\n\nreach (LazySet): Bound of the output after affine transformation.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.propagate_linear_batch-Tuple{BetaCrown, Flux.Dense, ModelVerification.BetaCrownBound, Any}","page":"Propagation","title":"ModelVerification.propagate_linear_batch","text":"propagate_linear_batch(prop_method::BetaCrown, layer::Dense, \n                       bound::BetaCrownBound, batch_info)\n\nPropagates the bounds through the dense layer for BetaCrown solver. It  operates an affine transformation on the given input bound and returns the output bound. It first preprocesses the lower- and upper-bounds of the bias of  the node using _preprocess. Then, it computes the interval map of the  resulting lower- and upper-bounds using dense_bound_oneside function. The  resulting bound is represented by BetaCrownBound type.\n\nArguments\n\nprop_method (BetaCrown): BetaCrown solver used for the verification    process.\nlayer (Dense): Dense layer of the model.\nbound (BetaCrownBound): Bound of the input, represented by    BetaCrownBound type.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nNew_bound (BetaCrownBound): Bound of the output after affine    transformation, which is represented by BetaCrownBound type.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.propagate_linear_batch-Tuple{Crown, Flux.Dense, ModelVerification.CrownBound, Any}","page":"Propagation","title":"ModelVerification.propagate_linear_batch","text":"propagate_linear_batch(prop_method::Crown, layer::Dense, \n                       bound::CrownBound, batch_info)\n\nPropagates the bounds through the dense layer for Crown solver. It operates an affine transformation on the given input bound and returns the output bound. It first clamps the input bound and multiplies with the weight matrix using  batch_interval_map function. Then, it adds the bias to the output bound. The resulting bound is represented by CrownBound type.\n\nArguments\n\nprop_method (Crown): Crown solver used for the verification process.\nlayer (Dense): Dense layer of the model.\nbound (CrownBound): Bound of the input, represented by CrownBound type.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nnew_bound (CrownBound): Bound of the output after affine transformation,    which is represented by CrownBound type.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#Identity","page":"Propagation","title":"Identity","text":"","category":"section"},{"location":"propagate.html","page":"Propagation","title":"Propagation","text":"Modules=[ModelVerification]\nPages=[\"identity.jl\"]","category":"page"},{"location":"propagate.html#ModelVerification.propagate_act-Tuple{Any, typeof(identity), Any, Any}","page":"Propagation","title":"ModelVerification.propagate_act","text":"propagate_act(prop_method, σ::typeof(identity), bound, batch_info)\n\nPropagate the bounds through the identity activation layer.\n\nArguments\n\nprop_method: Propagation method.\nσ: Identity activation function.\nbound: Bounds of the input.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nbound: Bounds of the output, which is equivalent to the bounds of the input.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#Normalise","page":"Propagation","title":"Normalise","text":"","category":"section"},{"location":"propagate.html","page":"Propagation","title":"Propagation","text":"Modules=[ModelVerification]\nPages=[\"normalise.jl\"]","category":"page"},{"location":"propagate.html#ModelVerification.propagate_linear-Tuple{ImageStar, Flux.BatchNorm, ModelVerification.ImageStarBound, Any}","page":"Propagation","title":"ModelVerification.propagate_linear","text":"propagate_linear(prop_method::ImageStar, layer::BatchNorm, \n                 bound::ImageStarBound, batch_info)\n\nPropagate the ImageStarBound bound through a batch norm layer. I.e., it  applies the batch norm operation to the ImageStarBound bound. The batch norm  operation is decomposed into two operations: centering and scaling. The  centering operation is applied to the center of the ImageStarBound bound. The scaling operation is applied to the generators of the ImageStarBound bound. The resulting bound is also of type ImageStarBound.\n\nArguments\n\nprop_method (ImageStar): The ImageStar propagation method used for the    verification problem.\nlayer (BatchNorm): The batch norm operation to be used for propagation.\nbound (ImageStarBound): The bound of the input node.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nThe batch normed bound of the output layer represented in ImageStarBound    type.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.propagate_linear-Tuple{ImageZono, Flux.BatchNorm, ModelVerification.ImageZonoBound, Any}","page":"Propagation","title":"ModelVerification.propagate_linear","text":"propagate_linear(prop_method::ImageZono, layer::BatchNorm, \n                 bound::ImageZonoBound, batch_info)\n\nPropagate the ImageZonoBound bound through a batch norm layer. I.e., it  applies the batch norm operation to the ImageZonoBound bound. The batch norm  operation is decomposed into two operations: centering and scaling. The  centering operation is applied to the center of the ImageZonoBound bound. The scaling operation is applied to the generators of the ImageZonoBound bound. The resulting bound is also of type ImageZonoBound.\n\nArguments\n\nprop_method (ImageZono): The ImageZono propagation method used for the    verification problem.\nlayer (BatchNorm): The batch norm operation to be used for propagation.\nbound (ImageZonoBound): The bound of the input node.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nThe batch normed bound of the output layer represented in ImageZonoBound    type.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.propagate_linear_batch-Tuple{Flux.BatchNorm, AbstractArray, Any}","page":"Propagation","title":"ModelVerification.propagate_linear_batch","text":"propagate_linear_batch(layer::BatchNorm, batch_reach::AbstractArray, \n                       batch_info)\n\nPropagate the batch_reach through a batch norm layer. I.e., it applies the  batch norm operation to the batch_reach. The batch norm operation is  decomposed into two operations: centering and scaling. This function supports  input batch with channel dimension.\n\nArguments\n\nlayer (BatchNorm): The batch norm operation to be used for propagation.\nbatch_reach (AbstractArray): The batch of input bounds.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nThe batch normed bound of the output layer.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ReLU","page":"Propagation","title":"ReLU","text":"","category":"section"},{"location":"propagate.html","page":"Propagation","title":"Propagation","text":"Modules=[ModelVerification]\nPages=[\"relu.jl\"]","category":"page"},{"location":"propagate.html#ModelVerification.ImageStar_to_Star-Tuple{ModelVerification.ImageStarBound}","page":"Propagation","title":"ModelVerification.ImageStar_to_Star","text":"ImageStar_to_Star(bound::ImageStarBound)\n\nConvert the ImageStarBound bound to Star bound.\n\nArguments\n\nbound (ImageStarBound): The bound of the input node, represented using    ImageStarBound type.\n\nReturns\n\nThe bound represented using Star type.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.Star_to_ImageStar-Tuple{LazySets.Star, Any}","page":"Propagation","title":"ModelVerification.Star_to_ImageStar","text":"Star_to_ImageStar(bound::Star, sz)\n\nConverts the Star bound to ImageStarBound bound.\n\nArguments\n\nbound (Star): The bound of the input node, represented using Star type.\nsz: The size of the input image, i.e., the target size.\n\nReturns\n\nThe bound represented using ImageStarBound type.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.bound_oneside-Tuple{Any, Any, Any}","page":"Propagation","title":"ModelVerification.bound_oneside","text":"bound_oneside(last_A, slope_pos, slope_neg)\n\nBound the ReLU activation function from one side, such as upper or lower.\n\nArguments\n\nlast_A: The last layer's activation.\nslope_pos: The slope of the ReLU activation function from the positive side.\nslope_neg: The slope of the ReLU activation function from the negative side.\n\nReturns\n\nThe bound of the ReLU activation function from one side.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.fast_overapproximate-Union{Tuple{N}, Tuple{LazySets.Rectification{N, <:LazySets.AbstractZonotope}, Type{<:LazySets.Zonotope}}} where N","page":"Propagation","title":"ModelVerification.fast_overapproximate","text":"fast_overapproximate(r::Rectification{N,<:AbstractZonotope}, \n                     ::Type{<:Zonotope}) where {N}\n\nComputes the overapproximation of the rectified set r using a Zonotope.\n\nArguments\n\nr (Rectification): The rectified set.\n::Type{<:Zonotope}: The type of the overapproximation, default is    Zonotope.\n\nReturns\n\nThe overapproximation of the rectified set r using a Zonotope.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.multiply_by_A_signs-Tuple{Any, Any, Any}","page":"Propagation","title":"ModelVerification.multiply_by_A_signs","text":"multiply_by_A_signs(last_A, slope_pos, slope_neg)\n\nMultiply the last layer's activation by the sign of the slope of the ReLU  activation function. This is for BetaLayer propagation method. \n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.partition_relu-Tuple{Any}","page":"Propagation","title":"ModelVerification.partition_relu","text":"partition_relu(bound)\n\nPartition the bound into multiple VPolytope objects, each of which is the  intersection of the bound and an orthant. The resulting VPolytope objects  are stored in an array. This is for ReLU propagations in ExactReach solver. Thus, the resulting VPolytope objects are the outputs of rectifying the input  bound. The dimension of the bound must be less than 30, since otherwise the  number of output sets will be too large.\n\nArguments\n\nbound: The bound of the input node.\n\nReturns\n\nAn array of partitioned bounds represented using VPolytope type.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.propagate_act-Tuple{Any, typeof(NNlib.relu), LazySets.Star, Any}","page":"Propagation","title":"ModelVerification.propagate_act","text":"propagate_act(prop_method, layer::typeof(relu), bound::Star, batch_info)\n\nPropagate the Star bound through a ReLU layer. I.e., it applies the ReLU  operation to the Star bound. The resulting bound is also of type Star. This  is for Star propagation methods.\n\nArguments\n\nprop_method: The propagation method used for the verification problem.\nlayer (typeof(relu)): The ReLU operation to be used for propagation.\nbound (Star): The bound of the input node, represented using Star type.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nthe relued bound of the output represented in Star type.\n\nReference\n\n[1] HD. Tran, S. Bak, W. Xiang, and T.T. Johnson, \"Verification of Deep Convolutional  Neural Networks Using ImageStars,\" in Computer Aided Verification (CAV), 2020.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.propagate_act-Tuple{Any, typeof(NNlib.relu), ModelVerification.ImageStarBound, Any}","page":"Propagation","title":"ModelVerification.propagate_act","text":"propagate_act(prop_method, layer::typeof(relu), \n              bound::ImageStarBound, batch_info)\n\nPropagate the ImageStarBound bound through a ReLU layer. I.e., it applies  the ReLU operation to the ImageStarBound bound. The resulting bound is also  of type ImageStarBound. This is for ImageStar propagation method. It  converts the input bound to Star type, calls propagate_act that propagates  the Star bound through a ReLU layer, and converts the resulting bound back to  ImageStarBound.\n\nArguments\n\nprop_method: The propagation method used for the verification problem.\nlayer (typeof(relu)): The ReLU operation to be used for propagation.\nbound (ImageStarBound): The bound of the input node, represented using    ImageStarBound type.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nThe relued bound of the output represented in ImageStarBound type.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.propagate_act-Tuple{Any, typeof(NNlib.relu), ModelVerification.ImageZonoBound, Any}","page":"Propagation","title":"ModelVerification.propagate_act","text":"propagate_act(prop_method, layer::typeof(relu), \n              bound::ImageZonoBound, batch_info)\n\nPropagate the ImageZonoBound bound through a ReLU layer. I.e., it applies  the ReLU operation to the ImageZonoBound bound. The resulting bound is also  of type ImageZonoBound. This is for ImageZono propagation method. It  flattens the input bound into a Zonotope and calls fast_overapproximate that  computes the overapproximation of the rectified set using a Zonotope. It then  converts the resulting Zonotope back to ImageZonoBound.\n\nArguments\n\nprop_method: The propagation method used for the verification problem.\nlayer (typeof(relu)): The ReLU operation to be used for propagation.\nbound (ImageZonoBound): The bound of the input node, represented using    ImageZonoBound type.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nthe relued bound of the output represented in ImageZonoBound type.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.propagate_act-Tuple{Box, typeof(NNlib.relu), LazySets.AbstractPolytope, Any}","page":"Propagation","title":"ModelVerification.propagate_act","text":"propagate_act(prop_method::Box, layer::typeof(relu), \n              reach::AbstractPolytope, batch_info)\n\nPropagate the AbstractPolytope bound through a ReLU layer. I.e., it applies  the ReLU operation to the AbstractPolytope bound. The resulting bound is also  of type AbstractPolytope. This is for Ai2's Box propagation method. It calls  rectify that rectifies the input bound.\n\nArguments\n\nprop_method (Box): The propagation method used for the verification    problem.\nlayer (typeof(relu)): The ReLU operation to be used for propagation.\nreach (AbstractPolytope): The bound of the input node.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nthe relued bound of the output represented in AbstractPolytope type.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.propagate_act-Tuple{ExactReach, typeof(NNlib.relu), ModelVerification.ExactReachBound, Any}","page":"Propagation","title":"ModelVerification.propagate_act","text":"propagate_act(prop_method::ExactReach, layer::typeof(relu), \n              reach::ExactReachBound, batch_info)\n\nPropagate the ExactReachBound bound through a ReLU layer. I.e., it applies  the ReLU operation to the ExactReachBound bound. The resulting bound is also  of type ExactReachBound. This is for ExactReach propagation method. It calls partition_relu that partitions the resulting rectified bound into  multiple VPolytope objects, each of which is the intersection of the resulting  bound and an orthant. The resulting VPolytope objects are vertically  concatenated and stored in an ExactReachBound object.\n\nArguments\n\nprop_method (ExactReach): The propagation method used for the verification    problem.\nlayer (typeof(relu)): The ReLU operation to be used for propagation.\nreach (ExactReachBound): The bound of the input node, represented using    ExactReachBound type.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nthe relued bound of the output represented in ExactReachBound type.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.propagate_act-Tuple{Union{ImageZono, Ai2z}, typeof(NNlib.relu), LazySets.AbstractPolytope, Any}","page":"Propagation","title":"ModelVerification.propagate_act","text":"propagate_act(prop_method::Union{Ai2z, ImageZono}, layer::typeof(relu), \n              reach::AbstractPolytope, batch_info)\n\nPropagate the AbstractPolytope bound through a ReLU layer. I.e., it applies  the ReLU operation to the AbstractPolytope bound. The resulting bound is also of type AbstractPolytope. This is for either Ai2z or ImageZono propagation  methods, which both use Zonotope-like representation for the safety  specifications. After rectifying the input bound, it overapproximates the  resulting bound using a Zonotope.\n\nArguments\n\nprop_method (Union{Ai2z, ImageZono}): The propagation method used for the    verification problem. It can be either Ai2z or ImageZono, which both use    Zonotope-like representation for the safety specifications.\nlayer (typeof(relu)): The ReLU operation to be used for propagation.\nreach (AbstractPolytope): The bound of the input node.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nthe relued bound of the output represented in Zonotope type.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.propagate_act_batch-Tuple{Crown, typeof(NNlib.relu), ModelVerification.CrownBound, Any}","page":"Propagation","title":"ModelVerification.propagate_act_batch","text":"propagate_act_batch(prop_method::Crown, layer::typeof(relu), \n                    bound::CrownBound, batch_info)\n\nPropagate the CrownBound bound through a ReLU layer.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.relu_upper_bound-Tuple{Any, Any}","page":"Propagation","title":"ModelVerification.relu_upper_bound","text":"relu_upper_bound(lower, upper)\n\nCompute the upper bound slope and intercept according to CROWN relaxation. \n\nArguments\n\nlower: The lower bound of the input node, pre-ReLU operation.\nupper: The upper bound of the input node, pre-ReLU operation.\n\nReturns\n\nThe upper bound slope and intercept according to CROWN relaxation.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#Stateless","page":"Propagation","title":"Stateless","text":"","category":"section"},{"location":"propagate.html","page":"Propagation","title":"Propagation","text":"Modules=[ModelVerification]\nPages=[\"stateless.jl\"]","category":"page"},{"location":"propagate.html#ModelVerification.propagate_linear-Tuple{Any, Flux.MeanPool, ModelVerification.ImageStarBound, Any}","page":"Propagation","title":"ModelVerification.propagate_linear","text":"propagate_linear(prop_method, layer::MeanPool, \n                 bound::ImageStarBound, batch_info)\n\nPropagate the ImageStarBound bound through a mean pool layer. I.e., it applies the mean pool operation to the ImageStarBound bound. The resulting bound is  also of type ImageStarBound.\n\nArguments\n\nprop_method: The propagation method used for the verification problem.\nlayer (MeanPool): The mean pool operation to be used for propagation.\nbound (ImageStarBound): The bound of the input node.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nThe mean pooled bound of the output layer represented in ImageStarBound    type.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.propagate_linear-Tuple{Any, Flux.MeanPool, ModelVerification.ImageZonoBound, Any}","page":"Propagation","title":"ModelVerification.propagate_linear","text":"propagate_linear(prop_method, layer::MeanPool, \n                 bound::ImageZonoBound, batch_info)\n\nPropagate the ImageZonoBound bound through a mean pool layer. I.e., it applies the mean pool operation to the ImageZonoBound bound. The resulting bound is  also of type ImageZonoBound.\n\nArguments\n\nprop_method: The propagation method used for the verification problem.\nlayer (MeanPool): The mean pool operation to be used for propagation.\nbound (ImageZonoBound): The bound of the input node.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nThe mean pooled bound of the output layer represented in ImageZonoBound    type.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.propagate_linear-Tuple{Any, typeof(Flux.flatten), ModelVerification.ImageStarBound, Any}","page":"Propagation","title":"ModelVerification.propagate_linear","text":"propagate_linear(prop_method, layer::typeof(flatten), \n                 bound::ImageStarBound, batch_info)\n\nPropagate the ImageStarBound bound through a flatten layer. I.e., it flattens  the ImageStarBound into a Star type.\n\nArguments\n\nprop_method: The propagation method used for the verification problem.\nlayer (typeof(flatten)): The layer operation to be used for propagation.\nbound (ImageStarBound): The bound of the input node.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nThe flattened bound of the output layer represented in Star type.\n\n\n\n\n\n","category":"method"},{"location":"propagate.html#ModelVerification.propagate_linear-Tuple{Any, typeof(Flux.flatten), ModelVerification.ImageZonoBound, Any}","page":"Propagation","title":"ModelVerification.propagate_linear","text":"propagate_linear(prop_method, layer::typeof(flatten), \n                 bound::ImageZonoBound, batch_info)\n\nPropagate the ImageZonoBound bound through a flatten layer. I.e., it flattens  the ImageZonoBound into a Zonotope type.\n\nArguments\n\nprop_method: The propagation method used for the verification problem.\nlayer (typeof(flatten)): The layer operation to be used for propagation.\nbound (ImageZonoBound): The bound of the input node.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nThe flattened bound of the output layer represented in Zonotope type.\n\n\n\n\n\n","category":"method"},{"location":"about.html#About","page":"About","title":"About","text":"","category":"section"},{"location":"about.html","page":"About","title":"About","text":"This toolbox is developed by the Intelligent Control Lab at the Robotics Institute at Carnegie Mellon University. It is an extension of the NeuralVerification.jl.","category":"page"},{"location":"about.html#Credit","page":"About","title":"Credit","text":"","category":"section"},{"location":"about.html#Developers","page":"About","title":"Developers","text":"","category":"section"},{"location":"about.html","page":"About","title":"About","text":"Changliu Liu, Carnegie Mellon University\nTianhao Wei, Carnegie Mellon University","category":"page"},{"location":"about.html#Contributors","page":"About","title":"Contributors","text":"","category":"section"},{"location":"about.html","page":"About","title":"About","text":"Luca Marzari, Carnegie Mellon University\nKai Yun, Carnegie Mellon University","category":"page"},{"location":"about.html#Acknowledgements","page":"About","title":"Acknowledgements","text":"","category":"section"},{"location":"solvers.html","page":"Solvers","title":"Solvers","text":"CurrentModule = ModelVerification","category":"page"},{"location":"solvers.html","page":"Solvers","title":"Solvers","text":"Pages=[\"solvers.md\"]\nDepth = 3","category":"page"},{"location":"solvers.html#Solvers","page":"Solvers","title":"Solvers","text":"","category":"section"},{"location":"solvers.html","page":"Solvers","title":"Solvers","text":"For most of the functions below, each solver has a unique dispatch defined.","category":"page"},{"location":"solvers.html#Variations-of-propagation-methods","page":"Solvers","title":"Variations of propagation methods","text":"","category":"section"},{"location":"solvers.html","page":"Solvers","title":"Solvers","text":"All the solvers are based on one of the following propagation methods.","category":"page"},{"location":"solvers.html","page":"Solvers","title":"Solvers","text":"PropMethod\nForwardProp\nBackwardProp\nSequentialForwardProp\nSequentialBackwardProp\nBatchForwardProp\nBatchBackwardProp","category":"page"},{"location":"solvers.html#ModelVerification.PropMethod","page":"Solvers","title":"ModelVerification.PropMethod","text":"PropMethod\n\nAlgorithm to propagate the bounds through the computational graph. This is the  super-type for all the \"solvers\" used in the verification process, and is  different from the functions defined in propagate folder. In other words,  the PropMethod should be understood as the \"solver\" used in the verification  process, while the functions in propagate folder are the \"propagation\"  functions used in the verification process. The solvers include methods such as  Ai2 and Crown. For an example, see the documentation on Ai2.\n\n\n\n\n\n","category":"type"},{"location":"solvers.html#ModelVerification.ForwardProp","page":"Solvers","title":"ModelVerification.ForwardProp","text":"ForwardProp <: PropMethod\n\nAbstract type representing solvers that use forward propagation.\n\n\n\n\n\n","category":"type"},{"location":"solvers.html#ModelVerification.BackwardProp","page":"Solvers","title":"ModelVerification.BackwardProp","text":"BackwardProp <: PropMethod\n\nAbstract type representing solvers that use backward propagation.\n\n\n\n\n\n","category":"type"},{"location":"solvers.html#ModelVerification.SequentialForwardProp","page":"Solvers","title":"ModelVerification.SequentialForwardProp","text":"SequentialForwardProp <: ForwardProp\n\n\n\n\n\n","category":"type"},{"location":"solvers.html#ModelVerification.SequentialBackwardProp","page":"Solvers","title":"ModelVerification.SequentialBackwardProp","text":"SequentialBackwardProp <: ForwardProp\n\n\n\n\n\n","category":"type"},{"location":"solvers.html#ModelVerification.BatchForwardProp","page":"Solvers","title":"ModelVerification.BatchForwardProp","text":"BatchForwardProp <: ForwardProp\n\n\n\n\n\n","category":"type"},{"location":"solvers.html#ModelVerification.BatchBackwardProp","page":"Solvers","title":"ModelVerification.BatchBackwardProp","text":"BatchBackwardProp <: BackwardProp\n\n\n\n\n\n","category":"type"},{"location":"solvers.html#Bound-types","page":"Solvers","title":"Bound types","text":"","category":"section"},{"location":"solvers.html","page":"Solvers","title":"Solvers","text":"The bounds are based on the following abstract type Bound.","category":"page"},{"location":"solvers.html","page":"Solvers","title":"Solvers","text":"Bound","category":"page"},{"location":"solvers.html#ModelVerification.Bound","page":"Solvers","title":"ModelVerification.Bound","text":"Bound\n\nAbstract type representing bounds.\n\n\n\n\n\n","category":"type"},{"location":"solvers.html#Preprocessing-for-the-solver","page":"Solvers","title":"Preprocessing for the solver","text":"","category":"section"},{"location":"solvers.html","page":"Solvers","title":"Solvers","text":"prepare_method is the first step called in search_branches. It initializes the bounds of the start node of the computational graph based on the given branch and the geometric representation used by the solver, which is specified with the prop_method. For each solver, there is a unique prepare_method defined. For more information, refer to the documentation for each solver.","category":"page"},{"location":"solvers.html","page":"Solvers","title":"Solvers","text":"prepare_method(prop_method::PropMethod, batch_input::AbstractVector, batch_output::AbstractVector, model_info)","category":"page"},{"location":"solvers.html#ModelVerification.prepare_method-Tuple{PropMethod, AbstractVector, AbstractVector, Any}","page":"Solvers","title":"ModelVerification.prepare_method","text":"prepare_method(prop_method::PropMethod, batch_input::AbstractVector, batch_output::AbstractVector, model_info)\n\nInitialize the bound of the start node of the computational graph based on the  solver (prop_method).\n\nAgruments\n\nprop_method (PropMethod): Propagation method, i.e., the solver.\nbatch_input (AbstractVector): Batch of inputs.\nbatch_output (AbstractVector): Batch of outputs.\nmodel_info: Structure containing the information of the neural network to   be verified.\n\nReturns\n\nbatch_output: Batch of outputs.\nbatch_info: Dictionary containing information of each node in the model.\n\n\n\n\n\n","category":"method"},{"location":"solvers.html","page":"Solvers","title":"Solvers","text":"The following functions are used to retrieve information regarding each node in the model.","category":"page"},{"location":"solvers.html","page":"Solvers","title":"Solvers","text":"init_propagation(prop_method::ForwardProp, batch_input, batch_output, model_info)\ninit_propagation(prop_method::BackwardProp, batch_input, batch_output, model_info)","category":"page"},{"location":"solvers.html#ModelVerification.init_propagation-Tuple{ModelVerification.ForwardProp, Any, Any, Any}","page":"Solvers","title":"ModelVerification.init_propagation","text":"init_propagation(prop_method::ForwardProp, batch_input, batch_output, model_info)\n\nReturns a dictionary containing the information of each node in the model. This  function is for ForwardProp solvers, and is mainly concerned with initializing  the dictionary, batch_info, and populating it with the initial bounds for the  starting node. For the starting node of the model, the :bound key is mapped  to the list of input specifications.\n\nArguments\n\nprop_method (ForwardProp): Solver that uses forward propagation.\nbatch_input: List of inputs.\nbatch_output: List of outputs.\nmodel_info: Structure containing the information of the neural network to    be verified.\n\nReturns\n\nbatch_info: Dictionary containing information of each node in the model.\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.init_propagation-Tuple{ModelVerification.BackwardProp, Any, Any, Any}","page":"Solvers","title":"ModelVerification.init_propagation","text":"init_propagation(prop_method::BackwardProp, batch_input, batch_output, model_info)\n\nReturns a dictionary containing the information of each node in the model. This  function is for BackwardProp solvers, and is mainly concerned with  initializing the dictionary, batch_info, and populating it with the initial  bounds for the starting node. For the starting node of the model, the :bound  key is mapped to the list of input specifications.\n\nArguments\n\nprop_method (BackwardProp): Solver that uses backward propagation.\nbatch_input: List of inputs.\nbatch_output: List of outputs.\nmodel_info: Structure containing the information of the neural network to    be verified.\n\nReturns\n\nbatch_info: Dictionary containing information of each node in the model.\n\n\n\n\n\n","category":"method"},{"location":"solvers.html","page":"Solvers","title":"Solvers","text":"The following functions are used to either retrieve or process the safety specification.","category":"page"},{"location":"solvers.html","page":"Solvers","title":"Solvers","text":"init_batch_bound(prop_method::ForwardProp, batch_input, batch_output)\ninit_batch_bound(prop_method::BackwardProp, batch_input, batch_output)\ninit_bound(prop_method::ForwardProp, input)\ninit_bound(prop_method::BackwardProp, output)\nprocess_bound","category":"page"},{"location":"solvers.html#ModelVerification.init_batch_bound-Tuple{ModelVerification.ForwardProp, Any, Any}","page":"Solvers","title":"ModelVerification.init_batch_bound","text":"init_batch_bound(prop_method::ForwardProp, batch_input, batch_output)\n\nReturns a list of the input specifications (geometries) for the given batch of  inputs. This is for ForwardProp solvers. Each input specification is  processed to fit the geometric representation used by the solver.\n\nArguments\n\nprop_method (ForwardProp): Solver that uses forward propagation method.\nbatch_input: Array of inputs.\nbatch_output: Array of outputs.\n\nReturns\n\nList of the input specifications for the given batch of inputs.\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.init_batch_bound-Tuple{ModelVerification.BackwardProp, Any, Any}","page":"Solvers","title":"ModelVerification.init_batch_bound","text":"init_batch_bound(prop_method::BackwardProp, batch_input, batch_output)\n\nReturns a list of the output specifications (geometries) for the given batch of  outputs. This is for BackwardProp solvers. Each input specification is  processed to fit the geometric representation used by the solver.\n\nArguments\n\nprop_method (BackwardProp): Solver that uses backward propagation method.\nbatch_input: Array of inputs.\nbatch_output: Array of outputs.\n\nReturns\n\nList of the output specifications for the given batch of outputs.\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.init_bound-Tuple{ModelVerification.ForwardProp, Any}","page":"Solvers","title":"ModelVerification.init_bound","text":"init_bound(prop_method::ForwardProp, input)\n\nReturns the geometry representation used to encode the input specification. This is for ForwardProp solvers. \n\nArguments\n\nprop_method (ForwardProp): Solver that uses forward propagation method. \ninput: Geometry representation used to encode the input specification.\n\nReturns\n\ninput: Geometry representation used to encode the input specification.\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.init_bound-Tuple{ModelVerification.BackwardProp, Any}","page":"Solvers","title":"ModelVerification.init_bound","text":"init_bound(prop_method::BackwardProp, output)\n\nReturns the geometry representation used to encode the output specification.  This is for BackwardProp solvers.\n\nArguments\n\nprop_method (BackwardProp): Solver that uses backward propagation method. \noutput: Geometry representation used to encode the output specification.\n\nReturns\n\noutput: Geometry representation used to encode the output specification.\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.process_bound","page":"Solvers","title":"ModelVerification.process_bound","text":"process_bound(prop_method::PropMethod, batch_bound, batch_out_spec, model_info, batch_info)\n\nReturns the list of bounds resulting from the propagation and the information of the batch.\n\nArguments\n\nprop_method (PropMethod): Solver.\nbatch_bound: List of the bounds for the given batch.\nbatch_out_spec: List of the output specifications for the given batch of    outputs.\nmodel_info: Structure containing the information of the neural network to be    verified.\nbatch_info: Dictionary containing information of each node in the model.\n\nReturns\n\nbatch_bound: List of the bounds for the given batch.\nbatch_info: Dictionary containing information of each node in the model.\n\n\n\n\n\nprocess_bound(prop_method::BetaCrown, batch_bound::BetaCrownBound, batch_out_spec, model_info, batch_info)\n\n\n\n\n\n","category":"function"},{"location":"solvers.html#Checking-inclusion","page":"Solvers","title":"Checking inclusion","text":"","category":"section"},{"location":"solvers.html","page":"Solvers","title":"Solvers","text":"check_inclusion(prop_method::ForwardProp, model, batch_input::AbstractArray, batch_reach::AbstractArray, batch_output::AbstractArray)","category":"page"},{"location":"solvers.html#ModelVerification.check_inclusion-Tuple{ModelVerification.ForwardProp, Any, AbstractArray, AbstractArray, AbstractArray}","page":"Solvers","title":"ModelVerification.check_inclusion","text":"check_inclusion(prop_method::ForwardProp, model, batch_input::AbstractArray, batch_reach::AbstractArray, batch_output::AbstractArray)\n\nDetermines whether the reachable sets, batch_reach, are within the respective  valid output sets, batch_output.\n\nArguments\n\nprop_method (ForwardProp): Solver being used.\nmodel: Neural network model that is to be verified.\ninput (AbstractArray): List of input specifications.\nreach (AbstractArray): List of reachable sets.\noutput (AbstractArray) : List of sets of valid outputs.\n\nReturns\n\nList of a combination of the following components:\n\nReachabilityResult(:holds, [reach]) if reach is a subset of output.\nCounterExampleResult(:unknown) if reach is not a subset of output, but    cannot find a counterexample.\nCounterExampleResult(:violated, x) if reach is not a subset of output,    and there is a counterexample.\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ExactReach","page":"Solvers","title":"ExactReach","text":"","category":"section"},{"location":"solvers.html","page":"Solvers","title":"Solvers","text":"ExactReach\nExactReachBound\ncenter(bound::ExactReachBound)\nprepare_problem(search_method::SearchMethod, split_method::SplitMethod, prop_method::ExactReach, problem::Problem)\ninit_bound(prop_method::ExactReach, bound::LazySet)\ncheck_inclusion(prop_method::ExactReach, model, input::ExactReachBound, reach::ExactReachBound, output::LazySet)","category":"page"},{"location":"solvers.html#ModelVerification.ExactReach","page":"Solvers","title":"ModelVerification.ExactReach","text":"ExactReach <: SequentialForwardProp\n\nExactReach performs exact reachability analysis to compute the exact reachable  set for a network. It works for piecewise linear networks with either linear or  ReLU activations. It computes the reachable set for every linear segment of the  network and keeps track of all sets. The final reachable set is the union of all  sets. Since the number of linear segments is exponential in the number of nodes  in one layer, this method is not scalable.\n\nProblem Requirement\n\nNetwork: any depth, ReLU activation (more activations to be supported in the future)\nInput: Array of AbstractPolytope, i.e., union of polytopes.\nOutput: Array of AbstractPolytope, i.e., union of polytopes.\n\nReturns\n\nBasicResult(:holds), BasicResult(:violated)\n\nMethod\n\nReachability analysis using split and join.\n\nProperty\n\nSound and complete.\n\nReference\n\n[1] C. Liu, T. Arnon, C. Lazarus, C. Strong, C. Barret, and M. J. Kochenderfer,  \"Algorithms for Verifying Deep Neural Networks,\" in Foundations and Trends in  Optimization, 2021.\n\n[2] W. Xiang, H.-D. Tran, and T. T. Johnson, \"Reachable Set Computation and  Safety Verification for Neural Networks with ReLU Activations,\" ArXiv Preprint  ArXiv:1712.08163, 2017.\n\n\n\n\n\n","category":"type"},{"location":"solvers.html#ModelVerification.ExactReachBound","page":"Solvers","title":"ModelVerification.ExactReachBound","text":"ExactReachBound <: Bound\n\nBound for ExactReach solver. It is a union of polytopes, represented with an  array of LazySet.\n\nFields\n\npolys (AbstractArray{LazySet}): Array of polytopes.\n\n\n\n\n\n","category":"type"},{"location":"solvers.html#ModelVerification.center-Tuple{ModelVerification.ExactReachBound}","page":"Solvers","title":"ModelVerification.center","text":"center(bound::ExactReachBound)\n\nReturns a randomly sampled point from the first polytope in the array of  polytopes, bound.polys.\n\nArguments\n\nbound (ExactReachBound): The ExactReachBound to sample from.\n\nReturns\n\nA randomly sampled point from the first polytope in the array of polytopes.\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.prepare_problem-Tuple{SearchMethod, SplitMethod, ExactReach, Problem}","page":"Solvers","title":"ModelVerification.prepare_problem","text":"prepare_problem(search_method::SearchMethod, split_method::SplitMethod, \n                prop_method::ExactReach, problem::Problem)\n\nPreprocessing of the Problem to be solved. This method converts the model to a  bounded computational graph, makes the input specification compatible with the  solver, and returns the model information and preprocessed Problem. This in  turn also initializes the branch bank.\n\nArguments\n\nsearch_method (SearchMethod): Method to search the branches.\nsplit_method (SplitMethod): Method to split the branches.\nprop_method (ExactReach): Solver to be used, specifically the    ExactReach.\nproblem (Problem): Problem to be preprocessed to better fit the solver.\n\nReturns\n\nmodel_info, a structure containing the information of the neural network to    be verified.\nProblem after processing the initial input specification and model.\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.init_bound-Tuple{ExactReach, LazySets.LazySet}","page":"Solvers","title":"ModelVerification.init_bound","text":"init_bound(prop_method::ExactReach, bound::LazySet)\n\nFor the ExactReach solver, this function converts the input set, represented  with a LazySet, to an ExactReachBound representation. This serves as a  preprocessing step for the ExactReach solver.\n\nArguments\n\nprop_method (ExactReach): ExactReach solver.\nbound (LazySet): Input set, represented with a LazySet.\n\nReturns\n\nExactReachBound representation of the input set.\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.check_inclusion-Tuple{ExactReach, Any, ModelVerification.ExactReachBound, ModelVerification.ExactReachBound, LazySets.LazySet}","page":"Solvers","title":"ModelVerification.check_inclusion","text":"check_inclusion(prop_method::ExactReach, model, input::ExactReachBound, \n                reach::ExactReachBound, output::LazySet)\n\nDetermines whether the reachable set, reach, is within the valid output  specified by a LazySet. This function achieves this by directly checking if  all the reachable sets in reach are subsets of the set of valid outputs  output. If not, it returns BasicResult(:violated). Otherwise, it returns  BasicResult(:holds).\n\nArguments\n\nprop_method (ExactReach): Solver being used.\nmodel: Neural network model that is to be verified.\ninput (ExactReachBound): Input specification represented with an    ExactReachBound.\nreach (ExactReachBound): Reachable set resulting from the propagation of   input through the model, represented with an ExactReachBound.\noutput (LazySet): Set of valid outputs represented with a LazySet.\n\nReturns\n\nBasicResult(:holds) if all reachable sets in reach are subsets of    output.\nBasicResult(:violated) if any reachable set in reach is not a subset of    output.\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#Ai2","page":"Solvers","title":"Ai2","text":"","category":"section"},{"location":"solvers.html","page":"Solvers","title":"Solvers","text":"Ai2\nStarSet\nprepare_method(prop_method::StarSet, batch_input::AbstractVector, batch_output::AbstractVector, model_info)\ncompute_bound(bound::Zonotope)\ncompute_bound(bound::Star)\ninit_bound(prop_method::StarSet, input::Hyperrectangle) \ncheck_inclusion(prop_method::ForwardProp, model, input::LazySet, reach::LazySet, output::LazySet)\ncheck_inclusion(prop_method::ForwardProp, model, input::LazySet, reach::LazySet, output::Complement)","category":"page"},{"location":"solvers.html#ModelVerification.Ai2","page":"Solvers","title":"ModelVerification.Ai2","text":"Ai2{T<:Union{Hyperrectangle, Zonotope, HPolytope, Star}} \n                                <: SequentialForwardProp\n\nAi2 performs over-approximated reachability analysis to compute the over- approximated output reachable set for a network. T can be Hyperrectangle,  Zonotope, Star, or HPolytope. Different geometric representations impact the verification performance due to different over-approximation sizes.  We use Zonotope as \"benchmark\" geometry, as in the original implementation[1],  due to improved scalability and precision (similar results can be achieved using  Star). On the other hand, using a HPolytope representation potentially  leads to a more precise but less scalable result, and the opposite holds for  Hyperrectangle.\n\nNote that initializing Ai2() defaults to Ai2{Zonotope}. The following aliases also exist for convenience:\n\nProblem Requirement\n\nNetwork: any depth, ReLU activation (more activations to be supported in the   future)\nInput: AbstractPolytope\n\nconst Ai2h = Ai2{HPolytope}\nconst Ai2z = Ai2{Zonotope}\nconst Ai2s = Ai2{Star}\nconst Box = Ai2{Hyperrectangle}\n\nOutput:  AbstractPolytope\n\nReturns\n\nReachabilityResult, CounterExampleResult\n\nMethod\n\nReachability analysis using split and join.\n\nProperty\n\nSound but not complete.\n\nReference\n\n[1] T. Gehr, M. Mirman, D. Drashsler-Cohen, P. Tsankov, S. Chaudhuri, and  M. Vechev, \"Ai2: Safety and Robustness Certification of Neural Networks with  Abstract Interpretation,\" in 2018 IEEE Symposium on Security and Privacy (SP), \n\n\n\n\n\n\n\n","category":"type"},{"location":"solvers.html#ModelVerification.StarSet","page":"Solvers","title":"ModelVerification.StarSet","text":"StarSet\n\nCovers supported Ai2 variations: Ai2h, Ai2z, Ai2s, Box.\n\nFields\n\npre_bound_method (Union{SequentialForwardProp, Nothing}): The geometric    representation used to compute the over-approximation of the input bounds.\n\n\n\n\n\n","category":"type"},{"location":"solvers.html#ModelVerification.prepare_method-Tuple{StarSet, AbstractVector, AbstractVector, Any}","page":"Solvers","title":"ModelVerification.prepare_method","text":"prepare_method(prop_method::StarSet, batch_input::AbstractVector, \nbatch_output::AbstractVector, model_info)\n\nInitialize the bound of the start node of the computational graph for the  StarSet solvers.\n\nArguments\n\nprop_method (StarSet) : Propagation method of type StarSet.\nbatch_input (AbstractVector) : Batch of inputs.\nbatch_output (AbstractVector) : Batch of outputs.\nmodel_info: Structure containing the information of the neural network to   be verified.\n\nReturns\n\nbatch_output: batch of outputs.\nbatch_info: Dictionary containing information of each node in the model.\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.compute_bound-Tuple{LazySets.Zonotope}","page":"Solvers","title":"ModelVerification.compute_bound","text":"compute_bound(bound::Zonotope)\n\nComputes the lower- and upper-bounds of a zonotope.  This function is used when propagating through the layers of the model. Radius is the sum of the absolute value of the generators of the given zonotope.\n\nArguments\n\nbound (Zonotope) : zonotope of which the bounds need to be computed\n\nReturns\n\nLower- and upper-bounds of the Zonotope.\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.compute_bound-Tuple{LazySets.Star}","page":"Solvers","title":"ModelVerification.compute_bound","text":"compute_bound(bound::Star)\n\nComputes the lower- and upper-bounds of a star set.  This function is used when propagating through the layers of the model. It overapproximates the given star set with a hyperrectangle.\n\nArguments\n\nbound (Star): Star set of which the bounds need to be computed.\n\nReturns\n\nLower- and upper-bounds of the overapproximated hyperrectangle.\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.init_bound-Tuple{StarSet, LazySets.Hyperrectangle}","page":"Solvers","title":"ModelVerification.init_bound","text":"init_bound(prop_method::StarSet, input::Hyperrectangle)\n\nGiven a hyperrectangle as input, this function returns a star set that  encompasses the hyperrectangle. This helps a more precise computation of bounds.\n\nArguments\n\nprop_method (StarSet): StarSet-type solver; includes Ai2h, Ai2z,    Ai2s, Box.\ninput (Hyperrectangle): Hyperrectangle to be converted into a star set\n\nReturns\n\nStar set that encompasses the given hyperrectangle.\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.check_inclusion-Tuple{ModelVerification.ForwardProp, Any, LazySets.LazySet, LazySets.LazySet, LazySets.LazySet}","page":"Solvers","title":"ModelVerification.check_inclusion","text":"check_inclusion(prop_method::ForwardProp, model, input::LazySet, \nreach::LazySet, output::LazySet)\n\nDetermines whether the reachable set, reach, is within the valid  output specified by a LazySet. This function achieves this by directly  checking if the reachable set reach is a subset of the set of valid outputs  output. If not, it attempts to find a counterexample and returns the  appropriate Result.\n\nArguments\n\nprop_method (ForwardProp): Solver being used.\nmodel: Neural network model that is to be verified.\ninput (LazySet): Input specification supported by LazySet.\nreach (LazySet): Reachable set resulting from the propagation of input    through the model.\noutput (LazySet) : Set of valid outputs represented with a LazySet.\n\nReturns\n\nReachabilityResult(:holds, [reach]) if reach is a subset of output.\nCounterExampleResult(:unknown) if reach is not a subset of output, but    cannot find a counterexample.\nCounterExampleResult(:violated, x) if reach is not a subset of output,    and there is a counterexample.\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.check_inclusion-Tuple{ModelVerification.ForwardProp, Any, LazySets.LazySet, LazySets.LazySet, LazySets.Complement}","page":"Solvers","title":"ModelVerification.check_inclusion","text":"check_inclusion(prop_method::ForwardProp, model, input::LazySet, \nreach::LazySet, output::Complement)\n\nDetermines whether the reachable set, R(input, model), is within the valid  output specified by a LazySet. This function achieves this by checking if the box approximation (overapproximation with hyperrectangle) of the reach set is disjoint with the unsafe_output. If the box approximation is a subset of the  unsafe_output, then the safety property is violated. \n\nArguments\n\nprop_method (ForwardProp): Solver being used.\nmodel: Neural network model that is to be verified.\ninput (LazySet): Input specification supported by Lazyset.\nreach (LazySet): Reachable set resulting from the propagation of input    through the model.\noutput (Complement): Set of valid outputs represented with a complement    set. For problems using this check_inclusion method, the unsafe region is    specified. Then, the complement of the unsafe region is given as the desired    output specification.\n\nReturns\n\nReachabilityResult(:holds, [reach]) if box_reach is disjoint with the   complement of the output.\nCounterExampleResult(:violated, x) if the center of the input set results    in a state that belongs to the unsafe_output.\nCounterExampleResult(:unknown) if either the two cases above are true.\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ImageStar","page":"Solvers","title":"ImageStar","text":"","category":"section"},{"location":"solvers.html","page":"Solvers","title":"Solvers","text":"ImageStar\nImageStarBound\nprepare_problem(search_method::SearchMethod, split_method::SplitMethod, prop_method::ImageStar, problem::Problem)\nprepare_method(prop_method::ImageStar, batch_input::AbstractVector, batch_output::AbstractVector, model_info)\ninit_bound(prop_method::ImageStar, ch::ImageConvexHull) \nassert_zono_star(bound::ImageStarBound)\ncompute_bound(bound::ImageStarBound)\ncenter(bound::ImageStarBound)\ncheck_inclusion(prop_method::ImageStar, model, input::ImageStarBound, reach::LazySet, output::LazySet)","category":"page"},{"location":"solvers.html#ModelVerification.ImageStar","page":"Solvers","title":"ModelVerification.ImageStar","text":"ImageStar <: SequentialForwardProp\n\nImageStar is a verification approach that can verify the robustness of  Convolutional Neural Network (CNN). This toolbox uses the term, ImageStar, as  the verification method itself that uses the ImageStar set. In terms of  geometric representation, an ImageStar is an extension of the generalized star set such that the center and generators are images with multiple channels.\n\nΘ =  x  x = c + _i=1^m (α_i v_i)  Cα  d \n\nwhere c is the center image, V =  v_1  v_m  is the set of generator images, and Cα  d represent the predicate with α's as the free  parameters. This set representation enables efficient over-approximative  analysis of CNNs. ImageStar is less conservative and faster than ImageZono [1].\n\nNote that initializing ImageStar() defaults to ImageStar(nothing).\n\nFields\n\npre_bound_method (Union{SequentialForwardProp, Nothing}): The geometric    representation used to compute the over-approximation of the input bounds.\n\nReference\n\n[1] HD. Tran, S. Bak, W. Xiang, and T.T. Johnson, \"Verification of Deep Convolutional  Neural Networks Using ImageStars,\" in Computer Aided Verification (CAV), 2020.\n\n\n\n\n\n","category":"type"},{"location":"solvers.html#ModelVerification.ImageStarBound","page":"Solvers","title":"ModelVerification.ImageStarBound","text":"ImageStarBound{T<:Real} <: Bound\n\nImageStarBound is used to represent the bounded set for ImageStar.  It is an extension of the geometric representation, StarSet.\n\nFields\n\ncenter (AbstractArray{T, 4}): center image (\"anchor\" image in literature),    of size heigth x width x number of channels x 1.\ngenerators (AbstractArray{T, 4}): matrix of generator images, of size   height x width x number of channels x number of generators.\nA (AbstractArray{T, 2}): normal direction of the predicate, of size    number of constraints x number of generators.\nb (AbstractArray{T, 1}): constraints of the predicate, of size    number of constraints x number of generators.\n\n\n\n\n\n","category":"type"},{"location":"solvers.html#ModelVerification.prepare_problem-Tuple{SearchMethod, SplitMethod, ImageStar, Problem}","page":"Solvers","title":"ModelVerification.prepare_problem","text":"prepare_problem(search_method::SearchMethod, split_method::SplitMethod, \n                prop_method::ImageStar, problem::Problem)\n\nPreprocessing of the Problem to be solved. This method converts the model to a  bounded computational graph, makes the input specification compatible with the  solver, and returns the model information and preprocessed Problem. This in  turn also initializes the branch bank.\n\nArguments\n\nsearch_method (SearchMethod): Method to search the branches.\nsplit_method (SplitMethod): Method to split the branches.\nprop_method (ImageStar): Solver to be used, specifically the ImageStar.\nproblem (Problem): Problem to be preprocessed to better fit the solver.\n\nReturns\n\nmodel_info, a structure containing the information of the neural network to    be verified.\nProblem after processing the initial input specification and model.\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.prepare_method-Tuple{ImageStar, AbstractVector, AbstractVector, Any}","page":"Solvers","title":"ModelVerification.prepare_method","text":"prepare_method(prop_method::ImageStar, batch_input::AbstractVector,\n               batch_output::AbstractVector, model_info)\n\nInitialize the bound of the start node of the computational graph based on the  pre_bound_method specified in the given ImageStar solver.\n\nAgruments\n\nprop_method (ImageStar): ImageStar solver.\nbatch_input (AbstractVector): Batch of inputs.\nbatch_output (AbstractVector): Batch of outputs.\nmodel_info: Structure containing the information of the neural network to   be verified.\n\nReturns\n\nbatch_output: Batch of outputs.\nbatch_info: Dictionary containing information of each node in the model.\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.init_bound-Tuple{ImageStar, ImageConvexHull}","page":"Solvers","title":"ModelVerification.init_bound","text":"init_bound(prop_method::ImageStar, ch::ImageConvexHull)\n\nFor the ImageStar solver, this function converts the input set, represented  with an ImageConvexHull, to an ImageStarBound representation. This serves as  a preprocessing step for the ImageStar solver. \n\nArguments\n\nprop_method (ImageStar): ImageStar solver.\nch (ImageConvexHull): Convex hull, type ImageConvexHull, is used for the    input specification.\n\nReturns\n\nImageStarBound set that encompasses the given ImageConvexHull.\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.assert_zono_star-Tuple{ModelVerification.ImageStarBound}","page":"Solvers","title":"ModelVerification.assert_zono_star","text":"assert_zono_star(bound::ImageStarBound)\n\nAsserts whether the given ImageStarBound set is a Zonotope. This is done by checking whether the free parameter belongs to a unit hypercube.\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.compute_bound-Tuple{ModelVerification.ImageStarBound}","page":"Solvers","title":"ModelVerification.compute_bound","text":"compute_bound(bound::ImageStarBound)\n\nComputes the lower- and upper-bounds of an image star set. This function is used when propagating through the layers of the model. It converts the image star set to a star set. Then, it overapproximates this  star set with a hyperrectangle.\n\nArguments\n\nbound (ImageStarBound): Image star set of which the bounds need to be    computed.\n\nReturns\n\nLower- and upper-bounds of the overapproximated hyperrectangle.\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.center-Tuple{ModelVerification.ImageStarBound}","page":"Solvers","title":"ModelVerification.center","text":"center(bound::ImageStarBound)\n\nReturns the center image of the ImageStarBound bound.\n\nArguments\n\nbound (ImageStarBound): Geometric representation of the specification    using ImageStarBound.\n\nReturns\n\nImageStarBound.center image of type AbstractArray{T, 4}.\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.check_inclusion-Tuple{ImageStar, Any, ModelVerification.ImageStarBound, LazySets.LazySet, LazySets.LazySet}","page":"Solvers","title":"ModelVerification.check_inclusion","text":"check_inclusion(prop_method::ImageStar, model, input::ImageStarBound, \n                reach::LazySet, output::LazySet)\n\nDetermines whether the reachable set, reach, is within the valid output  specified by a LazySet. \n\nAgruments\n\nprop_method (ImageStar): Solver being used.\nmodel: Neural network model that is to be verified.\ninput (ImageStarBound): Input specification supported by ImageStarBound.\nreach (LazySet): Reachable set resulting from the propagation of input    through the model.\noutput (LazySet): Set of valid outputs represented with a LazySet.\n\nReturns\n\nReachabilityResult(:holds, box_reach) if reach is a subset of output,    the function returns :holds with the box approximation (overapproximation    with hyperrectangle) of the reach set.\nCounterExampleResult(:unknown) if reach is not a subset of output, but    cannot find a counterexample.\nCounterExampleResult(:violated, x) if reach is not a subset of output,    and there is a counterexample.\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ImageZono","page":"Solvers","title":"ImageZono","text":"","category":"section"},{"location":"solvers.html","page":"Solvers","title":"Solvers","text":"ImageZono\nImageZonoBound\nprepare_problem(search_method::SearchMethod, split_method::SplitMethod, prop_method::ImageZono, problem::Problem)\ninit_bound(prop_method::ImageZono, ch::ImageConvexHull) \ninit_bound(prop_method::ImageZono, bound::ImageStarBound)\ncompute_bound(bound::ImageZonoBound)\ncenter(bound::ImageZonoBound)\ncheck_inclusion(prop_method::ImageZono, model, input::ImageZonoBound, reach::LazySet, output::LazySet)","category":"page"},{"location":"solvers.html#ModelVerification.ImageZono","page":"Solvers","title":"ModelVerification.ImageZono","text":"ImageZono <: SequentialForwardProp\n\nImageZono is a verification approach that uses Image Zonotope as the geometric  representation. It is an extension of ImageStar where there is no linear  constraints on the free parameters, α:\n\nΘ =  x  x = c + _i=1^m (α_i v_i) \n\nwhere c is the center image, V =  v_1  v_m  is the set of generator images, and α's are the free parameters.\n\n\n\n\n\n","category":"type"},{"location":"solvers.html#ModelVerification.ImageZonoBound","page":"Solvers","title":"ModelVerification.ImageZonoBound","text":"ImageZonoBound{T<:Real} <: Bound\n\nImageZonoBound is used to represent the bounded set for ImageZono.\n\nFields\n\ncenter (AbstractArray{T, 4}): center image (\"anchor\" image in literature),    of size heigth x width x number of channels x 1.\ngenerators (AbstractArray{T, 4}): matrix of generator images, of size   height x width x number of channels x number of generators.\n\n\n\n\n\n","category":"type"},{"location":"solvers.html#ModelVerification.prepare_problem-Tuple{SearchMethod, SplitMethod, ImageZono, Problem}","page":"Solvers","title":"ModelVerification.prepare_problem","text":"prepare_problem(search_method::SearchMethod, split_method::SplitMethod, \n                prop_method::ImageZono, problem::Problem)\n\nConverts the model to a bounded computational graph and makes input  specification compatible with the solver, prop_method. This in turn also  initializes the branch bank.\n\nArguments\n\nsearch_method (SearchMethod): Method to search the branches.\nsplit_method (SplitMethod): Method to split the branches.\nprop_method (ImageZono): Solver to be used, specifically the ImageZono.\nproblem (Problem): Problem to be preprocessed to better fit the solver.\n\nReturns\n\nmodel_info, a structure containing the information of the neural network to    be verified.\nProblem after processing the initial input specification and model.\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.init_bound-Tuple{ImageZono, ImageConvexHull}","page":"Solvers","title":"ModelVerification.init_bound","text":"init_bound(prop_method::ImageZono, ch::ImageConvexHull)\n\nFor the ImageZono solver, this function converts the input set, represented  with an ImageConvexHull, to an ImageZonoBound representation. This serves as  a preprocessing step for the ImageZono solver. \n\nArguments\n\nprop_method (ImageZono): ImageZono solver.\nch (ImageConvexHull): Convex hull, type ImageConvexHull, is used as the    input specification.\n\nReturns\n\nImageZonoBound set that encompasses the given ImageConvexHull.\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.init_bound-Tuple{ImageZono, ModelVerification.ImageStarBound}","page":"Solvers","title":"ModelVerification.init_bound","text":"init_bound(prop_method::ImageZono, bound::ImageStarBound)\n\nFor the ImageZono solver, if the input set, represented with an  ImageStarBound, is a zonotope, this function converts it to an  ImageZonoBound representation.\n\nArguments\n\nprop_method (ImageZono): ImageZono solver.\nch (ImageStarBound): ImageStarBound is used for the input specification.\n\nReturns\n\nImageZonoBound representation.\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.compute_bound-Tuple{ModelVerification.ImageZonoBound}","page":"Solvers","title":"ModelVerification.compute_bound","text":"compute_bound(bound::ImageZonoBound)\n\nComputes the lower- and upper-bounds of an image zono set. This function is used when propagating through the layers of the model. It converts the image zono set to a zonotope. Then, it computes the bounds using  compute_bound(bound::Zonotope).\n\nArguments\n\nbound (ImageZonoBound): Image zono set of which the bounds need to be    computed.\n\nReturns\n\nLower- and upper-bounds of the flattened zonotope.\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.center-Tuple{ModelVerification.ImageZonoBound}","page":"Solvers","title":"ModelVerification.center","text":"center(bound::ImageZonoBound)\n\nReturns the center image of the ImageZonoBound bound.\n\nArguments\n\nbound (ImageZonoBound): Geometric representation of the specification    using ImageZonoBound.\n\nReturns\n\nImageZonoBound.center image of type AbstractArray{T, 4}.\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.check_inclusion-Tuple{ImageZono, Any, ModelVerification.ImageZonoBound, LazySets.LazySet, LazySets.LazySet}","page":"Solvers","title":"ModelVerification.check_inclusion","text":"check_inclusion(prop_method::ImageZono, model, input::ImageZonoBound, \n                reach::LazySet, output::LazySet)\n\nDetermines whether the reachable set, reach, is within the valid output  specified by a LazySet.\n\nAgruments\n\nprop_method (ImageZono): Solver being used.\nmodel: Neural network model that is to be verified.\ninput (ImageZonoBound): Input specification supported by ImageZonoBound.\nreach (LazySet): Reachable set resulting from the propagation of input    through the model.\noutput (LazySet) : Set of valid outputs represented with a LazySet.\n\nReturns\n\nReachabilityResult(:holds, box_reach) if reach is a subset of output,    the function returns :holds with the box approximation (overapproximation    with hyperrectangle) of the reach set.\nCounterExampleResult(:unknown) if reach is not a subset of output, but    cannot find a counterexample.\nCounterExampleResult(:violated, x) if reach is not a subset of output,    and there is a counterexample.\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#Crown","page":"Solvers","title":"Crown","text":"","category":"section"},{"location":"solvers.html","page":"Solvers","title":"Solvers","text":"Crown\nCrownBound\nConcretizeCrownBound\nprepare_problem(search_method::SearchMethod, split_method::SplitMethod, prop_method::Crown, problem::Problem)\nprepare_method(prop_method::Crown, batch_input::AbstractVector, out_specs::LinearSpec, model_info)\ninit_batch_bound(prop_method::Crown, batch_input::AbstractArray, out_specs)\ncompute_bound(bound::CrownBound)\ncompute_bound(bound::ConcretizeCrownBound)\ncheck_inclusion(prop_method::Crown, model, batch_input::AbstractArray, bound::CrownBound, batch_out_spec::LinearSpec)","category":"page"},{"location":"solvers.html#ModelVerification.Crown","page":"Solvers","title":"ModelVerification.Crown","text":"Crown <: BatchForwardProp\n\n\n\n\n\n","category":"type"},{"location":"solvers.html#ModelVerification.CrownBound","page":"Solvers","title":"ModelVerification.CrownBound","text":"CrownBound <: Bound\n\n\n\n\n\n","category":"type"},{"location":"solvers.html#ModelVerification.ConcretizeCrownBound","page":"Solvers","title":"ModelVerification.ConcretizeCrownBound","text":"ConcretizeCrownBound <: Bound\n\n\n\n\n\n","category":"type"},{"location":"solvers.html#ModelVerification.prepare_problem-Tuple{SearchMethod, SplitMethod, Crown, Problem}","page":"Solvers","title":"ModelVerification.prepare_problem","text":"prepare_problem(search_method::SearchMethod, split_method::SplitMethod, \n                prop_method::Crown, problem::Problem)\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.prepare_method-Tuple{Crown, AbstractVector, ModelVerification.LinearSpec, Any}","page":"Solvers","title":"ModelVerification.prepare_method","text":"prepare_method(prop_method::Crown, batch_input::AbstractVector, \n               out_specs::LinearSpec, model_info)\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.init_batch_bound-Tuple{Crown, AbstractArray, Any}","page":"Solvers","title":"ModelVerification.init_batch_bound","text":"init_batch_bound(prop_method::Crown, batch_input::AbstractArray, out_specs)\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.compute_bound-Tuple{ModelVerification.CrownBound}","page":"Solvers","title":"ModelVerification.compute_bound","text":"compute_bound(bound::CrownBound)\n\nCompute lower and upper bounds of a relu node in Crown. l, u := ([low]₊*data_min + [low]₋*data_max), ([up]₊*data_max + [up]₋*data_min)\n\nArguments\n\nbound (CrownBound): CrownBound object\n\nOutputs:\n\n(lbound, ubound)\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.compute_bound-Tuple{ModelVerification.ConcretizeCrownBound}","page":"Solvers","title":"ModelVerification.compute_bound","text":"compute_bound(bound::ConcretizeCrownBound)\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.check_inclusion-Tuple{Crown, Any, AbstractArray, ModelVerification.CrownBound, ModelVerification.LinearSpec}","page":"Solvers","title":"ModelVerification.check_inclusion","text":"check_inclusion(prop_method::Crown, model, batch_input::AbstractArray, bound::CrownBound, batch_out_spec::LinearSpec)\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#\\alpha-Crown","page":"Solvers","title":"alpha-Crown","text":"","category":"section"},{"location":"solvers.html#\\beta-Crown","page":"Solvers","title":"beta-Crown","text":"","category":"section"},{"location":"solvers.html","page":"Solvers","title":"Solvers","text":"BetaCrown\nBetaCrownBound\nCompute_bound\nprepare_problem(search_method::SearchMethod, split_method::SplitMethod, prop_method::BetaCrown, problem::Problem)\ninit_batch_bound(prop_method::BetaCrown, batch_input::AbstractArray, batch_output::LinearSpec)\nprepare_method(prop_method::BetaCrown, batch_input::AbstractVector, batch_output::AbstractVector, model_info)\nprepare_method(prop_method::BetaCrown, batch_input::AbstractVector, out_specs::LinearSpec, model_info)\nupdate_bound_by_relu_con(node, batch_input, relu_input_lower, relu_input_upper)\ninit_alpha(layer::typeof(relu), node, batch_info, batch_input)\ninit_beta(layer::typeof(relu), node, batch_info, batch_input)\ninit_A_b(n, batch_size) # A x < b\ninit_bound(prop_method::BetaCrown, input) \noptimize_model(model, input, loss_func, optimizer, max_iter)\nprocess_bound(prop_method::BetaCrown, batch_bound::BetaCrownBound, batch_out_spec, model_info, batch_info)\nget_pre_relu_A(init, use_gpu, lower_or_upper, model_info, batch_info)\nget_pre_relu_spec_A(init, use_gpu, lower_or_upper, model_info, batch_info)\ncheck_inclusion(prop_method::BetaCrown, model, batch_input::AbstractArray, bound::ConcretizeCrownBound, batch_out_spec::LinearSpec)","category":"page"},{"location":"solvers.html#ModelVerification.BetaCrown","page":"Solvers","title":"ModelVerification.BetaCrown","text":"BetaCrown <: BatchBackwardProp\n\n\n\n\n\n","category":"type"},{"location":"solvers.html#ModelVerification.BetaCrownBound","page":"Solvers","title":"ModelVerification.BetaCrownBound","text":"BetaCrownBound <: Bound\n\n\n\n\n\n","category":"type"},{"location":"solvers.html#ModelVerification.Compute_bound","page":"Solvers","title":"ModelVerification.Compute_bound","text":"Compute_bound\n\n\n\n\n\n","category":"type"},{"location":"solvers.html#ModelVerification.prepare_problem-Tuple{SearchMethod, SplitMethod, BetaCrown, Problem}","page":"Solvers","title":"ModelVerification.prepare_problem","text":"prepare_problem(search_method::SearchMethod, split_method::SplitMethod, prop_method::BetaCrown, problem::Problem)\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.init_batch_bound-Tuple{BetaCrown, AbstractArray, ModelVerification.LinearSpec}","page":"Solvers","title":"ModelVerification.init_batch_bound","text":"init_batch_bound(prop_method::BetaCrown, batch_input::AbstractArray, batch_output::LinearSpec)\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.prepare_method-Tuple{BetaCrown, AbstractVector, AbstractVector, Any}","page":"Solvers","title":"ModelVerification.prepare_method","text":"prepare_method(prop_method::BetaCrown, batch_input::AbstractVector, batch_output::AbstractVector, model_info)\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.prepare_method-Tuple{BetaCrown, AbstractVector, ModelVerification.LinearSpec, Any}","page":"Solvers","title":"ModelVerification.prepare_method","text":"prepare_method(prop_method::BetaCrown, batch_input::AbstractVector, out_specs::LinearSpec, model_info)\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.update_bound_by_relu_con-NTuple{4, Any}","page":"Solvers","title":"ModelVerification.update_bound_by_relu_con","text":"update_bound_by_relu_con(node, batch_input, relu_input_lower, relu_input_upper)\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.init_alpha-Tuple{typeof(NNlib.relu), Any, Any, Any}","page":"Solvers","title":"ModelVerification.init_alpha","text":"init_alpha(layer::typeof(relu), node, batch_info, batch_input)\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.init_beta-Tuple{typeof(NNlib.relu), Any, Any, Any}","page":"Solvers","title":"ModelVerification.init_beta","text":"initbeta(layer::typeof(relu), node, batchinfo, batch_input)\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.init_A_b-Tuple{Any, Any}","page":"Solvers","title":"ModelVerification.init_A_b","text":"init_A_b(n, batch_size) # A x < b\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.init_bound-Tuple{BetaCrown, Any}","page":"Solvers","title":"ModelVerification.init_bound","text":"init_bound(prop_method::BetaCrown, input)\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.optimize_model-NTuple{5, Any}","page":"Solvers","title":"ModelVerification.optimize_model","text":"optimize_model(model, input, loss_func, optimizer, max_iter)\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.process_bound-Tuple{BetaCrown, ModelVerification.BetaCrownBound, Any, Any, Any}","page":"Solvers","title":"ModelVerification.process_bound","text":"process_bound(prop_method::BetaCrown, batch_bound::BetaCrownBound, batch_out_spec, model_info, batch_info)\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.get_pre_relu_A-NTuple{5, Any}","page":"Solvers","title":"ModelVerification.get_pre_relu_A","text":"get_pre_relu_A(init, use_gpu, lower_or_upper, model_info, batch_info)\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.get_pre_relu_spec_A-NTuple{5, Any}","page":"Solvers","title":"ModelVerification.get_pre_relu_spec_A","text":"get_pre_relu_spec_A(init, use_gpu, lower_or_upper, model_info, batch_info)\n\n\n\n\n\n","category":"method"},{"location":"solvers.html#ModelVerification.check_inclusion-Tuple{BetaCrown, Any, AbstractArray, ModelVerification.ConcretizeCrownBound, ModelVerification.LinearSpec}","page":"Solvers","title":"ModelVerification.check_inclusion","text":"check_inclusion(prop_method::BetaCrown, model, batch_input::AbstractArray, bound::ConcretizeCrownBound, batch_out_spec::LinearSpec)\n\n\n\n\n\n","category":"method"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"CurrentModule = ModelVerification","category":"page"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"Pages=[\"safety_spec.md\"]\nDepth=3","category":"page"},{"location":"safety_spec.html#Input-Output-Specification","page":"Input-Output Specification","title":"Input-Output Specification","text":"","category":"section"},{"location":"safety_spec.html#Safety-Property","page":"Input-Output Specification","title":"Safety Property","text":"","category":"section"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"A safety property is essentially an input-output relationship for the model we want to verify. In general, the constraints for the input set mathcalX and the output set mathcalY can have any geometry. For the sake of simplicity, ModelVerification.jl uses convex polytopes and the complement of a polytope to encode the input and output specifications. Specifically, our implementation utilizes the geometric definitions of LazySets, a Julia package for calculus with convex sets. The following section dives into the geometric representations ModelVerification.jl uses and the representations required for each solver. ","category":"page"},{"location":"safety_spec.html#Geometric-Representation","page":"Input-Output Specification","title":"Geometric Representation","text":"","category":"section"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"Different solvers implemented in ModelVerification.jl require the input-output specification formulated with particular geometries. We report here a brief overview of the sets we use. For specifics, please read Algorithms for Verifying Deep Neural Networks by C. Liu, et al.  and Sets in LazySets.jl.","category":"page"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"HR = Hyperrectangle\nHS = HalfSpace\nHP = HPolytope\nSS = StarSet\nIS = ImageStar\nZT = Zonotope\nPC = PolytopeComplement\nCH = ConvexHull","category":"page"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"Solver Input set Output\nAi2 ZT,SS,HP,HR ReachabilityResult, CounterExampleResult\nCROWN ZT,SS,HP,HR,CH BasicResult\nalpha-CROWN ZT,SS,HP,HR,CH BasicResult\nbeta-CROWN ZT,SS,HP,HR,CH BasicResult\nalpha-beta-CROWN ZT,SS,HP,HR,CH BasicResult\nImageZono CH ReachabilityResult, CounterExampleResult\nImageStar CH ReachabilityResult, CounterExampleResult","category":"page"},{"location":"safety_spec.html#Hyperrectangle-([Hyperrectangle](https://juliareach.github.io/LazySets.jl/dev/lib/sets/Hyperrectangle/#def_Hyperrectangle))","page":"Input-Output Specification","title":"Hyperrectangle (Hyperrectangle)","text":"","category":"section"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"Corresponds to a high-dimensional rectangle, defined by","category":"page"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"x-c le r","category":"page"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"where cinmathbbR^k_0 is the center of the hyperrectangle and rinmathbbR^k_0 is the radius of the hyperrectangle.","category":"page"},{"location":"safety_spec.html#HalfSpace-([HalfSpace](https://juliareach.github.io/LazySets.jl/dev/lib/sets/HalfSpace/))","page":"Input-Output Specification","title":"HalfSpace (HalfSpace)","text":"","category":"section"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"Represented by a single linear inequality constraint","category":"page"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"a^top x le b","category":"page"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"where ainmathbbR^k_0 and binmathbbR.","category":"page"},{"location":"safety_spec.html#Halfspace-Polytope-([HPolytope](https://juliareach.github.io/LazySets.jl/dev/lib/sets/HPolytope/#def_HPolytope))","page":"Input-Output Specification","title":"Halfspace-Polytope (HPolytope)","text":"","category":"section"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"HPolytope uses a set of linear inequality constraints to represent a convex polytope, i.e., it is a bounded set defined using an intersection of half-spaces.","category":"page"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"Ax le b","category":"page"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"where AinmathbbR^ktimes k_0 binmathbbR^k with k representing the number of inequality constraints.","category":"page"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"(Image: ) ","category":"page"},{"location":"safety_spec.html#StarSet-([Star](https://juliareach.github.io/LazySets.jl/dev/lib/sets/Star/#def_Star))","page":"Input-Output Specification","title":"StarSet (Star)","text":"","category":"section"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"Only convex star set is considered in this toolbox. A convex star set is an affine transformation of an arbitrary convex polytope,","category":"page"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"x = c + beginbmatrix r_1  r_2  cdots  r_l endbmatrix alpha Calpha le d","category":"page"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"where cinmathbbR^k_0 is the center of the star set, r_iinmathbbR^k_0 iin1dotsl are generators of the star set, CinmathbbR^ktimes l, dinmathbbR^k, alphainmathbbR^l is the free parameter that belongs to a unit hypercube, and k is the number of inequality constraints on alpha. l is the degree of freedom of the star set.","category":"page"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"(Image: )  The general starset, on the left, is not necessarily convex. We only consider convex starsets.","category":"page"},{"location":"safety_spec.html#Zonotope-([Zonotope](https://juliareach.github.io/LazySets.jl/dev/lib/sets/Zonotope/#def_Zonotope))","page":"Input-Output Specification","title":"Zonotope (Zonotope)","text":"","category":"section"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"Zonotope is basically as star set in which all predicate variables are in the range of -1 1. Zonotope represents polytopes that can be written as affine transformations of a unit hypercube, defined as","category":"page"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"x = c + beginbmatrix r_1  r_2  cdots  r_l endbmatrix alpha alpha le 1","category":"page"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"where cinmathbbR^k_0 is the center of the zonotope, r_iinmathbbR^k_0 iin1dotsl are generators of the zonotope, and alphainmathbbR^l is the free parameter that belongs to a unit hypercube. l is the degree of freedom of the zonotope.","category":"page"},{"location":"safety_spec.html#ImageStar","page":"Input-Output Specification","title":"ImageStar","text":"","category":"section"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"ImageStar is an extension of the star set where the center and generators are images with multiple channels.","category":"page"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"x = c + beginbmatrix r_1  r_2  cdots  r_l endbmatrix alpha Calpha le d","category":"page"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"where cinmathbbR^htimes w times k_0 is the center image, r_iinmathbbR^h times w times k_0 iin1dotsl are the generator iamges, CinmathbbR^ktimes l, dinmathbbR^k, and hwk are the height, width, and number of channels (input dimension) of the images respectively. alphainmathbbR^l is the free parameter that belongs to a unit hypercube, and k is the number of inequality constraints on alpha. l is the degree of freedom of the star set.","category":"page"},{"location":"safety_spec.html#ImageZono","page":"Input-Output Specification","title":"ImageZono","text":"","category":"section"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"ImageZono is an extension of the zonotope where the center and generators are images with multiple channels.","category":"page"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"x = c + beginbmatrix r_1  r_2  cdots  r_l endbmatrix alpha","category":"page"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"where cinmathbbR^htimes w times k_0 is the center image, r_iinmathbbR^h times w times k_0 iin1dotsl are the generator iamges, and hwk are the height, width, and number of channels (input dimension) of the images respectively. alphainmathbbR^l is the free parameter that belongs to a unit hypercube and l is the degree of freedom of the zonotope.","category":"page"},{"location":"safety_spec.html#PolytopeComplement-([Complement](https://juliareach.github.io/LazySets.jl/stable/lib/lazy_operations/Complement/))","page":"Input-Output Specification","title":"PolytopeComplement (Complement)","text":"","category":"section"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"PolytopeComplement is a type that represents the complement of a polytope, that is the set","category":"page"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"Y = X^c =  yinmathbbR^n  y notin X ","category":"page"},{"location":"safety_spec.html#References","page":"Input-Output Specification","title":"References","text":"","category":"section"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"[1] C. Liu, T. Arnon, C. Lazarus, C. Strong, C. Barret, and M. J. Kochenderfer, \"Algorithms for Verifying Deep Neural Networks,\" in Foundations and Trends in Optimization, 2021.","category":"page"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"[2] T. Gehr, M. Mirman, D. Drashsler-Cohen, P. Tsankov, S. Chaudhuri, and M. Vechev, \"Ai2: Safety and Robustness Certification of Neural Networks with Abstract Interpretation,\" in 2018 IEEE Symposium on Security and Privacy (SP), 2018.","category":"page"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"[3] M. Forets and C. Schilling, \"LazySets.jl: Scalable Symbolic-Numeric Set Computations,\" in Proceeds of the JuliaCon Conferences, 2021.","category":"page"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"[4] HD. Tran, S. Bak, W. Xiang, and T.T. Johnson, \"Verification of Deep Convolutional Neural Networks Using ImageStars,\" in Computer Aided Verification (CAV), 2020.","category":"page"},{"location":"safety_spec.html#Spec","page":"Input-Output Specification","title":"Spec","text":"","category":"section"},{"location":"safety_spec.html#Specifications","page":"Input-Output Specification","title":"Specifications","text":"","category":"section"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"Spec\nInputSpec\nOutputSpec","category":"page"},{"location":"safety_spec.html#ModelVerification.Spec","page":"Input-Output Specification","title":"ModelVerification.Spec","text":"Spec\n\nAbstract super-type for input-output specifications.\n\n\n\n\n\n","category":"type"},{"location":"safety_spec.html#ModelVerification.InputSpec","page":"Input-Output Specification","title":"ModelVerification.InputSpec","text":"InputSpec\n\nInput specification can be of any type supported by LazySet or ImageConvexHull.\n\n\n\n\n\n","category":"type"},{"location":"safety_spec.html#ModelVerification.OutputSpec","page":"Input-Output Specification","title":"ModelVerification.OutputSpec","text":"OutputSpec\n\nOutput specification can be of any type supported by LazySet or LinearSpec.\n\n\n\n\n\n","category":"type"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"The following are structures for specifications and construction functions for specifications.","category":"page"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"LinearSpec\nget_linear_spec(batch_out_set::AbstractVector)\nReLUConstraints\nReLUConstrainedDomain\nImageConvexHull\nImageLinfBall\nget_image_linf_spec\nclassification_spec(n::Int64, target::Int64)","category":"page"},{"location":"safety_spec.html#ModelVerification.LinearSpec","page":"Input-Output Specification","title":"ModelVerification.LinearSpec","text":"LinearSpec <: Spec\n\nSafety specification defined as the set  x x = A x - b  0 .\n\nFields\n\nA (AbstractArray{Float64, 3}): Normal dierction of size    spec_dim x out_dim x batch_size.\nb (AbstractArray{Float64, 2}): Constraints of size    spec_dim x batch_size.\nis_complement (Bool): Boolean flag for whether this specification is a    complement or not.\n\n\n\n\n\n","category":"type"},{"location":"safety_spec.html#ModelVerification.get_linear_spec-Tuple{AbstractVector}","page":"Input-Output Specification","title":"ModelVerification.get_linear_spec","text":"get_linear_spec(batch_out_set::AbstractVector)\n\nRetrieves the linear specifications of the batch of output sets and returns a LinearSpec structure. \n\nArguments\n\nbatch_out_set (AbstractVector): Batch of output sets.\n\nReturns\n\nLinearSpec of the batch of output sets.\n\n\n\n\n\n","category":"method"},{"location":"safety_spec.html#ModelVerification.ReLUConstraints","page":"Input-Output Specification","title":"ModelVerification.ReLUConstraints","text":"ReLUConstraints\n\nA mutable structure for storing information related to the constraints of a ReLU  (Rectified Linear Unit) activation function in a neural network.\n\nFields\n\nidx_list: A list of indices. \nval_list: A list of values corresponding to the indices in idx_list. \nnot_splitted_mask: A mask indicating which elements in idx_list and    val_list have not been split. This is used in the context of a piecewise    linear approximation of the ReLU function, where the input space is split    into regions where the function is linear.\nhistory_split: A record of the splits that have been performed. \n\n\n\n\n\n","category":"type"},{"location":"safety_spec.html#ModelVerification.ReLUConstrainedDomain","page":"Input-Output Specification","title":"ModelVerification.ReLUConstrainedDomain","text":"ReLUConstrainedDomain <: Spec\n\nA mutable structure for storing specifications related to the ReLU  (Rectified Linear Unit) activation function in a neural network.\n\nFields\n\ndomain: A geometric specification representing the domain of the ReLU    function.\nall_relu_cons: A dictionary of ReLU constraints for each node in the    network.\n\n\n\n\n\n","category":"type"},{"location":"safety_spec.html#ModelVerification.ImageConvexHull","page":"Input-Output Specification","title":"ModelVerification.ImageConvexHull","text":"ImageConvexHull <: Spec\n\nConvex hull for images used to specify safety property for images.  It is the smallest convex polytope that contains all the images given in the imgs array.\n\nFields\n\nimgs (AbstractArray): List of images in AbstractArray. Image is    represented as a matrix of height x weight x channels.\n\n\n\n\n\n","category":"type"},{"location":"safety_spec.html#ModelVerification.ImageLinfBall","page":"Input-Output Specification","title":"ModelVerification.ImageLinfBall","text":"ImageLinfBall\n\nA mutable structure for storing information related to the constraints of a  L-infinity ball for images.\n\nFields\n\nlb: Lower bound of the ball.\nub: Upper bound of the ball.\n\n\n\n\n\n","category":"type"},{"location":"safety_spec.html#ModelVerification.get_image_linf_spec","page":"Input-Output Specification","title":"ModelVerification.get_image_linf_spec","text":"get_image_linf_spec(lb, ub, img_size)\n\nGiven a lower bound lb, an upper bound ub, and the size of the image,  returns a ImageZonoBound structure.\n\nArguments\n\nlb: Lower bound of the image.\nub: Upper bound of the image.\nimg_size: Size of the image.\n\nReturns\n\nImageZonoBound structure.\n\n\n\n\n\n","category":"function"},{"location":"safety_spec.html#ModelVerification.classification_spec-Tuple{Int64, Int64}","page":"Input-Output Specification","title":"ModelVerification.classification_spec","text":"classification_spec(n::Int64, target::Int64)\n\nGenerates an output specification constructed with a convex polyhedron,  HPolyhedron, for classification tasks. Given n-number of labels with  target as the correct label, the resulting polyhedron is the finite  intersection of halfspaces:\n\nP = bigcap_i=1^n H_i\n\nwhere H_i = x  a_i^T x leq 0   iin1n is a halfspace,  a_i is a row vector where the n-th element is 1.0, the target-th  element is -1.0, and the rest are 0's.\n\nArguments\n\nn (Int64): Number of labels.\ntarget (Int64): Target label.\n\nReturns\n\nHPolyhedron specified as above such that the output specification captures    the target label.\n\n\n\n\n\n","category":"method"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"The following are helper functions for retrieving information the specification structures.","category":"page"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"get_size(input_spec::LazySet)\nget_size(input_spec::ImageConvexHull)\nget_shape(input::ImageConvexHull)\nget_shape(input::Hyperrectangle)","category":"page"},{"location":"safety_spec.html#ModelVerification.get_size-Tuple{LazySets.LazySet}","page":"Input-Output Specification","title":"ModelVerification.get_size","text":"get_size(input_spec::LazySet)\n\nGiven a LazySet, it determines the size of the set.\n\n\n\n\n\n","category":"method"},{"location":"safety_spec.html#ModelVerification.get_size-Tuple{ImageConvexHull}","page":"Input-Output Specification","title":"ModelVerification.get_size","text":"get_size(input_spec::ImageConvexHull)\n\nGiven an ImageConvexHull, it determines the size of the image.\n\n\n\n\n\n","category":"method"},{"location":"safety_spec.html#ModelVerification.get_shape-Tuple{ImageConvexHull}","page":"Input-Output Specification","title":"ModelVerification.get_shape","text":"get_shape(input::ImageConvexHull)\n\nReturns the shape of the given ImageConvexHull input set.\n\nArguments\n\ninput (ImageConvexHull): Input set.\n\nReturns\n\nshape (Tuple): Shape of the input set. The last dimension is always the    number of the images. The first dimensions are the shape of the image. For    example, if the input set is consisted of 10 images of size 128 x 128, then    the shape is (128, 128, 10).\n\n\n\n\n\n","category":"method"},{"location":"safety_spec.html#ModelVerification.get_shape-Tuple{LazySets.Hyperrectangle}","page":"Input-Output Specification","title":"ModelVerification.get_shape","text":"get_shape(input::Hyperrectangle)\n\nReturns the shape of the given Hyperrectangle input set.\n\nArguments\n\ninput (Hyperrectangle): Input set.\n\nReturns\n\nshape (Tuple): Shape of the hyperrectangle. The last dimension is always \nFor example, if the input set is a 2D hyperrectangle, then the shape is \n(2, 1).\n\n\n\n\n\n","category":"method"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"The following are helper functions for modifying (scaling) the specification structures.","category":"page"},{"location":"safety_spec.html","page":"Input-Output Specification","title":"Input-Output Specification","text":"scale_set(set::Hyperrectangle, ratio)\nscale_set(set::ImageConvexHull, ratio)","category":"page"},{"location":"safety_spec.html#ModelVerification.scale_set-Tuple{LazySets.Hyperrectangle, Any}","page":"Input-Output Specification","title":"ModelVerification.scale_set","text":"scale_set(set::Hyperrectangle, ratio)\n\nScale the hyperrectangle set by the given ratio. The center of the set is  not changed, but the radius is scaled by the ratio.\n\nArguments\n\nset (Hyperrectangle): The set to be scaled.\nratio (Real): The ratio to scale the set by.\n\nReturns\n\nThe scaled Hyperrectangle set.\n\n\n\n\n\n","category":"method"},{"location":"safety_spec.html#ModelVerification.scale_set-Tuple{ImageConvexHull, Any}","page":"Input-Output Specification","title":"ModelVerification.scale_set","text":"scale_set(set::ImageConvexHull, ratio)\n\nScale the image convex hull set by the given ratio. The first image is not  changed, but the rest of the images are scaled by the ratio. The first image  is not changed because it acts as the \"center\" of the set. \n\nArguments\n\nset (ImageConvexHull): The set to be scaled.\nratio (Real): The ratio to scale the set by.\n\nReturns\n\nThe scaled ImageConvexHull set.\n\n\n\n\n\n","category":"method"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"CurrentModule = ModelVerification","category":"page"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"Pages=[\"toolbox_flow.md\"]\nDepth=2","category":"page"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"Please note that this page is under construction.","category":"page"},{"location":"toolbox_flow.html#Flow","page":"Flow","title":"Flow","text":"","category":"section"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"(Image: )","category":"page"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"This page serves to explain the overall flow of the toolbox. For examples and explanation on how to use specific verification functions, please refer to the tutorials. ","category":"page"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"In general, verification algorithms follow the paradigm of Branch and Bound. This process can be summarized into three steps:","category":"page"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"split the input set into smaller sets, which we call \"branches\",\npropagate the bound through the model for a given branch,\ncheck whether the bound of the final layer satisfies the output specificaiton.","category":"page"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"Repeat or terminate the process based on the result.","category":"page"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"ModelVerification.jl uses a modularized code structure to support various combinations of search methods, split methods, and solvers for a variety of neural network architectures and geometric representations for the safety specifications. After reading through this section, the user should have an overall idea of the flow of the toolbox and the design philosophy behind it. Thanks to the highly modularized structure of the toolbox, the user can add additional functionalities at any layer of the verification process. ","category":"page"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"(Image: )","category":"page"},{"location":"toolbox_flow.html#Definition-of-Terms","page":"Flow","title":"Definition of Terms","text":"","category":"section"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"Here, we define some terms that are unique to the toolbox or are used differently compared to the typical usage.","category":"page"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"Instance: combination of all the necessary information to define an \"instance\" of neural network verification problem. This is consisted of: \nproblem\nsolver\nsearch methods\nsplit methods\nPropagation Method: this is the bound propagation method used for verifying the problem. In other words, it is the choice of term to represent the \"solver\": all the solvers in ModelVerification.jl are represented as a propagation method. However, this is different from the methods in propagate.jl. This will be clearer in the following explanations.\nModel / (Deep) Neural Network / Network: these terms are used interchangeably and represent the deep neural network (DNN) to be verified.\nNode: (This is not equivalent to a \"neuron\" in a traditional deep learning sense.) This refers to a \"node\" in a computational-graph sense.\nLayer: (This is not equivalent to a \"layer\" in a traditional deep learning sense.) This refers to an operation at a node, such as ReLU activation function.\nBaB: \"Branch-and-Bound\" is a method that creates a binary tree for the search space where the verification is employed. \nSet vs Bound: One set is composed of bounds. E.g., for the output reachable set is a union of output bounds. But we use these terms interchangeably throughout the toolbox.","category":"page"},{"location":"toolbox_flow.html#.-Creating-an-instance:-*what-kind-of-verification-problem-do-you-want-to-solve?*","page":"Flow","title":"1. Creating an instance: what kind of verification problem do you want to solve?","text":"","category":"section"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"Let's first create an instance. An instance contains all the information required to run the verify function. This function does the heavy-lifting where the verification problem is solved. As long as the user properly defines the problem and solver methods, this is the only function the user has to call. To run verify, the user has to provide the following arguments. These collectively define an \"instance\":","category":"page"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"SearchMethod: Algorithm for iterating through the branches, such as BFS (breadth-first search) and DFS (depth-first search).\nSplitMethod: Algorithm for splitting an unknown branch into smaller pieces for further refinement. This is also used in the first step of verify to populate the branches bank. In other words, it splits the input specification into branches to facilitate the propagation process.\nPropMethod: Solver used to verify the problem, such as Ai2 and Crown.\nProblem: Problem to be verified. It consists of a Network, and input and output specifications.","category":"page"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"This toolbox design choice allows for extensive customization of methods and solvers by defining different search or split methods. The user simply needs to add their chosen methods in the specific files (search.jl and split.jl), which the solvers will automatically use for the verification process.","category":"page"},{"location":"toolbox_flow.html#[SearchMethod](@ref)","page":"Flow","title":"SearchMethod","text":"","category":"section"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"SearchMethod describes the strategy the solver uses when iterating through the branches. Currently, ModelVerification.jl only supports Breath-first Search (BFS). The solver can exploit parallel analysis of the nodes in the BaB by indicating a batch_size is greater than 1. ","category":"page"},{"location":"toolbox_flow.html#[SplitMethod](@ref)","page":"Flow","title":"SplitMethod","text":"","category":"section"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"SplitMethod specifies how many splits and where they are performed on a single node of the BaB. Depending on the SplitMethod, the solver will split either the input space or the ReLU nodes.","category":"page"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"The following split methods are supported:","category":"page"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"Bisectection (Bisect): splits either the input space or the ReLU nodes.\nBranch-and-bound (BaBSR): splits the ReLU nodes.","category":"page"},{"location":"toolbox_flow.html#[PropMethod](@ref)","page":"Flow","title":"PropMethod","text":"","category":"section"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"PropMethod is the solver to be used for the verification.","category":"page"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"The following solvers are supported:","category":"page"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"ExactReach\nAi2\nImageStar\nImageZono\nCrown\nalpha\n-Crown\nbeta\n-Crown","category":"page"},{"location":"toolbox_flow.html#[Problem](@ref)","page":"Flow","title":"Problem","text":"","category":"section"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"Problem is composed by the model to be verified and the input & output specifications. Specifically, this part of the \"instance\" encodes what we want to verify rather than how we achieve the formal verification results.","category":"page"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"For information on how to load or convert models and how they are represented in ModelVerification.jl, please refer Network.\nFor the different geometric representations for the input and output specifications, please refer Input-Output Specification. ","category":"page"},{"location":"toolbox_flow.html#.-Verifying-the-instance:-*spinning-through-the-branches-where-the-magic-happens!*","page":"Flow","title":"2. Verifying the instance: spinning through the branches - where the magic happens!","text":"","category":"section"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"verify is the main function called by ModelVerification.jl to start the verification process of the \"instance\" provided by the user.","category":"page"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"verify","category":"page"},{"location":"toolbox_flow.html#ModelVerification.verify","page":"Flow","title":"ModelVerification.verify","text":"verify(searchmethod::SearchMethod, splitmethod::SplitMethod,         propmethod::PropMethod, problem::Problem;         timeout=86400, attackrestart=100, collectbound=false,         summary=false, pre_split=nothing)\n\nThis is the main function for verification. It takes in a search method,  a split method, a propagation method, and a problem, and returns a result.  The result is of type ResultInfo, which is a wrapper for the following  Result types: BasicResult, CounterExampleResult, AdversarialResult,  ReachabilityResult, EnumerationResult, or timeout.  For each Result, the status field is either :violated, :verified, or  :unknown. Optional arguments can be passed to the function  to control the timeout, the number of restarts for the attack, whether  to collect the bounds for each branch, whether to print a summary of the  verification process, and whether to pre-split the problem.\n\nArguments\n\nsearch_method (SearchMethod): The search method, such as BFS, used to    search through the branches.\nsplit_method (SplitMethod): The split method, such as Bisect, used to    split the branches.\nprop_method (PropMethod): The propagation method, such as Ai2, used to    propagate the constraints.\nproblem (Problem): The problem to be verified - consists of a network,    input set, and output set.\ntime_out (Int): The timeout in seconds. Defaults to 86400 seconds, or 24    hours. If the timeout is reached, the function returns :timeout.\nattack_restart (Int): The number of restarts for the attack. Defaults to 100.\ncollect_bound (Bool): Whether to collect the bounds for each branch.\nsummary (Bool): Whether to print a summary of the verification process.\npre_split: A function that takes in a Problem and returns a    Problem with the input set pre-split. Defaults to nothing.\nsearch_adv_bound (Bool): Whether to search the maximal input bound that can    pass the verification (get :holds) with the given setting.\n\nReturns\n\nThe result is ResultInfo, the status field is either :violated, :verified,    :unknown, or :timeout. The info is a dictionary that contains other information.\n\n\n\n\n\n","category":"function"},{"location":"toolbox_flow.html#prepare_problem","page":"Flow","title":"prepare_problem","text":"","category":"section"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"The first step of verify is prepare_problem which preprocesses the Problem into a form that is compatible with the verification solver. Its main two functionalities are:","category":"page"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"Retrieves the model information and stores it inside model_info,\nExploits the init_bound function which returns the geometry representation that matches the solver requirements. For instance, since CROWN is a backward propagation method, the init_bound function returns the geometry used to encode the output specification. ","category":"page"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"The result of prepare_problem are two variables:","category":"page"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"model_info: structure that contains information about the Flux model,\nprepared_problem: Problem with a processed input-output specification.","category":"page"},{"location":"toolbox_flow.html#search_branches","page":"Flow","title":"search_branches","text":"","category":"section"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"search_branches(search_method::BFS, split_method, prop_method, problem, model_info)\nadvance_split(max_iter::Int, search_method::BFS, split_method, prop_method, problem, model_info)","category":"page"},{"location":"toolbox_flow.html#ModelVerification.search_branches-Tuple{BFS, Vararg{Any, 4}}","page":"Flow","title":"ModelVerification.search_branches","text":"search_branches(search_method::BFS, split_method, prop_method, \n                problem, model_info)\n\nSearches through the branches in the branch bank, branches, until the branch  bank is empty or time out. In each iteration (up to search_method.max_iter),  a batch of unverified branches will be extracted from the branch bank. Then, the  following is performed to verify the model:\n\nprepare_method initializes the bound of the start node of the \n\ncomputational graph based on the geometric representation and corresponding  solver.\n\npropagate propagates the bound from the start node to the end node of the \n\ncomputational graph.\n\nprocess_bound processes the bounds resulting from the propagation \n\naccordingly to the solver, prop_method. For example, for Ai2-based methods,  process_bound simply returns the bounds from the propagate step. However,  for Crown-based methods, process_bound post-processes the bounds.\n\ncheck_inclusion decides whether the bound of the end node, the reachable \n\nset, satisfies the output specification or not.      1. If not, i.e., :violated, then the counterexample is returned and the      verification process terminates.     2. If yes, i.e., :holds, then the current branch is verified and the      function starts Step 1 again for the next branch, if any.     3. If unknown, i.e., :unknown, further refinement of the problem is      preformed using split_branch, which divides the current branch into      smaller pieces and puts them into the branch bank for further verification.      Such :unknown status results due to the overapproximation introduced in      the verification process.\n\nIf the branch bank is empty after going through search_method.max_iter number  of verification procedures, the model is verified to be valid and returns  :holds. If the branch bank is not empty, the function returns :unknown.\n\nArguments\n\nsearch_method (BFS): Breadth-first Search method for iteratively going    through the branches.\nsplit_method: Method for splitting the branches when further refinement is    needed. This inclueds methods such as Bisect and BaBSR.\nprop_method: Propagation method used for the verification process. This is    one of the solvers used to verify the given model.\nproblem: Problem definition for model verification.\nmodel_info: Structure containing the information of the neural network to be    verified.\ncollect_bound(optional): Default is false, whether return the verified    bound.\npre_split(optional): nothing, the number of split before any propagation.    This is particularly useful for large input set that could lead to memory    overflow.\n\nReturns\n\nBasicResult(:holds) if all the reachable sets are within the corresponding    output specifications in the batch.\nBasicResult(:unknown) if the function failed to make a firm decision within    the given time. This is due to the overapproximation introduced in the    verification process.\nCounterExampleResult(:violated, x) if a reachable set is not within the    corresponding output specification and there is a counterexample found.\n\n\n\n\n\n","category":"method"},{"location":"toolbox_flow.html#ModelVerification.advance_split-Tuple{Int64, BFS, Vararg{Any, 4}}","page":"Flow","title":"ModelVerification.advance_split","text":"advancesplit(maxiter::Int, searchmethod::BFS, splitmethod, propmethod,                problem, modelinfo)\n\nPerforms the splitting of the branches in the branch bank, branches, for a  max_iter number of times. This is used in the search_branches function as  serves as the first step of the verification process: populating the branches  bank with initial branches.\n\nArguments\n\nmax_iter (Int): Maximum number of iterations to split the input   specification.\nsearch_method (BFS): Breadth-first Search method for iteratively going    through the branches.\nsplit_method: Method for splitting the branches for the initial    population of the branch bank. This inclueds methods such as Bisect.\nprop_method: Propagation method used for the verification process. This is    one of the solvers used to verify the given model.\nproblem: Problem definition for model verification. Include the model and    input and output specifications.\nmodel_info: Structure containing the information of the neural network to be   verified.\n\nReturns\n\nbranches: Array of branches to be verified, split from the initial input    specification.\n\n\n\n\n\n","category":"method"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"search_branches is the core function used for the verification process. It consists of several subfunctions that we are going to summarize in the following. At first, the function initializes the branch bank for the entire safety property's input-output domain. This can be done by advance_split, which splits the input-output domain using the given split method. Thus, each \"branch\" is a subpart of the input-output domain. The function seeks to verify all the branches and if it cannot provide a result (i.e., we obtain an :unknown answer), the function proceeds to split branch for a more refined verification process.. If the function verifies all the branches within the given maximum number of iterations, then we obtain a :holds answer. If the function finds any branch that does not satisfy the safety property, then it returns :violated.","category":"page"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"For each iteration, i.e., for each branch, the function calls the following subfunctions to verify the branch:","category":"page"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"prepare_method: this function retrieves all the information to perform either the forward or backward propagation of the input domain of the branch.  The result is stored in two variables called batch_out_spec, batch_info, which contain the batch of the outputs and a dictionary containing all the information of each node in the model. prepare_method calls the following functions in sequence:\ninit_propagation: Differentiates between ForwardProp and BackwardProp. If the solver being used employs a forward propagation method, then we start propagating from the input nodes. If it employs a backward propagation method, then we start from the output nodes.\ninit_batch_bound: Calls init_bound, which returns either the input or output geometry representation based on the type of propagation to perform.\nThe result of the previous function is then used in the propagate function. This function propagates the starting bounds through the model using the specified propagation method, i.e., the solver. The propagate function acts as the overall logic for propagating the branch through the model and performs the propagation based on the layer operation (linear, ReLU, etc.) and the geometric representation for the bounds. The user can add additional layer operators in the propagate/operators folder. Moreover, the toolbox supports skip connections. The propagate function returns batch_bound, the bound of the output node, and an augmented batch_info dictionary with the output bound information added.\nNow, process_bounds returns the reachable bounds obtained from the propagate function. Depending on the solver, the reachable bounds may be post-processed to optimized the verification procedure.\nFinally, check_inclusion checks for the overlapping between the reachable bounds obtained from the propagation and the safety property's output bounds. Since we are using overapproximation of the output reachable set, the only case in which we can obtain :holds result is when the output reachable set is fully contained in the user-specified output set. On the other hand, the :violated result is only possible when the sets are completely disjoint. In all other cases, we have an :unknown answer and we proceed with the branch splitting method below to populate the branch bank.\nsplit_branch is used to split the current branch with :unknown answer into two separate branches which are split based on the split_method. The sub-branches are then added to the \"branches\" bank.","category":"page"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"We continue this loop until either get a :violated result, a :hold result for all the branches, or reach the maximum number of iterations.","category":"page"},{"location":"toolbox_flow.html#search_adv_input_bound","page":"Flow","title":"search_adv_input_bound","text":"","category":"section"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"If the verification result from verify is not :holds, i.e., either :unknown or :violated, then search_adv_input_bound searches for the maximul input bound that can pass the verification, i.e., retrieves :holds, with the given setting. This information is passed to the ResultInfo as a dictionary field so that the user can check.","category":"page"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"search_adv_input_bound","category":"page"},{"location":"toolbox_flow.html#ModelVerification.search_adv_input_bound","page":"Flow","title":"ModelVerification.search_adv_input_bound","text":"search_adv_input_bound(search_method::SearchMethod, \n                       split_method::SplitMethod, \n                       prop_method::PropMethod, \n                       problem::Problem;\n                       eps = 1e-3)\n\nThis function is used to search the maximal input bound that can pass the  verification (get :holds) with the given setting. The search is done by  binary search on the input bound that is scaled by the given ratio. This  function is called in verify function when search_adv_bound is set to  true and the initial verification result is :unknown or :violated. \n\nArguments\n\nsearch_method (SearchMethod): The search method, such as BFS, used to    search through the branches. \nsplit_method (SplitMethod): The split method, such as Bisect, used to    split the branches.\nprop_method (PropMethod): The propagation method, such as Ai2, used to    propagate the constraints.\nproblem (Problem): The problem to be verified - consists of a network,    input set, and output set.\neps (Real): The precision of the binary search. Defaults to 1e-3. \n\nReturns\n\nThe maximal input bound that can pass the verification (get :holds) with    the given setting.\n\n\n\n\n\n","category":"function"},{"location":"toolbox_flow.html#.-Results-and-how-to-interpret-them:-*so-is-my-model-good-to-go?*","page":"Flow","title":"3. Results and how to interpret them: so is my model good to go?","text":"","category":"section"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"Once the verify function is over, it returns a ResultInfo that contains the status (either :hold, :violated, :unknown) and a dictionary that contains any other additional information needed to understand the verification results in detail, such as the verified bounds, adversarial input bounds, etc.","category":"page"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"The following are the Result types used interally for the toolbox to differentiate between different verification results. The result is either a BasicResult, CounterExampleResult,  AdversarialResult, ReachabilityResult, or EnumerationResult (to-be-supported). The status field is either :violated, :holds, or :unknown.","category":"page"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"Output result Explanation\n[BasicResult::holds] The input-output constraint is always satisfied.\n[BasicResult::violated] The input-output constraint is violated, i.e., it exists a single point in the input constraint that violates the property.\n[BasicResult::unknown] Could not be determined if the property holds due to timeout in the computation.\n[CounterExampleResult] Like BasicResult, but also returns a counterexample if one is found (if status = :violated). The counterexample is a point in the input set that, after the NN, lies outside the output constraint set.\n[AdversarialResult] Like BasicResult, but also returns the maximum allowable disturbance in the input (if status = :violated).\n[ReachabilityResult] Like BasicResult, but also returns the output reachable set given the input constraint (if status = :violated).\n[EnumerationResult] Set of all the (un)safe regions in the safety property's domain.","category":"page"},{"location":"toolbox_flow.html","page":"Flow","title":"Flow","text":"For more information, please refer to Output (Verification Results).","category":"page"},{"location":"utils.html","page":"Helper Functions","title":"Helper Functions","text":"CurrentModule = ModelVerification","category":"page"},{"location":"utils.html#Helper-Functions","page":"Helper Functions","title":"Helper Functions","text":"","category":"section"},{"location":"utils.html#Flux-to-Network,-Network-to-Flux","page":"Helper Functions","title":"Flux-to-Network, Network-to-Flux","text":"","category":"section"},{"location":"utils.html","page":"Helper Functions","title":"Helper Functions","text":"network(c::Chain)\nFlux.Chain(m::Network)","category":"page"},{"location":"utils.html#ModelVerification.network-Tuple{Flux.Chain}","page":"Helper Functions","title":"ModelVerification.network","text":"network(c::Chain)\n\nConverts Flux.Chain to a Network.\n\n\n\n\n\n","category":"method"},{"location":"utils.html#Flux.Chain-Tuple{ModelVerification.Network}","page":"Helper Functions","title":"Flux.Chain","text":"Flux.Chain(m::Network)\n\nConverts Network to a Flux.Chain.\n\n\n\n\n\n","category":"method"},{"location":"nnet_converter.html#NNet-Converter","page":"NNet Converter","title":"NNet Converter","text":"","category":"section"},{"location":"nnet_converter.html","page":"NNet Converter","title":"NNet Converter","text":"The following Python scripts are used to convert between different neural network file formats. The supported file formats are as follows:","category":"page"},{"location":"nnet_converter.html","page":"NNet Converter","title":"NNet Converter","text":".onnx (Open Neural Network Exchange): Specification that defines how models should be constructed and the operators in the graph. Open-source project under the Linux Foundation. \n.pb (protobug): Used by TensorFlow's serving when the model needs to be deployed for production. Open-source project that is currently overviewd by Google.\n.h5 (HDF5 binary data format): Originally used by Keras to save models. This file format is less general and more \"data-oriented\" and less programmatic than .pb, but simpler to use than .pb. It is easily convertible to .pb.\n.nnet (NNet): Developed by the Stanford Intelligent Systems Laboratory, initially to define aircraft collision avoidance neural networks in human-readable text document. This format is a simple text-based format for feed-forward, fully-connected, ReLU-activate neural networks.\n.pt (PyTorch): Used by PyTorch.","category":"page"},{"location":"nnet_converter.html#[H5-to-ONNX](https://github.com/intelligent-control-lab/ModelVerification.jl/blob/master/NNet/converters/h52onnx.py)","page":"NNet Converter","title":"H5 to ONNX","text":"","category":"section"},{"location":"nnet_converter.html","page":"NNet Converter","title":"NNet Converter","text":"Converts a .h5 model to an .onnx model.","category":"page"},{"location":"nnet_converter.html","page":"NNet Converter","title":"NNet Converter","text":"~/ModelVerification.jl/NNet/converters$ python h52onnx.py --model_path \"[path/to/h5/file]\" --name_model \"[path/to/converted/onnx/file]\" --test_conversion [True/False]","category":"page"},{"location":"nnet_converter.html#[NNET-to-ONNX](https://github.com/intelligent-control-lab/ModelVerification.jl/blob/master/NNet/converters/nnet2onnx.py)","page":"NNet Converter","title":"NNET to ONNX","text":"","category":"section"},{"location":"nnet_converter.html","page":"NNet Converter","title":"NNet Converter","text":"Converts a .nnet model to an .onnx model.","category":"page"},{"location":"nnet_converter.html","page":"NNet Converter","title":"NNet Converter","text":"~/ModelVerification.jl/NNet/converters$ python nnet2onnx.py [nnetFile] [onnxFile] [outputName] [normalizeNetwork]","category":"page"},{"location":"nnet_converter.html","page":"NNet Converter","title":"NNet Converter","text":"where ","category":"page"},{"location":"nnet_converter.html","page":"NNet Converter","title":"NNet Converter","text":"nnetFile: (string) .nnet file to convert to onnx.\nonnxFile: (string, optional) Optional, name for the created .onnx file.\noutputName: (string, optional) Optional, name of the output variable in onnx.\nnormalizeNetwork: (bool, optional) If true, adapt the network weights and biases so that networks and inputs do not need to be normalized. Default is False.","category":"page"},{"location":"nnet_converter.html#[NNET-to-PB](https://github.com/intelligent-control-lab/ModelVerification.jl/blob/master/NNet/converters/nnet2pb.py)","page":"NNet Converter","title":"NNET to PB","text":"","category":"section"},{"location":"nnet_converter.html","page":"NNet Converter","title":"NNet Converter","text":"Converts a .nnet model to a .pb model.","category":"page"},{"location":"nnet_converter.html","page":"NNet Converter","title":"NNet Converter","text":"~/ModelVerification.jl/NNet/converters$ python nnet2pb.py [nnetFile] [pbFile] [output_node_names]","category":"page"},{"location":"nnet_converter.html","page":"NNet Converter","title":"NNet Converter","text":"nnetFile (string): A .nnet file to convert to Tensorflow format.\npbFile (string, optional): Name for the created .pb file. Default: \"\".\noutput_node_names (string, optional): Name of the final operation in the Tensorflow graph. Default: \"y_out\".","category":"page"},{"location":"nnet_converter.html#[ONNX-to-NNET](https://github.com/intelligent-control-lab/ModelVerification.jl/blob/master/NNet/converters/onnx2nnet.py)","page":"NNet Converter","title":"ONNX to NNET","text":"","category":"section"},{"location":"nnet_converter.html","page":"NNet Converter","title":"NNet Converter","text":"Converts an .onnx model to a .nnet model.","category":"page"},{"location":"nnet_converter.html","page":"NNet Converter","title":"NNet Converter","text":"~/ModelVerification.jl/NNet/converters$ python onnx2nnet.py [onnxFile] [nnetFile]","category":"page"},{"location":"nnet_converter.html","page":"NNet Converter","title":"NNet Converter","text":"onnxFile (string): Path to .onnx file.\nnnetFile (string, optional): Name for the created .nnet file.","category":"page"},{"location":"nnet_converter.html#[PB-to-NNET](https://github.com/intelligent-control-lab/ModelVerification.jl/blob/master/NNet/converters/pb2nnet.py)","page":"NNet Converter","title":"PB to NNET","text":"","category":"section"},{"location":"nnet_converter.html","page":"NNet Converter","title":"NNet Converter","text":"Converts a .pb model to a .nnet model.","category":"page"},{"location":"nnet_converter.html","page":"NNet Converter","title":"NNet Converter","text":"~/ModelVerification.jl/NNet/converters$ python pb2nnet.py [pbFile]","category":"page"},{"location":"nnet_converter.html","page":"NNet Converter","title":"NNet Converter","text":"pbFile (string): If savedModel is false, it is the path to the frozen graph .pb file. If savedModel is true, it is the path to the savedModel folder, which contains .pb file and variables subdirectory.","category":"page"},{"location":"nnet_converter.html#[PT-to-ONNX](https://github.com/intelligent-control-lab/ModelVerification.jl/blob/master/NNet/converters/pt2onnx.py)","page":"NNet Converter","title":"PT to ONNX","text":"","category":"section"},{"location":"nnet_converter.html","page":"NNet Converter","title":"NNet Converter","text":"Converts a .pt model to an .onnx model.","category":"page"},{"location":"nnet_converter.html","page":"NNet Converter","title":"NNet Converter","text":"~/ModelVerification.jl/NNet/converters$ python pt2onnx.py --model_path \"[path/to/h5/file]\" --name_model \"[path/to/converted/onnx/file]\" --test_conversion [True/False]","category":"page"},{"location":"python_interface.html#Python-Interface","page":"Python Interface","title":"Python Interface","text":"","category":"section"},{"location":"python_interface.html","page":"Python Interface","title":"Python Interface","text":"TO-BE-DEVELOPED","category":"page"},{"location":"problem.html","page":"Problem Outline","title":"Problem Outline","text":"CurrentModule = ModelVerification","category":"page"},{"location":"problem.html","page":"Problem Outline","title":"Problem Outline","text":"Pages=[\"problem.md\"]\nDepth = 3","category":"page"},{"location":"problem.html#Problem-Outline","page":"Problem Outline","title":"Problem Outline","text":"","category":"section"},{"location":"problem.html","page":"Problem Outline","title":"Problem Outline","text":"Verification checks if the input-output relationships of a function, specifically deep neural networks (DNN) mathcalF in this case, hold. For an input specification imposed by a set mathcalXsubseteq mathcalD_x, we would like to check if the corresponding output of the function is contained in an output specification imposed by a set mathcalYsubseteq mathcalD_y:","category":"page"},{"location":"problem.html","page":"Problem Outline","title":"Problem Outline","text":"xinmathcalX Longrightarrow y = mathcalF(x) in mathcalY","category":"page"},{"location":"problem.html","page":"Problem Outline","title":"Problem Outline","text":"Thus, a DNN-Verification problem consists of two main components:","category":"page"},{"location":"problem.html","page":"Problem Outline","title":"Problem Outline","text":"model (DNN) : mathcalF\nsafety property (input-output specification) : mathcalX mathcalY.","category":"page"},{"location":"problem.html","page":"Problem Outline","title":"Problem Outline","text":"(Image: )","category":"page"},{"location":"problem.html","page":"Problem Outline","title":"Problem Outline","text":"Due to the nonlinear and nonconvex nature of DNNs, estimating the exact reachable set is impractical, although there are algorithms that allow us to do this such as ExactReach. Thus, we preform an over-approximation of the reachable set, called mathcalR. We check its containment in the desired reachable set mathcalY which if ture, we can assert that the safety property holds.","category":"page"},{"location":"problem.html","page":"Problem Outline","title":"Problem Outline","text":"Below, we give a brief overview of models (Network), safety property, and outputs (verification results).","category":"page"},{"location":"problem.html#Network","page":"Problem Outline","title":"Network","text":"","category":"section"},{"location":"problem.html","page":"Problem Outline","title":"Problem Outline","text":"Details on Network","category":"page"},{"location":"problem.html#Safety-Property","page":"Problem Outline","title":"Safety Property","text":"","category":"section"},{"location":"problem.html","page":"Problem Outline","title":"Problem Outline","text":"Details on Input-Output Specification","category":"page"},{"location":"problem.html#Output-(Verification-Results)","page":"Problem Outline","title":"Output (Verification Results)","text":"","category":"section"},{"location":"problem.html","page":"Problem Outline","title":"Problem Outline","text":"The following are the different result types used internally in the toolbox. We outline them here so that the user can have a better idea of what kind of conclusion the toolbox makes. ","category":"page"},{"location":"problem.html","page":"Problem Outline","title":"Problem Outline","text":"The user has to only interact with the wrapper ResultInfo, which contains the status and any other additional information needed to help understand the verification result. ","category":"page"},{"location":"problem.html","page":"Problem Outline","title":"Problem Outline","text":"Output result Explanation\n[BasicResult::holds] The input-output constraint is always satisfied.\n[BasicResult::violated] The input-output constraint is violated, i.e., it exists a single point in the input constraint that violates the property.\n[BasicResult::unknown] Could not be determined if the property holds due to timeout in the computation.\n[CounterExampleResult] Like BasicResult, but also returns a counterexample if one is found (if status = :violated). The counterexample is a point in the input set that, after the NN, lies outside the output constraint set.\n[AdversarialResult] Like BasicResult, but also returns the maximum allowable disturbance in the input (if status = :violated).\n[ReachabilityResult] Like BasicResult, but also returns the output reachable set given the input constraint (if status = :violated).\n[EnumerationResult] Set of all the (un)safe regions in the safety property's domain.","category":"page"},{"location":"problem.html","page":"Problem Outline","title":"Problem Outline","text":"(Image: )","category":"page"},{"location":"problem.html#Problem","page":"Problem Outline","title":"Problem","text":"","category":"section"},{"location":"problem.html","page":"Problem Outline","title":"Problem Outline","text":"Problem\nprepare_problem(search_method::SearchMethod, split_method::SplitMethod, prop_method::PropMethod, problem::Problem)","category":"page"},{"location":"problem.html#ModelVerification.Problem","page":"Problem Outline","title":"ModelVerification.Problem","text":"Problem{P, Q}(network::Network, input::P, output::Q)\n\nProblem definition for neural verification. The verification problem consists of: for all  points in the input set, the corresponding output of the network must belong to the output set.\n\nThere are three ways to construct a Problem:\n\nProblem(path::String, model::Chain, input_data, output_data) if both the    .onnx model path and Flux_model are given.\nProblem(path::String, input_data, output_data) if only the .onnx model   path is given.\nProblem(model::Chain, input_data, output_data) if only the Flux_model is   given.\n\nFields\n\nnetwork : Network that can be constructed either using the path to an onnx   model or a Flux.Chain structure.\ninput : Input specification defined using a LazySet.\noutput : Output specification defined using a LazySet.\n\n\n\n\n\n","category":"type"},{"location":"problem.html#ModelVerification.prepare_problem-Tuple{SearchMethod, SplitMethod, PropMethod, Problem}","page":"Problem Outline","title":"ModelVerification.prepare_problem","text":"prepare_problem(search_method::SearchMethod, split_method::SplitMethod, \n                prop_method::PropMethod, problem::Problem)\n\nConverts the given Problem into a form that is compatible with the verification process of the toolbox. In particular, it retrieves information about the ONNX  model to be verified and stores them into a Model. It returns the Problem  itself and the Model structure. \n\nArguments\n\nsearch_method (SearchMethod): Search method for the verification process.\nsplit_method (SplitMethod): Split method for the verification process.\nprop_method (PropMethod): Propagation method for the verification process.\nproblem (Problem): Problem definition for model verification.\n\nReturns\n\nmodel_info (Model): Information about the model to be verified.\nproblem (Problem): The given problem definition for model verification.\n\n\n\n\n\n","category":"method"},{"location":"problem.html#Result","page":"Problem Outline","title":"Result","text":"","category":"section"},{"location":"problem.html","page":"Problem Outline","title":"Problem Outline","text":"Result\nResultInfo\nBasicResult\nCounterExampleResult\nAdversarialResult\nReachabilityResult\nstatus\nvalidate_status","category":"page"},{"location":"problem.html#ModelVerification.Result","page":"Problem Outline","title":"ModelVerification.Result","text":"Result\n\nSupertype of all result types.\n\nSee also: \n\nBasicResult \nCounterExampleResult\nAdversarialResult\nReachabilityResult\n\n\n\n\n\n","category":"type"},{"location":"problem.html#ModelVerification.ResultInfo","page":"Problem Outline","title":"ModelVerification.ResultInfo","text":"ResultInfo(status, info)\n\nLike BasicResult, but also returns a info dictionary that contains other  informations. This is designed to be the general result type. \n\nFields\n\nstatus (Symbol): Status of the result, can be :holds, :violated, or    :unknown.\ninfo (Dict): A dictionary that contains information related to the result,    such as the verified bounds, adversarial input bounds, counter example, etc.\n\n\n\n\n\n","category":"type"},{"location":"problem.html#ModelVerification.BasicResult","page":"Problem Outline","title":"ModelVerification.BasicResult","text":"BasicResult(status)\n\nResult type that captures whether the input-output constraint is satisfied. Possible status values:\n\n:holds (io constraint is satisfied always)\n\n:violated (io constraint is violated)\n\n:unknown (could not be determined)\n\nFields\n\nstatus (Symbol): Status of the result, can be :holds, :violated, or    :unknown.\n\n\n\n\n\n","category":"type"},{"location":"problem.html#ModelVerification.CounterExampleResult","page":"Problem Outline","title":"ModelVerification.CounterExampleResult","text":"CounterExampleResult(status, counter_example)\n\nLike BasicResult, but also returns a counter_example if one is found (if status = :violated). The counter_example is a point in the input set that, after the NN, lies outside the output set.\n\n\n\n\n\n","category":"type"},{"location":"problem.html#ModelVerification.AdversarialResult","page":"Problem Outline","title":"ModelVerification.AdversarialResult","text":"AdversarialResult(status, max_disturbance)\n\nLike BasicResult, but also returns the maximum allowable disturbance in the input (if status = :violated).\n\n\n\n\n\n","category":"type"},{"location":"problem.html#ModelVerification.ReachabilityResult","page":"Problem Outline","title":"ModelVerification.ReachabilityResult","text":"ReachabilityResult(status, reachable)\n\nLike BasicResult, but also returns the output reachable set given the input constraint (if status = :violated).\n\n\n\n\n\n","category":"type"},{"location":"problem.html#ModelVerification.status","page":"Problem Outline","title":"ModelVerification.status","text":"status(result::Result)\n\nReturns the status of the result. Only (:holds, :violated, :unknown) are  accepted.\n\n\n\n\n\n","category":"function"},{"location":"problem.html#ModelVerification.validate_status","page":"Problem Outline","title":"ModelVerification.validate_status","text":"validate_status(st)\n\nValidates the status code. Only (:holds, :violated, :unknown) are accepted.\n\nArguments\n\nst (Symbol): Status code.\n\nReturns\n\nAssertion Error if the given st is not one of (:holds, :violated, :unknown).\nOtherwise, returns the given st.\n\n\n\n\n\n","category":"function"},{"location":"attack.html#Attacks","page":"Attacks","title":"Attacks","text":"","category":"section"},{"location":"attack.html","page":"Attacks","title":"Attacks","text":"Modules=[ModelVerification]\nPages=[\"pgd.jl\"]","category":"page"},{"location":"attack.html#ModelVerification.APGD-NTuple{4, Any}","page":"Attacks","title":"ModelVerification.APGD","text":"APGD(model, loss, x, y; ϵ = 10, step_size = 0.1, iters = 100, clamp_range = (0, 1))\n\nAuto Projected Gradient Descent (APGD) (https://arxiv.org/pdf/2003.01690.pdf)\n\nArguments:\n\nmodel: The model to base teh attack upon.\nloss: the loss function to use, assuming that it includes the prediction function   i.e. loss(x, y) = crossentropy(m(x), y)\nx: The input to be perturbed.\nstep_size: The ϵ value in the FGSM step.\nrho: PGD success rate threshold to reduce the step size.\na: momentum.\niters: The maximum number of iterations to run the algorithm for.\n\n\n\n\n\n","category":"method"},{"location":"attack.html#ModelVerification.FGSM-Tuple{Any, Any, Any}","page":"Attacks","title":"ModelVerification.FGSM","text":"FGSM(model, loss, x, y; ϵ = 0.1, clamp_range = (0, 1))\n\nFast Gradient Sign Method (FGSM) is a method of creating adversarial examples by pushing the input in the direction of the gradient and bounded by the ε parameter.\n\nThis method was proposed by Goodfellow et al. 2014 (https://arxiv.org/abs/1412.6572)\n\nArguments:\n\nmodel: The model to base the attack upon.\nloss: The loss function to use. This assumes that the loss function includes   the predict function, i.e. loss(x, y) = crossentropy(model(x), y).\nx: The input to be perturbed by the FGSM algorithm.\nϵ: The amount of perturbation to apply.\n\n\n\n\n\n","category":"method"},{"location":"attack.html#ModelVerification.PGD-NTuple{4, Any}","page":"Attacks","title":"ModelVerification.PGD","text":"PGD(model, loss, x, y; ϵ = 10, step_size = 0.1, iters = 100, clamp_range = (0, 1))\n\nProjected Gradient Descent (PGD) is an itrative variant of FGSM with a random point. For every step the FGSM algorithm moves the input in the direction of the gradient bounded in the l∞ norm. (https://arxiv.org/pdf/1706.06083.pdf)\n\nArguments:\n\nmodel: The model to base teh attack upon.\nloss: the loss function to use, assuming that it includes the prediction function   i.e. loss(x, y) = crossentropy(m(x), y)\nx: The input to be perturbed.\nstep_size: The ϵ value in the FGSM step.\niters: The maximum number of iterations to run the algorithm for.\n\n\n\n\n\n","category":"method"},{"location":"attack.html#ModelVerification.attack-Tuple{Any, Any, Any}","page":"Attacks","title":"ModelVerification.attack","text":"attack(model, input, output; restart=100)\n\n\n\n\n\n","category":"method"},{"location":"attack.html#ModelVerification.attack-Tuple{Any}","page":"Attacks","title":"ModelVerification.attack","text":"attack(problem; restart=100)\n\n\n\n\n\n","category":"method"},{"location":"attack.html#ModelVerification.project-Tuple{Any, AbstractVector, LazySets.Hyperrectangle}","page":"Attacks","title":"ModelVerification.project","text":"project(x, dir::AbstractVector, set::Hyperrectangle)\n\n\n\n\n\n","category":"method"},{"location":"attack.html#ModelVerification.project-Tuple{Any, AbstractVector, LazySets.LazySet}","page":"Attacks","title":"ModelVerification.project","text":"project(x, dir::AbstractVector, set::LazySet)\n\n\n\n\n\n","category":"method"},{"location":"attack.html#ModelVerification.project-Tuple{Any, LazySets.Hyperrectangle}","page":"Attacks","title":"ModelVerification.project","text":"project(p, rect::Hyperrectangle)\n\n\n\n\n\n","category":"method"},{"location":"attack.html#ModelVerification.project-Tuple{Any, LazySets.LazySet}","page":"Attacks","title":"ModelVerification.project","text":"project(p, polytope::LazySet)\n\n\n\n\n\n","category":"method"},{"location":"benchmark.html#Benchmark","page":"Benchmark","title":"Benchmark","text":"","category":"section"},{"location":"index.html#ModelVerification.jl","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"","category":"section"},{"location":"index.html","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Pages=[\"index.md\"]","category":"page"},{"location":"index.html#Introduction","page":"ModelVerification.jl","title":"Introduction","text":"","category":"section"},{"location":"index.html","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Deep Neural Network (DNN) is crucial in approximating nonlinear functions across diverse applications, such as computer vision and control. Verifying specific input-output properties can be a highly challenging task. To this end, we present ModelVerification.jl, the only cutting-edge toolbox that contains a suite of state-of-the-art methods for verifying DNNs. This toolbox significantly extends and improves the previous version (NeuralVerification.jl) and is designed to empower developers and machine learning practioners with robust tools for verifying and ensuring the trustworthiness of their DNN models.","category":"page"},{"location":"index.html#Key-features:","page":"ModelVerification.jl","title":"Key features:","text":"","category":"section"},{"location":"index.html","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Julia and Python integration: Built on Julia programming language, ModelVerification.jl leverages Julia's high-performance capabilities, ensuring efficient and scalable verification processes. Moreover, we provide the user with an easy, ready-to-use Python interface to exploit the full potential of the toolbox even without knowledge of the Julia language (for future versions).\nDifferent types of verification: ModelVerification.jl enables verification of several input-output specifications, such as reacability analysis, behavioral properties (e.g., to verify Deep Reinforcement Learning policies), or even robustness properties for Convolutional Neural Network (CNN). It also introduces new types of verification, not only for finding individual adversarial input, but for enumerating the entire set of unsafe zones for a given network and safety properties.\nVisualization of intermediate verification results (reachable sets): ModelVerification.jl enables the visualization of intermediate verification results in terms of reachable sets. In particular, our toolbox allows to plot the impactful features for the verification process and the correlated output reachable set (layer by layer) and thus to define new specific input-output specifications based on this information.\nVerification benchmarks: Compare our or your verification toolboxes against state-of-the-art benchmarks and evaluation criteria (VNN-Comp 2023). ModelVerification.jl includes a collection of solvers and standard benchmarks to perform this evaluation efficiently.","category":"page"},{"location":"index.html#Setup","page":"ModelVerification.jl","title":"Setup","text":"","category":"section"},{"location":"index.html","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"This toolbox requires Julia v1.5 or later. Refer the official Julia documentation to install it for your system.","category":"page"},{"location":"index.html#Installation","page":"ModelVerification.jl","title":"Installation","text":"","category":"section"},{"location":"index.html","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"To download this toolbox, clone it from the Julia package manager like so:","category":"page"},{"location":"index.html","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"pkg> add https://github.com/intelligent-control-lab/ModelVerification.jl/","category":"page"},{"location":"index.html#Develop-the-toolbox-(for-development)","page":"ModelVerification.jl","title":"Develop the toolbox (for development)","text":"","category":"section"},{"location":"index.html","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Deprecated once project is done and should be changed to \"Building the package\".","category":"page"},{"location":"index.html","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Go to the toolbox directory and start the Julia REPL. ","category":"page"},{"location":"index.html","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"julia > ]\n(@v1.9) > develop .\n(@v1.9) > activate .\n(@v1.9) > instantiate","category":"page"},{"location":"index.html","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"This will enable development mode for the toolbox. The dependency packages will also be installed. Some of the important ones are listed below. ","category":"page"},{"location":"index.html","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Flux\nLazySets\nJuMP\nZygote","category":"page"},{"location":"index.html#Overview-of-the-toolbox","page":"ModelVerification.jl","title":"Overview of the toolbox","text":"","category":"section"},{"location":"index.html","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"(Image: )","category":"page"},{"location":"index.html","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"ModelVerification.jl receives input as a set consisting of:","category":"page"},{"location":"index.html","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Model to be verified,\nA safety property encoded as input-output specifications for the neural network,\nThe solver to be used for the formal verification process.","category":"page"},{"location":"index.html","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"The toolbox's output varies depending on the type of verification we are performing. Nonetheless, at the end of the verification process, the response of the toolbox potentially allows us to obtain provable guarantees that a given safety property holds (or does not hold) for the model tested.","category":"page"},{"location":"index.html","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"For more details on how the toolbox works, please refer to the tutorial below.","category":"page"},{"location":"index.html#Quickstart","page":"ModelVerification.jl","title":"Quickstart","text":"","category":"section"},{"location":"index.html","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Here is a simple example for verifying that the user-given safety property holds for a small deep neural network (DNN) with a single input node, two hidden layers with two ReLU nodes, and a single output node. We use the formal verification results obtained through the reachability analysis to get a provable answer whether the safety property holds.","category":"page"},{"location":"index.html","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"First, we load the relevant libraries and the ModelVerification.jl toolbox.","category":"page"},{"location":"index.html","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"using ModelVerification\nusing Flux\nusing LazySets","category":"page"},{"location":"index.html","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"First, load the model.","category":"page"},{"location":"index.html","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"onnx_path = \"models/small_nnet.onnx\"\ntoy_model = ModelVerification.build_flux_model(onnx_path)","category":"page"},{"location":"index.html","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Suppose we want to verify that all inputs in mathcalX=-25 25 are mapped into mathcalY=185 1145. We encode this safety property using convex sets, provided by LazySets. ","category":"page"},{"location":"index.html","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"X = Hyperrectangle(low = [-2.5], high = [2.5]) # expected out: [18.5, 114.5]\nY = Hyperrectangle(low = [18.5], high = [114.5]) # here we expect the property holds","category":"page"},{"location":"index.html","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Now, we construct a Problem instance. Note that ModelVerification.jl converts the .onnx model into a Flux model.","category":"page"},{"location":"index.html","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"problem = Problem(toy_model, X, Y)","category":"page"},{"location":"index.html","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Instantiate the solver, which in this case is CROWN. We also need search, split, and propagation methods in addition to the solver and Problem.","category":"page"},{"location":"index.html","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"search_method = BFS(max_iter=100, batch_size=1)\nsplit_method = Bisect(1)\n\nuse_gpu = false\nlower_bound = true\nupper_bound = true\nsolver = Crown(use_gpu, lower_bound, upper_bound)","category":"page"},{"location":"index.html","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Finally, we can verify that the safety property holds for this simple example!","category":"page"},{"location":"index.html","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"result = verify(search_method, split_method, solver, problem)\nprintln(result)\nprintln(result.status)","category":"page"},{"location":"index.html","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"CROWN verifies that the input-output relationship holds!","category":"page"},{"location":"index.html#Tutorials","page":"ModelVerification.jl","title":"Tutorials","text":"","category":"section"},{"location":"index.html","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Tutorials\nExample 1: Verifying a toy DNN with reachability analysis\nExample 2: Verifying a CNN for robustness safety property\nExample 3: Verifying a Deep Reinforcement Learning (DRL) policy for collision avoidance safety property","category":"page"},{"location":"index.html#Toolbox-Outline","page":"ModelVerification.jl","title":"Toolbox Outline","text":"","category":"section"},{"location":"index.html","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"(Image: ) For detailed examples on how to use different functionalities provided by the toolbox, please refer to the Tutorials. The pages below will direct you to the respective documentation for each category.","category":"page"},{"location":"index.html","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Pages = [\"toolbox_flow.md\", \"problem.md\", \"network.md\", \"safety_spec.md\", \"branching.md\", \"propagate.md\", \"solvers.md\", \"attack.md\", \"utils.md\"]\nDepth = 3","category":"page"},{"location":"index.html#Python-Interface","page":"ModelVerification.jl","title":"Python Interface","text":"","category":"section"},{"location":"index.html","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"[Python Interface](./pythoninterface.md) is currently in development._","category":"page"},{"location":"index.html","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"ModelVerification.jl provides an interface with Python so that users who are not familiar with Julia can still use the toolbox via Python. Moreover, it provides converters in Python for converting between different neural network file formats, such as .onnx, .pb, .pt, .h5, and .nnet.","category":"page"},{"location":"index.html","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Pages = [\"nnet_converter.md\", \"python_interface.md\"]\nDepth = 3","category":"page"}]
}
