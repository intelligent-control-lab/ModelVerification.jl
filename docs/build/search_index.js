var documenterSearchIndex = {"docs":
[{"location":"branching/","page":"Branching","title":"Branching","text":"Pages=[\"branching.md\"]\nDepth = 3","category":"page"},{"location":"branching/#Branching","page":"Branching","title":"Branching","text":"","category":"section"},{"location":"branching/","page":"Branching","title":"Branching","text":"The \"branch\" part of the Branch and Bound paradigm for verification algorithms. The branching folder contains algorithms for dividing the input set into searchable smaller sets, which we call \"branches.\" ","category":"page"},{"location":"branching/","page":"Branching","title":"Branching","text":"The search.jl module includes algorithms to iterate over all branches, such as BFS (Breadth-first Search) and DFS (Depth-first Search). The search.jl\\search_branches function is of particular importance since it executes the verification procedure.","category":"page"},{"location":"branching/","page":"Branching","title":"Branching","text":"The split.jl module includes algorithms to split an unknown branch, such as bisect, sensitivity analysis, etc. The split.jl\\split_branch function divides the unknown branches into smaller pieces and put them back to the branch bank for future verification. This is done so that we can get a more concrete answer by refining the problem in case the over-approximation introduced in the verification process prevents us from getting a firm result.","category":"page"},{"location":"branching/#Search","page":"Branching","title":"Search","text":"","category":"section"},{"location":"branching/","page":"Branching","title":"Branching","text":"Modules=[ModelVerification]\nPages=[\"search.jl\"]","category":"page"},{"location":"branching/#ModelVerification.BFS","page":"Branching","title":"ModelVerification.BFS","text":"BFS <: SearchMethod\n\nBreadth-first Search (BFS) \n\nFields\n\nmax_iter : \nbatch_size : \n\n\n\n\n\n","category":"type"},{"location":"branching/#ModelVerification.search_branches-Tuple{BFS, Vararg{Any, 4}}","page":"Branching","title":"ModelVerification.search_branches","text":"search_branches(search_method, split_method, prop_method, problem, model_info)\n\n(Kai) Essentially THE FUNCTION that does the heavy lifting... Think of prop_method as the solver. Well, it is. This returns the result.\n\n\n\n\n\n","category":"method"},{"location":"branching/#Split","page":"Branching","title":"Split","text":"","category":"section"},{"location":"branching/","page":"Branching","title":"Branching","text":"Modules=[ModelVerification]\nPages=[\"split.jl\"]","category":"page"},{"location":"branching/#ModelVerification.BaBSR","page":"Branching","title":"ModelVerification.BaBSR","text":"BaBSR <: SplitMethod\n\nBranch-and-Bound method for splitting.\n\n\n\n\n\n","category":"type"},{"location":"branching/#ModelVerification.Bisect","page":"Branching","title":"ModelVerification.Bisect","text":"Bisect <: SplitMethod\n\n\n\n\n\n","category":"type"},{"location":"branching/#ModelVerification.InputGradSplit","page":"Branching","title":"ModelVerification.InputGradSplit","text":"InputGradSplit <: SplitMethod\n\n\n\n\n\n","category":"type"},{"location":"branching/#ModelVerification.branching_scores_kfsb-Tuple{Any, Any, Any}","page":"Branching","title":"ModelVerification.branching_scores_kfsb","text":"branching_scores_kfsb(model_info, batch_info, input)\n\n\"Kernel Function Split Branch\"\n\n\n\n\n\n","category":"method"},{"location":"branching/#ModelVerification.split_beta-NTuple{8, Any}","page":"Branching","title":"ModelVerification.split_beta","text":"split_beta(S_dict, score, split_relu_node, i, split_neurons_index_in_node, j, input, output)\n\n\n\n\n\n","category":"method"},{"location":"branching/#ModelVerification.split_branch-Tuple{BaBSR, Flux.Chain, Tuple, Any, Any, Any}","page":"Branching","title":"ModelVerification.split_branch","text":"split_branch(split_method::BaBSR, model::Chain, input::Tuple, output, model_info, batch_info)\n\n\n\n\n\n","category":"method"},{"location":"branching/#ModelVerification.split_branch-Tuple{Bisect, Flux.Chain, LazySets.Hyperrectangle, Any, Any, Any}","page":"Branching","title":"ModelVerification.split_branch","text":"split_branch(split_method::Bisect, model::Chain, input::Hyperrectangle, output, model_info, batch_info)\n\n\n\n\n\n","category":"method"},{"location":"branching/#ModelVerification.split_branch-Tuple{Bisect, Flux.Chain, LazySets.LazySet, Any, Any, Any}","page":"Branching","title":"ModelVerification.split_branch","text":"split_branch(split_method::Bisect, model::Chain, input::LazySet, output, model_info, batch_info)\n\n\n\n\n\n","category":"method"},{"location":"branching/#ModelVerification.split_branch-Tuple{Bisect, Flux.Chain, ModelVerification.ImageStarBound, Any, Any, Any}","page":"Branching","title":"ModelVerification.split_branch","text":"split_branch(split_method::Bisect, model::Chain, input::ImageStarBound, output, model_info, batch_info)\n\n\n\n\n\n","category":"method"},{"location":"branching/#ModelVerification.split_branch-Tuple{Bisect, Flux.Chain, ModelVerification.ImageStarBound, Any}","page":"Branching","title":"ModelVerification.split_branch","text":"split_branch(split_method::Bisect, model::Chain, input::ImageStarBound, output)\n\n\n\n\n\n","category":"method"},{"location":"branching/#ModelVerification.split_branch-Tuple{Bisect, Flux.Chain, ModelVerification.ImageZonoBound, Any, Any, Any}","page":"Branching","title":"ModelVerification.split_branch","text":"split_branch(split_method::Bisect, model::Chain, input::ImageZonoBound, output, model_info, batch_info)\n\n\n\n\n\n","category":"method"},{"location":"branching/#ModelVerification.split_branch-Tuple{Bisect, Flux.Chain, ModelVerification.ImageZonoBound, Any}","page":"Branching","title":"ModelVerification.split_branch","text":"split_branch(split_method::Bisect, model::Chain, input::ImageZonoBound, output)\n\n\n\n\n\n","category":"method"},{"location":"branching/#ModelVerification.split_interval-Tuple{LazySets.Hyperrectangle, Int64}","page":"Branching","title":"ModelVerification.split_interval","text":"split_interval(dom, i)\n\nSplit a set into two at the given index.\n\nInputs:\n\ndom::Hyperrectangle: the set to be split\ni: the index to split at\n\nReturn:\n\n(left, right)::Tuple{Hyperrectangle, Hyperrectangle}: two sets after split\n\n\n\n\n\n","category":"method"},{"location":"branching/#ModelVerification.topk-Tuple{Any, Any, Any}","page":"Branching","title":"ModelVerification.topk","text":"topk(score, k, model_info)\n\n\"Top Kernel\"\n\n\n\n\n\n","category":"method"},{"location":"branching/#ModelVerification.vecmask_convert_to_original_size-Tuple{Any, Any}","page":"Branching","title":"ModelVerification.vecmask_convert_to_original_size","text":"vecmask_convert_to_original_size(index, original)\n\n\n\n\n\n","category":"method"},{"location":"branching/#ModelVerification.vecsign_convert_to_original_size-Tuple{Any, Any, Any}","page":"Branching","title":"ModelVerification.vecsign_convert_to_original_size","text":"vecsign_convert_to_original_size(index, vector, original)\n\n\n\n\n\n","category":"method"},{"location":"network/","page":"Network","title":"Network","text":"Pages = [\"network.md\"]\nDepth = 3","category":"page"},{"location":"network/#Network","page":"Network","title":"Network","text":"","category":"section"},{"location":"network/#Network-2","page":"Network","title":"Network","text":"","category":"section"},{"location":"network/","page":"Network","title":"Network","text":"Modules=[ModelVerification]\nPages=[\"network.jl\"]","category":"page"},{"location":"network/#ModelVerification.Layer","page":"Network","title":"ModelVerification.Layer","text":"Layer{F, N}\n\nConsists of weights and bias for linear mapping, and activation for nonlinear mapping.\n\nFields\n\nweights::Matrix{N}\nbias::Vector{N}\nactivation::F\n\nSee also: Network\n\n\n\n\n\n","category":"type"},{"location":"network/#ModelVerification.Network","page":"Network","title":"ModelVerification.Network","text":"A Vector of layers.\n\nNetwork([layer1, layer2, layer3, ...])\n\nSee also: Layer\n\n\n\n\n\n","category":"type"},{"location":"network/#ModelVerification.n_nodes-Tuple{ModelVerification.Layer}","page":"Network","title":"ModelVerification.n_nodes","text":"n_nodes(L::Layer)\n\nReturns the number of neurons in a layer.\n\n\n\n\n\n","category":"method"},{"location":"network/#Activation-Functions","page":"Network","title":"Activation Functions","text":"","category":"section"},{"location":"network/","page":"Network","title":"Network","text":"Modules=[ModelVerification]\nPages=[\"activation.jl\"]","category":"page"},{"location":"network/#ModelVerification.ActivationFunction","page":"Network","title":"ModelVerification.ActivationFunction","text":"ActivationFunction\n\nFunction that calculates the output of the node. Supported activation functions are:\n\nReLU (ReLU)\nMax (Max)\nIdentity (Id)\nSigmoid (Sigmoid)\nTanh (Tanh)\n\n\n\n\n\n","category":"type"},{"location":"network/#ModelVerification.GeneralAct","page":"Network","title":"ModelVerification.GeneralAct","text":"GeneralAct <: ActivationFunction\n\nWrapper type for a general activation function.\n\nUsage\n\nact = GeneralAct(tanh)\n\nact(0) == tanh(0)           # true\nact(10.0) == tanh(10.0)     # true\n\nact = GeneralAct(x->tanh.(x))\n\njulia> act(-2:2)\n5-element Array{Float64,1}:\n -0.9640275800758169\n -0.7615941559557649\n  0.0\n  0.7615941559557649\n  0.9640275800758169\n\n\n\n\n\n","category":"type"},{"location":"network/#ModelVerification.Id","page":"Network","title":"ModelVerification.Id","text":"Id <: ActivationFunction\n\nIdentity operator\n\n(Id())(x) -> x\n\n\n\n\n\n","category":"type"},{"location":"network/#ModelVerification.Max","page":"Network","title":"ModelVerification.Max","text":"Max <: ActivationFunction\n\n(Max())(x) -> max(maximum(x), 0)\n\n\n\n\n\n","category":"type"},{"location":"network/#ModelVerification.PiecewiseLinear","page":"Network","title":"ModelVerification.PiecewiseLinear","text":"PiecewiseLinear <: ActivationFunction\n\nActivation function that uses linear interpolation between supplied knots. An extrapolation condition can be set for values outside the set of knots. Default is Linear.\n\nPiecewiseLinear(knots_x, knots_y, [extrapolation = Line()])\n\nUsage\n\nkx = [0.0, 1.2, 1.7, 3.1]\nky = [0.0, 0.5, 1.0, 1.5]\nact = PiecewiseLinear(kx, ky)\n\nact(first(kx)) == first(ky) == 0.0\nact(last(kx))  == last(ky)  == 1.5\n\nact(1.0)    # 0.4166666666666667\nact(-102)   # -42.5\n\nact = PiecewiseLinear(kx, ky, Flat())\n\nact(-102)   # 0.0\nact(Inf)    # 1.5\n\nExtrapolations\n\nFlat()\nLine()\nconstant (supply a number as the argument)\nThrow() (throws bounds error)\n\nPiecewiseLinear uses Interpolations.jl.\n\n\n\n\n\n","category":"type"},{"location":"network/#ModelVerification.ReLU","page":"Network","title":"ModelVerification.ReLU","text":"ReLU <: ActivationFunction\n\n(ReLU())(x) -> max.(x, 0)\n\n\n\n\n\n","category":"type"},{"location":"network/#ModelVerification.Sigmoid","page":"Network","title":"ModelVerification.Sigmoid","text":"Sigmoid <: ActivationFunction\n\n(Sigmoid())(x) -> 1 ./ (1 .+ exp.(-x))\n\n\n\n\n\n","category":"type"},{"location":"network/#ModelVerification.Tanh","page":"Network","title":"ModelVerification.Tanh","text":"Tanh <: ActivationFunction\n\n(Tanh())(x) -> tanh.(x)\n\n\n\n\n\n","category":"type"},{"location":"network/#Helper-Functions","page":"Network","title":"Helper Functions","text":"","category":"section"},{"location":"network/","page":"Network","title":"Network","text":"Modules=[ModelVerification]\nPages=[\"util.jl\"]","category":"page"},{"location":"network/#ModelVerification.act_gradient-Tuple{ModelVerification.ReLU, Vector}","page":"Network","title":"ModelVerification.act_gradient","text":"act_gradient(act, z_hat::Vector{N}) where N\n\nCompute the gradient of an activation function at point z_hat. Currently only supports ReLU and Id.\n\n\n\n\n\n","category":"method"},{"location":"network/#ModelVerification.act_gradient_bounds-Tuple{ModelVerification.Network, LazySets.AbstractPolytope}","page":"Network","title":"ModelVerification.act_gradient_bounds","text":"act_gradient_bounds(nnet::Network, input::AbstractPolytope)\n\nCompute the bounds on the gradient of all activation functions given an input set. Currently only support ReLU. Return:\n\nLΛ, UΛ::NTuple{2, Vector{BitVector}}: lower and upper bounds on activation\n\n\n\n\n\n","category":"method"},{"location":"network/#ModelVerification.affine_map-Tuple{Flux.Dense, Any}","page":"Network","title":"ModelVerification.affine_map","text":"affine_map(layer, x)\n\nCompute W*x ⊕ b for a vector or LazySet x\n\n\n\n\n\n","category":"method"},{"location":"network/#ModelVerification.affine_map-Tuple{ModelVerification.Layer, Any}","page":"Network","title":"ModelVerification.affine_map","text":"affine_map(layer, x)\n\nCompute W*x ⊕ b for a vector or LazySet x\n\n\n\n\n\n","category":"method"},{"location":"network/#ModelVerification.approximate_act_map-Tuple{ModelVerification.ActivationFunction, LazySets.Hyperrectangle}","page":"Network","title":"ModelVerification.approximate_act_map","text":"approximateactmap(layer, input::Hyperrectangle)\n\nReturns a Hyperrectangle overapproximation of the activation map of the input. actmust be monotonic.\n\n\n\n\n\n","category":"method"},{"location":"network/#ModelVerification.approximate_affine_map-Tuple{ModelVerification.Layer, LazySets.Hyperrectangle}","page":"Network","title":"ModelVerification.approximate_affine_map","text":"approximateaffinemap(layer, input::Hyperrectangle)\n\nReturns a Hyperrectangle overapproximation of the affine map of the input.\n\n\n\n\n\n","category":"method"},{"location":"network/#ModelVerification.broadcast_mid_dim-Union{Tuple{T1}, Tuple{T2}, Tuple{AbstractMatrix{T1}, AbstractArray{T2, 3}}} where {T2, T1}","page":"Network","title":"ModelVerification.broadcast_mid_dim","text":"broadcast_mid_dim(m::AbstractArray{2}, target::AbstractArray{T,3})\n\nGiven a target tensor of the shape AxBxC,  broadcast the 2D mask of the shape AxC to AxBxC.\n\nOutputs:\n\nm broadcasted.\n\n\n\n\n\n","category":"method"},{"location":"network/#ModelVerification.compute_output-Tuple{ModelVerification.Network, Any}","page":"Network","title":"ModelVerification.compute_output","text":"compute_output(nnet::Network, input::Vector{Float64})\n\nPropagate a given vector through a nnet and compute the output.\n\n\n\n\n\n","category":"method"},{"location":"network/#ModelVerification.get_activation-Tuple{ModelVerification.Layer{ModelVerification.ReLU}, LazySets.Hyperrectangle}","page":"Network","title":"ModelVerification.get_activation","text":"get_activation(L::Layer{ReLU}, bounds::Hyperrectangle)\n\nGiven a layer, find the activation pattern of all neurons in the layer given the node-wise bounds. Assume ReLU. Assume bounds is the pre-activation bounds for each ReLU in the layer. return Vector{Vector{Int64}}.\n\n1: activated\n0: undetermined\n-1: not activated\n\n\n\n\n\n","category":"method"},{"location":"network/#ModelVerification.get_activation-Tuple{ModelVerification.Layer{ModelVerification.ReLU}, Vector}","page":"Network","title":"ModelVerification.get_activation","text":"get_activation(L, x::Vector)\n\nFinds the activation pattern of a vector x subject to the activation function given by the layer L. Returns a Vector{Bool} where true denotes the node is \"active\". In the sense of ReLU, this would be x[i] >= 0.\n\n\n\n\n\n","category":"method"},{"location":"network/#ModelVerification.get_activation-Tuple{ModelVerification.Network, LazySets.Hyperrectangle}","page":"Network","title":"ModelVerification.get_activation","text":"get_activation(nnet::Network, input::Hyperrectangle)\n\nGiven a network, find the activation pattern of all neurons for a given input set. Assume ReLU. return Vector{Vector{Int64}}.\n\n1: activated\n0: undetermined\n-1: not activated\n\n\n\n\n\n","category":"method"},{"location":"network/#ModelVerification.get_activation-Tuple{ModelVerification.Network, Vector{Float64}}","page":"Network","title":"ModelVerification.get_activation","text":"get_activation(nnet::Network, x::Vector)\n\nGiven a network, find the activation pattern of all neurons at a given point x. Returns Vector{Vector{Bool}}. Each Vector{Bool} refers to the activation pattern of a particular layer.\n\n\n\n\n\n","category":"method"},{"location":"network/#ModelVerification.get_activation-Tuple{ModelVerification.Network, Vector{LazySets.Hyperrectangle}}","page":"Network","title":"ModelVerification.get_activation","text":"get_activation(nnet::Network, bounds::Vector{Hyperrectangle})\n\nGiven a network, find the activation pattern of all neurons given the node-wise bounds. Assume ReLU. Assume pre-activation bounds where the bounds on the input are given by the first hyperrectangle, the first hidden layer by the second hyperrectangle, and so on. return Vector{Vector{Int64}}.\n\n1: activated\n0: undetermined\n-1: not activated\n\n\n\n\n\n","category":"method"},{"location":"network/#ModelVerification.get_bounds-Tuple{ModelVerification.Network, Any}","page":"Network","title":"ModelVerification.get_bounds","text":"get_bounds(problem::Problem)\nget_bounds(nnet::Network, input::Hyperrectangle, [true])\n\nComputes node-wise bounds given a input set. The optional last argument determines whether the bounds are pre- or post-activation.\n\nReturn:\n\nVector{Hyperrectangle}: bounds for all nodes. bounds[1] is the input set.\n\n\n\n\n\n","category":"method"},{"location":"network/#ModelVerification.get_gradient-Tuple{ModelVerification.Network, Vector}","page":"Network","title":"ModelVerification.get_gradient","text":"get_gradient(nnet::Network, x::Vector)\n\nGiven a network, find the gradient at the input x\n\n\n\n\n\n","category":"method"},{"location":"network/#ModelVerification.get_gradient_bounds-Tuple{ModelVerification.Network, LazySets.AbstractPolytope}","page":"Network","title":"ModelVerification.get_gradient_bounds","text":"get_gradient_bounds(nnet::Network, LΛ::Vector{AbstractVector}, UΛ::Vector{AbstractVector})\nget_gradient_bounds(nnet::Network, input::AbstractPolytope)\n\nGet lower and upper bounds on network gradient for given gradient bounds on activations, or given an input set. Return:\n\n(LG, UG)::NTuple{2, Matrix{Float64} lower and upper bounds.\n\n\n\n\n\n","category":"method"},{"location":"network/#ModelVerification.interval_map-Union{Tuple{N}, Tuple{AbstractMatrix{N}, AbstractVecOrMat, AbstractVecOrMat}} where N","page":"Network","title":"ModelVerification.interval_map","text":"interval_map(W::Matrix, l::AbstractVecOrMat, u::AbstractVecOrMat)\n\nSimple linear mapping on intervals. L, U := ([W]₊*l + [W]₋*u), ([W]₊*u + [W]₋*l)\n\nOutputs:\n\n(lbound, ubound) (after the mapping)\n\n\n\n\n\n","category":"method"},{"location":"network/#ModelVerification.print_header-Tuple{IOStream, Any}","page":"Network","title":"ModelVerification.print_header","text":"print_header(file::IOStream, network[; header_text])\n\nThe NNet format has a particular header containing information about the network size and training data. print_header does not take training-related information into account (subject to change).\n\n\n\n\n\n","category":"method"},{"location":"network/#ModelVerification.print_layer-Tuple{IOStream, Any}","page":"Network","title":"ModelVerification.print_layer","text":"print_layer(file::IOStream, layer)\n\nPrint to file an object implementing weights(layer) and bias(layer)\n\n\n\n\n\n","category":"method"},{"location":"network/#ModelVerification.read_layer","page":"Network","title":"ModelVerification.read_layer","text":"read_layer(output_dim::Int, f::IOStream, [act = ReLU()])\n\nRead in layer from nnet file and return a Layer containing its weights/biases. Optional argument act sets the activation function for the layer.\n\n\n\n\n\n","category":"function"},{"location":"network/#ModelVerification.read_nnet-Tuple{String}","page":"Network","title":"ModelVerification.read_nnet","text":"read_nnet(fname::String; last_layer_activation = Id())\n\nRead in neural net from a .nnet file and return Network struct. The .nnet format is borrowed from NNet. The format assumes all hidden layers have ReLU activation. Keyword argument last_layer_activation sets the activation of the last layer, and defaults to Id(), (i.e. a linear output layer).\n\n\n\n\n\n","category":"method"},{"location":"network/#ModelVerification.relaxed_relu_gradient-Tuple{Real, Real}","page":"Network","title":"ModelVerification.relaxed_relu_gradient","text":"relaxed_relu_gradient(l::Real, u::Real)\n\nReturn the slope of a ReLU activation based on its lower and upper bounds\n\nReturns 0 if u<0, 1 if l>0, u/(u-l) otherwise\n\n\n\n\n\n","category":"method"},{"location":"network/#ModelVerification.to_comment-Tuple{Any}","page":"Network","title":"ModelVerification.to_comment","text":"Prepend // to each line of a string.\n\n\n\n\n\n","category":"method"},{"location":"network/#ModelVerification.write_nnet-Tuple{Any, Any}","page":"Network","title":"ModelVerification.write_nnet","text":"write_nnet(filename, network[; header_text])\n\nWrite network to filename.nnet. Note: Does not perform safety checks on inputs, so use with caution.\n\nBased on python code at https://github.com/sisl/NNet/blob/master/utils/writeNNet.py and follows .nnet format given here: https://github.com/sisl/NNet.\n\n\n\n\n\n","category":"method"},{"location":"existing_implementations/#Existing-Implementations","page":"Existing Implementations","title":"Existing Implementations","text":"","category":"section"},{"location":"existing_implementations/","page":"Existing Implementations","title":"Existing Implementations","text":"MIPVerify\nConvDual\nReluVal\nNeurify\nSherlock\nPlanet\nPLNN\nDLV\nReluplex","category":"page"},{"location":"propagate/","page":"Propagation","title":"Propagation","text":"Pages=[\"propagation.md\"]\nDepth = 3","category":"page"},{"location":"propagate/#Propagation","page":"Propagation","title":"Propagation","text":"","category":"section"},{"location":"propagate/","page":"Propagation","title":"Propagation","text":"Functions for propagating the bound through the model (from start nodes to the end nodes) for a given branch. For a forward propagation method (ForwardProp), the start nodes are the input nodes of the computational graph and the end nodes are the output nodes. For a backward propagation method (BackwardProp), the start nodes are the output nodes and the end nodes are the input nodes. We use BFS (Breadth-first Search) to iterate through the computational graph and propagates the bounds from nodes to nodes.","category":"page"},{"location":"propagate/","page":"Propagation","title":"Propagation","text":"The propagate\\propagate.jl module defines algorithms for propagating bounds from input to output, for both forward propagation and backward propagation.","category":"page"},{"location":"propagate/","page":"Propagation","title":"Propagation","text":"The propagate\\operators folder contains specific propagation algorithms for different operators, such as ReLU, Dense, Identity, Convolution, Bivariate, etc.","category":"page"},{"location":"propagate/","page":"Propagation","title":"Propagation","text":"PropMethod","category":"page"},{"location":"propagate/#ModelVerification.PropMethod","page":"Propagation","title":"ModelVerification.PropMethod","text":"PropMethod\n\n\n\n\n\n","category":"type"},{"location":"propagate/","page":"Propagation","title":"Propagation","text":"Modules=[ModelVerification]\nPages=[\"propagate.jl\"]","category":"page"},{"location":"propagate/#ModelVerification.backward_layer-Tuple{Any, Any, Any}","page":"Propagation","title":"ModelVerification.backward_layer","text":"backward_layer(prop_method, layer, batch_bound)\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.forward_act_batch-Tuple{ModelVerification.ForwardProp, Any, AbstractArray, AbstractArray}","page":"Propagation","title":"ModelVerification.forward_act_batch","text":"forward_act_batch(prop_method::ForwardProp, σ, batch_reach::AbstractArray, batch_info::AbstractArray)\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.forward_layer-NTuple{4, Any}","page":"Propagation","title":"ModelVerification.forward_layer","text":"forward_layer(prop_method, layer, batch_bound, batch_info)\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.forward_linear_batch-Tuple{ModelVerification.ForwardProp, Any, AbstractArray, AbstractArray}","page":"Propagation","title":"ModelVerification.forward_linear_batch","text":"forward_linear_batch(prop_method::ForwardProp, layer, batch_reach::AbstractArray, batch_info::AbstractArray)\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.forward_skip_batch-Tuple{ModelVerification.ForwardProp, Any, Vararg{AbstractArray, 4}}","page":"Propagation","title":"ModelVerification.forward_skip_batch","text":"forward_skip_batch(prop_method::ForwardProp, layer, batch_reach1::AbstractArray, batch_reach2::AbstractArray, batch_info1::AbstractArray, batch_info2::AbstractArray)\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.is_activation-Tuple{Any}","page":"Propagation","title":"ModelVerification.is_activation","text":"is_activation(l)\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate-Tuple{PropMethod, Any, Any}","page":"Propagation","title":"ModelVerification.propagate","text":"propagate(prop_method::PropMethod, model_info, batch_info)\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_act_batch-Tuple{ModelVerification.ForwardProp, Any, AbstractArray, Any}","page":"Propagation","title":"ModelVerification.propagate_act_batch","text":"propagate_act_batch(prop_method::ForwardProp, σ, batch_reach::AbstractArray, batch_info)\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_layer_batch-NTuple{4, Any}","page":"Propagation","title":"ModelVerification.propagate_layer_batch","text":"propagate_layer_batch(prop_method, layer, batch_bound, batch_info)\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_layer_method-Tuple{ModelVerification.BackwardProp, Any, Any, Any}","page":"Propagation","title":"ModelVerification.propagate_layer_method","text":"propagate_layer_method(prop_method::BackwardProp, model_info, batch_info, node)\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_layer_method-Tuple{ModelVerification.ForwardProp, Any, Any, Any}","page":"Propagation","title":"ModelVerification.propagate_layer_method","text":"propagate_layer_method(prop_method::ForwardProp, model_info, batch_info, node)\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_linear_batch-Tuple{ModelVerification.ForwardProp, Any, AbstractArray, Any}","page":"Propagation","title":"ModelVerification.propagate_linear_batch","text":"propagate_linear_batch(prop_method::ForwardProp, layer, batch_reach::AbstractArray, batch_info)\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_skip_batch-Tuple{ModelVerification.ForwardProp, Any, AbstractArray, AbstractArray, Any}","page":"Propagation","title":"ModelVerification.propagate_skip_batch","text":"propagate_skip_batch(prop_method::ForwardProp, layer, batch_reach1::AbstractArray, batch_reach2::AbstractArray, batch_info)\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_skip_method-Tuple{ModelVerification.BackwardProp, Any, Any, Any}","page":"Propagation","title":"ModelVerification.propagate_skip_method","text":"propagate_skip_method(prop_method::BackwardProp, model_info, batch_info, node)\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_skip_method-Tuple{ModelVerification.ForwardProp, Any, Any, Any}","page":"Propagation","title":"ModelVerification.propagate_skip_method","text":"propagate_skip_method(prop_method::ForwardProp, model_info, batch_info, node)\n\n\n\n\n\n","category":"method"},{"location":"propagate/","page":"Propagation","title":"Propagation","text":"NOTE: Need to include ForwardProp, BackwardProp, ... from solvers\\solver.jl.","category":"page"},{"location":"propagate/#Bivariate","page":"Propagation","title":"Bivariate","text":"","category":"section"},{"location":"propagate/","page":"Propagation","title":"Propagation","text":"Modules=[ModelVerification]\nPages=[\"bivariate.jl\"]","category":"page"},{"location":"propagate/#ModelVerification.propagate_skip-Tuple{AlphaCrown, typeof(+), ModelVerification.AlphaCrownBound, ModelVerification.AlphaCrownBound, Any}","page":"Propagation","title":"ModelVerification.propagate_skip","text":"propagate_skip(prop_method::AlphaCrown, layer::typeof(+), bound1::AlphaCrownBound, bound2::AlphaCrownBound, batch_info)\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_skip-Tuple{Any, typeof(+), ModelVerification.ImageStarBound, ModelVerification.ImageStarBound, Any}","page":"Propagation","title":"ModelVerification.propagate_skip","text":"propagate_skip(prop_method, layer::typeof(+), bound1::ImageStarBound, bound2::ImageStarBound, batch_info)\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_skip-Tuple{Any, typeof(+), ModelVerification.ImageZonoBound, ModelVerification.ImageZonoBound, Any}","page":"Propagation","title":"ModelVerification.propagate_skip","text":"propagate_skip(prop_method, layer::typeof(+), bound1::ImageZonoBound, bound2::ImageZonoBound, batch_info)\n\n\n\n\n\n","category":"method"},{"location":"propagate/#Convolution","page":"Propagation","title":"Convolution","text":"","category":"section"},{"location":"propagate/","page":"Propagation","title":"Propagation","text":"Modules=[ModelVerification]\nPages=[\"convolution.jl\"]","category":"page"},{"location":"propagate/#ModelVerification.bound_layer-Tuple{Flux.Conv{2, 4, typeof(identity), Array{Float32, 4}, Vector{Float32}}, Vararg{AbstractArray, 4}}","page":"Propagation","title":"ModelVerification.bound_layer","text":"bound_layer(layer::Conv{2, 4, typeof(identity), Array{Float32, 4}, Vector{Float32}}, lower_weight::AbstractArray, upper_weight::AbstractArray, lower_bias::AbstractArray, upper_bias::AbstractArray)\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.bound_onside-Tuple{Flux.Conv{2, 4, typeof(identity), Array{Float32, 4}, Vector{Float32}}, AbstractArray, AbstractArray}","page":"Propagation","title":"ModelVerification.bound_onside","text":"bound_onside(layer::Conv{2, 4, typeof(identity), Array{Float32, 4}, Vector{Float32}}, conv_input_size::AbstractArray, batch_reach::AbstractArray)\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.interval_propagate","page":"Propagation","title":"ModelVerification.interval_propagate","text":"interval_propagate(layer::Conv{2, 4, typeof(identity), Array{Float32, 4}, Vector{Float32}}, interval, C = nothing)\n\n\n\n\n\n","category":"function"},{"location":"propagate/#ModelVerification.propagate_by_small_batch-Tuple{Any, Any}","page":"Propagation","title":"ModelVerification.propagate_by_small_batch","text":"propagate_by_small_batch(f, x; sm_batch=500)\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_linear-Tuple{ImageStar, Flux.Conv, ModelVerification.ImageStarBound, Any}","page":"Propagation","title":"ModelVerification.propagate_linear","text":"propagate_linear(prop_method::ImageStar, layer::Conv, bound::ImageStarBound, batch_info)\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_linear-Tuple{ImageStar, Flux.ConvTranspose, ModelVerification.ImageStarBound, Any}","page":"Propagation","title":"ModelVerification.propagate_linear","text":"propagate_linear(prop_method::ImageStar, layer::ConvTranspose, bound::ImageStarBound, batch_info)\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_linear-Tuple{ImageZono, Flux.Conv, ModelVerification.ImageZonoBound, Any}","page":"Propagation","title":"ModelVerification.propagate_linear","text":"propagate_linear(prop_method::ImageZono, layer::Conv, bound::ImageZonoBound, batch_info)\n\n\n\n\n\n","category":"method"},{"location":"propagate/#ModelVerification.propagate_linear-Tuple{ImageZono, Flux.ConvTranspose, ModelVerification.ImageZonoBound, Any}","page":"Propagation","title":"ModelVerification.propagate_linear","text":"propagate_linear(prop_method::ImageZono, layer::ConvTranspose, bound::ImageZonoBound, batch_info)\n\n\n\n\n\n","category":"method"},{"location":"propagate/#Dense","page":"Propagation","title":"Dense","text":"","category":"section"},{"location":"propagate/#Identity","page":"Propagation","title":"Identity","text":"","category":"section"},{"location":"propagate/#Normalise","page":"Propagation","title":"Normalise","text":"","category":"section"},{"location":"propagate/#ReLU","page":"Propagation","title":"ReLU","text":"","category":"section"},{"location":"propagate/#Stateless","page":"Propagation","title":"Stateless","text":"","category":"section"},{"location":"about/#About","page":"About","title":"About","text":"","category":"section"},{"location":"about/","page":"About","title":"About","text":"This package is developed by the Intelligent Control Lab at the Robotics Institute at Carnegie Mellon University. It is an extension of the NeuralVerification.jl.","category":"page"},{"location":"solvers/","page":"Solvers","title":"Solvers","text":"Pages=[\"solvers.md\"]\nDepth = 3","category":"page"},{"location":"solvers/#Solvers","page":"Solvers","title":"Solvers","text":"","category":"section"},{"location":"solvers/","page":"Solvers","title":"Solvers","text":"Modules=[ModelVerification]\nPages=[\"solver.jl\"]","category":"page"},{"location":"solvers/#ModelVerification.BackwardProp","page":"Solvers","title":"ModelVerification.BackwardProp","text":"BackwardProp <: PropMethod\n\n\n\n\n\n","category":"type"},{"location":"solvers/#ModelVerification.BatchBackwardProp","page":"Solvers","title":"ModelVerification.BatchBackwardProp","text":"BatchBackwardProp <: BackwardProp\n\n\n\n\n\n","category":"type"},{"location":"solvers/#ModelVerification.BatchForwardProp","page":"Solvers","title":"ModelVerification.BatchForwardProp","text":"BatchForwardProp <: ForwardProp\n\n\n\n\n\n","category":"type"},{"location":"solvers/#ModelVerification.Bound","page":"Solvers","title":"ModelVerification.Bound","text":"Bound\n\nAbstract type \n\n\n\n\n\n","category":"type"},{"location":"solvers/#ModelVerification.ForwardProp","page":"Solvers","title":"ModelVerification.ForwardProp","text":"ForwardProp <: PropMethod\n\n\n\n\n\n","category":"type"},{"location":"solvers/#ModelVerification.SequentialBackwardProp","page":"Solvers","title":"ModelVerification.SequentialBackwardProp","text":"SequentialBackwardProp <: ForwardProp\n\n\n\n\n\n","category":"type"},{"location":"solvers/#ModelVerification.SequentialForwardProp","page":"Solvers","title":"ModelVerification.SequentialForwardProp","text":"SequentialForwardProp <: ForwardProp\n\n\n\n\n\n","category":"type"},{"location":"solvers/#ModelVerification.check_inclusion-Tuple{ModelVerification.ForwardProp, Any, AbstractArray, AbstractArray, AbstractArray}","page":"Solvers","title":"ModelVerification.check_inclusion","text":"check_inclusion(prop_method::ForwardProp, model, batch_input::AbstractArray, batch_reach::AbstractArray, batch_output::AbstractArray)\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.init_batch_bound-Tuple{ModelVerification.BackwardProp, Any, Any}","page":"Solvers","title":"ModelVerification.init_batch_bound","text":"init_batch_bound(prop_method::BackwardProp, batch_input, batch_output)\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.init_batch_bound-Tuple{ModelVerification.ForwardProp, Any, Any}","page":"Solvers","title":"ModelVerification.init_batch_bound","text":"init_batch_bound(prop_method::ForwardProp, batch_input, batch_output)\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.init_bound-Tuple{ModelVerification.BackwardProp, Any}","page":"Solvers","title":"ModelVerification.init_bound","text":"init_bound(prop_method::BackwardProp, output)\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.init_bound-Tuple{ModelVerification.ForwardProp, Any}","page":"Solvers","title":"ModelVerification.init_bound","text":"init_bound(prop_method::ForwardProp, input)\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.init_propagation-Tuple{ModelVerification.BackwardProp, Any, Any, Any}","page":"Solvers","title":"ModelVerification.init_propagation","text":"init_propagation(prop_method::BackwardProp, batch_input, batch_output, model_info)\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.init_propagation-Tuple{ModelVerification.ForwardProp, Any, Any, Any}","page":"Solvers","title":"ModelVerification.init_propagation","text":"init_propagation(prop_method::ForwardProp, batch_input, batch_output, model_info)\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.prepare_method-Tuple{PropMethod, AbstractVector, AbstractVector, Any}","page":"Solvers","title":"ModelVerification.prepare_method","text":"prepare_method(prop_method::PropMethod, batch_input::AbstractVector, batch_output::AbstractVector, model_info)\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.process_bound-Tuple{PropMethod, Vararg{Any, 4}}","page":"Solvers","title":"ModelVerification.process_bound","text":"process_bound(prop_method::PropMethod, batch_bound, batch_out_spec, model_info, batch_info)\n\n\n\n\n\n","category":"method"},{"location":"solvers/#Ai2","page":"Solvers","title":"Ai2","text":"","category":"section"},{"location":"solvers/","page":"Solvers","title":"Solvers","text":"Modules=[ModelVerification]\nPages=[\"polytope.jl\"]","category":"page"},{"location":"solvers/#ModelVerification.Ai2","page":"Solvers","title":"ModelVerification.Ai2","text":"Ai2{T}\n\nAi2 performs over-approximated reachability analysis to compute the over- approximated output reachable set for a network. T can be Hyperrectangle,  Zonotope, Star, or HPolytope, and determines the amount of over- approximation (and hence also performance tradeoff). The original implementation  (from [1]) uses Zonotopes, so we consider this the \"benchmark\" case. The  HPolytope case is more precise, but not scalable, and the opposite is true of  the Hyperrectangle case. Zonotope and Star are more scalable and precise.\n\nNote that initializing Ai2() defaults to Ai2{Zonotope}. The following aliases also exist for convenience:\n\nconst Ai2h = Ai2{HPolytope}\nconst Ai2z = Ai2{Zonotope}\nconst Ai2s = Ai2{Star}\nconst Box = Ai2{Hyperrectangle}\n\nProblem requirement\n\nNetwork: any depth, ReLU activation (more activations to be supported in the future)\nInput: AbstractPolytope\nOutput: AbstractPolytope\n\nReturn\n\nReachabilityResult\n\nMethod\n\nReachability analysis using split and join.\n\nProperty\n\nSound but not complete.\n\nNote\n\nEfficient over-approximation of intersections and unions involving zonotopes  relies on Theorem 3.1 of [2].\n\nReference\n\n[1] T. Gehr, M. Mirman, D. Drashsler-Cohen, P. Tsankov, S. Chaudhuri, and  M. Vechev, \"Ai2: Safety and Robustness Certification of Neural Networks with  Abstract Interpretation,\" in 2018 IEEE Symposium on Security and Privacy (SP), \n\n\n\n[2] Singh, G., Gehr, T., Mirman, M., Püschel, M., & Vechev, M. (2018). Fast and effective robustness certification. In Advances in Neural Information Processing Systems (pp. 10802-10813).\n\n\n\n\n\n","category":"type"},{"location":"solvers/#ModelVerification.StarSet","page":"Solvers","title":"ModelVerification.StarSet","text":"StarSet\n\nCovers all Ai2 variations: Ai2h, Ai2z, Ai2s, Box.\n\nFields\n\npre_bound_method: \n\n\n\n\n\n","category":"type"},{"location":"solvers/#ModelVerification.check_inclusion-Tuple{ModelVerification.ForwardProp, Any, LazySets.LazySet, LazySets.LazySet, LazySets.Complement}","page":"Solvers","title":"ModelVerification.check_inclusion","text":"check_inclusion(prop_method::ForwardProp, model, input::LazySet, \nreach::LazySet, output::Complement)\n\nDetermines whether the reachable set, R(input, model), is within the valid  output specified by a LazySet. This function achieves this by checking if the box approximation (overapproximation with hyperrectangle) of the reach set is disjoint with the unsafe_output.\n\nFields\n\nprop_method (ForwardProp): solver being used.\nmodel : deep neural network model that is to be verified.\ninput (LazySet): input specification supported by Lazyset.\nreach (LazySet): reachable set resulting from the propagation of input    through the model.\noutput (Complement): set of valid outputs represented with a complement set.\n\nReturns\n\nReachabilityResult(:holds, [reach]) if box_reach is disjoint with the   complement of the output.\nCounterExampleResult(:violated, x) if the center of the input set results    in a state that belongs to the unsafe_output.\nCounterExampleResult(:unknown) if either the two cases above are true.\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.check_inclusion-Tuple{ModelVerification.ForwardProp, Any, LazySets.LazySet, LazySets.LazySet, LazySets.LazySet}","page":"Solvers","title":"ModelVerification.check_inclusion","text":"check_inclusion(prop_method::ForwardProp, model, input::LazySet, \nreach::LazySet, output::LazySet)\n\nDetermines whether the reachable set, R(input, model), is within the valid  output specified by a LazySet. This function achieves this by directly  checking if the reachable set reach is a subset of the set of valid outputs  output. If not, it attempts to find a counterexample and returns the  appropriate Result.\n\nFields\n\nprop_method (ForwardProp): solver being used.\nmodel : deep neural network model that is to be verified.\ninput (LazySet): input specification supported by LazySet.\nreach (LazySet): reachable set resulting from the propagation of input    through the model.\noutput (LazySet) : set of valid outputs represented with a LazySet.\n\nReturns\n\nReachabilityResult(:holds, [reach]) if reach is a subset of output.\nCounterExampleResult(:unknown) if reach is not a subset of output, but    cannot find a counterexample.\nCounterExampleResult(:violated, x) if reach is not a subset of output,    and there is a counterexample.\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.compute_bound-Tuple{LazySets.Star}","page":"Solvers","title":"ModelVerification.compute_bound","text":"compute_bound(bound::Star)\n\nComputes the lower- and upper-bounds of a star set.  This function is used when propagating through the layers of network. It overapproximates the given star set with a hyperrectangle.\n\nFields\n\nbound (Star) : star of which the bounds need to be computed\n\nReturns\n\nLower- and upper-bounds of the overapproximated hyperrectangle.\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.compute_bound-Tuple{LazySets.Zonotope}","page":"Solvers","title":"ModelVerification.compute_bound","text":"compute_bound(bound::Zonotope)\n\nComputes the lower- and upper-bounds of a zonotope.  This function is used when propagating through the layers of network. Radius is the sum of absolute value of the generators of the given zonotope.\n\nFields\n\nbound (Zonotope) : zonotope of which the bounds need to be computed\n\nReturns\n\nLower- and upper-bounds of the Zonotope.\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.init_bound-Tuple{StarSet, LazySets.Hyperrectangle}","page":"Solvers","title":"ModelVerification.init_bound","text":"init_bound(prop_method::StarSet, input::Hyperrectangle)\n\nGiven a hyperrectangle as input, this function returns a star set that  encompasses the hyperrectangle. This helps a more precise computation of bounds.\n\nFields\n\nprop_method (StarSet) : (not used –> need to be deprecated)\ninput (Hyperrectangle) : hyperrectangle to be converted into a star set\n\nReturns\n\nStar set that encompasses the given hyperrectangle.\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.prepare_method-Tuple{StarSet, AbstractVector, AbstractVector, Any}","page":"Solvers","title":"ModelVerification.prepare_method","text":"prepare_method(prop_method::StarSet, batch_input::AbstractVector, \nbatch_output::AbstractVector, model_info)\n\nInitialize the solver\n\nFields\n\nprop_method (StarSet) : propagation method of type StarSet.\nbatch_input (AbstractVector) : batch of input s\nbatch_output (AbstractVector) : batch of outputs\nmodel_info   :\n\nReturns\n\nbatch_output: batch of outputs.\nbatch_info:\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ImageStar","page":"Solvers","title":"ImageStar","text":"","category":"section"},{"location":"solvers/","page":"Solvers","title":"Solvers","text":"Modules=[ModelVerification]\nPages=[\"image-star.jl\", \"image-zono.jl\"]","category":"page"},{"location":"solvers/#ModelVerification.ImageStar","page":"Solvers","title":"ModelVerification.ImageStar","text":"ImageStar <: SequentialForwardProp\n\nImageStar is a verification approach that can verify the robustness of CNN. It is defined as a set representation in literature, but this toolbox uses the  term as the verification method itself that uses the ImageStar set. ImageStarBound is used to represent the bounded set.\n\nFields\n\npre_bound_method : \n\nReference\n\n[1] HD. Tran, S. Bak, W. Xiang, and T.T. Johnson, \"Verification of Deep Convolutional  Neural Networks Using ImageStars,\" in Computer Aided Verification (CAV), 2020.\n\n\n\n\n\n","category":"type"},{"location":"solvers/#ModelVerification.ImageStarBound","page":"Solvers","title":"ModelVerification.ImageStarBound","text":"ImageStarBound{T<:Real} <: Bound\n\n\n\n\n\n","category":"type"},{"location":"solvers/#ModelVerification.assert_zono_star-Tuple{ModelVerification.ImageStarBound}","page":"Solvers","title":"ModelVerification.assert_zono_star","text":"assert_zono_star(bound::ImageStarBound)\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.check_inclusion-Tuple{ImageStar, Any, ModelVerification.ImageStarBound, LazySets.LazySet, LazySets.LazySet}","page":"Solvers","title":"ModelVerification.check_inclusion","text":"check_inclusion(prop_method::ImageStar, model, input::ImageStarBound, reach::LazySet, output::LazySet)\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.compute_bound-Tuple{ModelVerification.ImageStarBound}","page":"Solvers","title":"ModelVerification.compute_bound","text":"compute_bound(bound::ImageStarBound)\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.init_bound-Tuple{ImageStar, ImageConvexHull}","page":"Solvers","title":"ModelVerification.init_bound","text":"init_bound(prop_method::ImageStar, ch::ImageConvexHull)\n\nAssume batch_input[1] is a list of vertex images. Return a zonotope. \n\nFields:\n\nprop_method: ImageStar solver.\nch: convex hull, type ImageConvexHull, is used as the input specification.\n\nReturns:\n\nImageStarBound\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.prepare_problem-Tuple{SearchMethod, SplitMethod, ImageStar, Problem}","page":"Solvers","title":"ModelVerification.prepare_problem","text":"prepare_problem(search_method, split_method, prop_method, problem)\n\nArguments\n\nsearch_method::SearchMethod:\nsplit_method::SplitMethod:\nprop_method::ImageStar:\nproblem::Problem:\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.ImageZono","page":"Solvers","title":"ModelVerification.ImageZono","text":"ImageZono <: SequentialForwardProp\n\n\n\n\n\n","category":"type"},{"location":"solvers/#ModelVerification.ImageZonoBound","page":"Solvers","title":"ModelVerification.ImageZonoBound","text":"ImageZonoBound{T<:Real} <: Bound\n\n\n\n\n\n","category":"type"},{"location":"solvers/#ModelVerification.check_inclusion-Tuple{ImageZono, Any, ModelVerification.ImageZonoBound, LazySets.LazySet, LazySets.LazySet}","page":"Solvers","title":"ModelVerification.check_inclusion","text":"check_inclusion(prop_method::ImageZono, model, input::ImageZonoBound, reach::LazySet, output::LazySet)\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.compute_bound-Tuple{ModelVerification.ImageZonoBound}","page":"Solvers","title":"ModelVerification.compute_bound","text":"compute_bound(bound::ImageZonoBound)\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.init_bound-Tuple{ImageZono, ImageConvexHull}","page":"Solvers","title":"ModelVerification.init_bound","text":"init_bound(prop_method::ImageZono, ch::ImageConvexHull)\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.init_bound-Tuple{ImageZono, ModelVerification.ImageStarBound}","page":"Solvers","title":"ModelVerification.init_bound","text":"init_bound(prop_method::ImageZono, bound::ImageStarBound)\n\n\n\n\n\n","category":"method"},{"location":"solvers/#ModelVerification.prepare_problem-Tuple{SearchMethod, SplitMethod, ImageZono, Problem}","page":"Solvers","title":"ModelVerification.prepare_problem","text":"prepare_problem(search_method::SearchMethod, split_method::SplitMethod, prop_method::ImageZono, problem::Problem)\n\n\n\n\n\n","category":"method"},{"location":"solvers/#Crown","page":"Solvers","title":"Crown","text":"","category":"section"},{"location":"solvers/#\\alpha-Crown","page":"Solvers","title":"alpha-Crown","text":"","category":"section"},{"location":"solvers/#\\beta-Crown","page":"Solvers","title":"beta-Crown","text":"","category":"section"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"Pages=[\"safety_spec.md\"]\nDepth=3","category":"page"},{"location":"safety_spec/#Input-Output-Specification","page":"Input-Output Specification","title":"Input-Output Specification","text":"","category":"section"},{"location":"safety_spec/#Safety-Property","page":"Input-Output Specification","title":"Safety Property","text":"","category":"section"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"A safety property is essentially an input-output relationship for the model we want to verify. In general, the constraints for the input set mathcalX and the output set mathcalY can have any geometry. For the sake of simplicity, ModelVerification.jl uses convex polytopes and the complement of a polytope to encode the input and output specifications. Specifically, our implementation utilizes the geometric definitions of LazySets, a Julia package for calculus with convex sets. The following section dives into the geometric representations ModelVerification.jl uses and the representations required for each solver. ","category":"page"},{"location":"safety_spec/#Geometric-Representation","page":"Input-Output Specification","title":"Geometric Representation","text":"","category":"section"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"Different solvers implemented in ModelVerification.jl require the input-output specification formulated with particular geometries. We report here a brief overview of the sets we use. For specifics, please read Algorithms for Verifying Deep Neural Networks by C. Liu, et al.  and Sets in LazySets.jl.","category":"page"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"HR = Hyperrectangle\nHS = HalfSpace\nHP = HPolytope\nSS = StarSet\nZT = Zonotope\nIS = ImageStar\nIZ = ImageZono\nPC = PolytopeComplement","category":"page"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"Solver Input Set Output Set\nAi2 HR, ZT, HP, SS HP (bounded)\nCROWN HR HP (bounded)\nalpha-CROWN HR HP (bounded)\nbeta-CROWN HR HP (bounded)\nalpha-beta-CROWN HR HP (bounded)","category":"page"},{"location":"safety_spec/#Hyperrectangle-([Hyperrectangle](https://juliareach.github.io/LazySets.jl/dev/lib/sets/Hyperrectangle/#def_Hyperrectangle))","page":"Input-Output Specification","title":"Hyperrectangle (Hyperrectangle)","text":"","category":"section"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"Corresponds to a high-dimensional rectangle, defined by","category":"page"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"x-c le r","category":"page"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"where cinmathbbR^k_0 is the center of the hyperrectangle and rinmathbbR^k_0 is the radius of the hyperrectangle.","category":"page"},{"location":"safety_spec/#HalfSpace-([HalfSpace](https://juliareach.github.io/LazySets.jl/dev/lib/sets/HalfSpace/))","page":"Input-Output Specification","title":"HalfSpace (HalfSpace)","text":"","category":"section"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"Represented by a single linear inequality constraint","category":"page"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"c^top x le d","category":"page"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"where cinmathbbR^k_0 and dinmathbbR.","category":"page"},{"location":"safety_spec/#Halfspace-Polytope-([HPolytope](https://juliareach.github.io/LazySets.jl/dev/lib/sets/HPolytope/#def_HPolytope))","page":"Input-Output Specification","title":"Halfspace-Polytope (HPolytope)","text":"","category":"section"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"HPolytope uses a set of linear inequality constraints to represent a convex polytope, i.e., it is a bounded set defined using an intersection of half-spaces.","category":"page"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"Cx le d","category":"page"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"where CinmathbbR^ktimes k_0 dinmathbbR^k with k representing the number of inequality constraints.","category":"page"},{"location":"safety_spec/#StarSet-([Star](https://juliareach.github.io/LazySets.jl/dev/lib/sets/Star/#def_Star))","page":"Input-Output Specification","title":"StarSet (Star)","text":"","category":"section"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"Only convex star set is considered in this toolbox. A convex star set is an affine transformation of an arbitrary convex polytope,","category":"page"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"x = c + beginbmatrix r_1  r_2  cdots  r_l endbmatrix alpha Calpha le d","category":"page"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"where cinmathbbR^k_0 is the center of the star set, r_iinmathbbR^k_0 iin1dotsl are generators of the star set, CinmathbbR^ktimes l, dinmathbbR^k, alphainmathbbR^l is the free parameter that belongs to a unit hypercube, and k is the number of inequality constraints on alpha. l is the degree of freedom of the star set.","category":"page"},{"location":"safety_spec/#Zonotope-([Zonotope](https://juliareach.github.io/LazySets.jl/dev/lib/sets/Zonotope/#def_Zonotope))","page":"Input-Output Specification","title":"Zonotope (Zonotope)","text":"","category":"section"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"Zonotope is basically as star set in which all predicate variables are in the range of -1 1. Zonotope represents polytopes that can be written as affine transformations of a unit hypercube, defined as","category":"page"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"x = c + beginbmatrix r_1  r_2  cdots  r_l endbmatrix alpha alpha le 1","category":"page"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"where cinmathbbR^k_0 is the center of the zonotope, r_iinmathbbR^k_0 iin1dotsl are generators of the zonotope, and alphainmathbbR^l is the free parameter that belongs to a unit hypercube. l is the degree of freedom of the zonotope.","category":"page"},{"location":"safety_spec/#ImageStar","page":"Input-Output Specification","title":"ImageStar","text":"","category":"section"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"ImageStar is an extension of the star set where the center and generators are images with multiple channels.","category":"page"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"x = c + beginbmatrix r_1  r_2  cdots  r_l endbmatrix alpha Calpha le d","category":"page"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"where cinmathbbR^htimes w times k_0 is the center image, r_iinmathbbR^h times w times k_0 iin1dotsl are the generator iamges, CinmathbbR^ktimes l, dinmathbbR^k, and hwk are the height, width, and number of channels (input dimension) of the images respectively. alphainmathbbR^l is the free parameter that belongs to a unit hypercube, and k is the number of inequality constraints on alpha. l is the degree of freedom of the star set.","category":"page"},{"location":"safety_spec/#ImageZono","page":"Input-Output Specification","title":"ImageZono","text":"","category":"section"},{"location":"safety_spec/#PolytopeComplement","page":"Input-Output Specification","title":"PolytopeComplement","text":"","category":"section"},{"location":"safety_spec/#References","page":"Input-Output Specification","title":"References","text":"","category":"section"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"[1] C. Liu, T. Arnon, C. Lazarus, C. Strong, C. Barret, and M. J. Kochenderfer, \"Algorithms for Verifying Deep Neural Networks,\" in Foundations and Trends in Optimization, 2021.","category":"page"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"[2] T. Gehr, M. Mirman, D. Drashsler-Cohen, P. Tsankov, S. Chaudhuri, and M. Vechev, \"Ai2: Safety and Robustness Certification of Neural Networks with Abstract Interpretation,\" in 2018 IEEE Symposium on Security and Privacy (SP), 2018.","category":"page"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"[3] M. Forets and C. Schilling, \"LazySets.jl: Scalable Symbolic-Numeric Set Computations,\" in Proceeds of the JuliaCon Conferences, 2021.","category":"page"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"[4] HD. Tran, S. Bak, W. Xiang, and T.T. Johnson, \"Verification of Deep Convolutional Neural Networks Using ImageStars,\" in Computer Aided Verification (CAV), 2020.","category":"page"},{"location":"safety_spec/#Spec","page":"Input-Output Specification","title":"Spec","text":"","category":"section"},{"location":"safety_spec/","page":"Input-Output Specification","title":"Input-Output Specification","text":"Modules=[ModelVerification]\nPages=[\"spec.jl\"]","category":"page"},{"location":"safety_spec/#ModelVerification.InputSpec","page":"Input-Output Specification","title":"ModelVerification.InputSpec","text":"InputSpec\n\nInput specification can be of any type supported by LazySet or ImageConvexHull.\n\n\n\n\n\n","category":"type"},{"location":"safety_spec/#ModelVerification.OutputSpec","page":"Input-Output Specification","title":"ModelVerification.OutputSpec","text":"OutputSpec\n\nOutput specification can be of any type supported by LazySet or LinearSpec.\n\n\n\n\n\n","category":"type"},{"location":"safety_spec/#ModelVerification.ImageConvexHull","page":"Input-Output Specification","title":"ModelVerification.ImageConvexHull","text":"ImageConvexHull <: Spec\n\nConvex hull for images used to specify safety property for images.  It is the smallest convex polytope that contains all the images given in the imgs array.\n\nFields\n\nimgs (AbstractArray): list of images in AbstractArray.    Image is represented as a matrix of h x w x c.\n\n\n\n\n\n","category":"type"},{"location":"safety_spec/#ModelVerification.LinearSpec","page":"Input-Output Specification","title":"ModelVerification.LinearSpec","text":"LinearSpec <: Spec\n\nSafety specification defined as the set x x = A x - b  0.\n\nFields\n\nA (AbstractArray{Float64, 3}): normal dierction of size spec_dim x out_dim x batch_size.\nb (AbstractArray{Float64, 2}): constraints of size spec_dim x batch_size.\nis_complement (Bool): boolean flag for whether this specification is a complement or not.\n\n\n\n\n\n","category":"type"},{"location":"safety_spec/#ModelVerification.Spec","page":"Input-Output Specification","title":"ModelVerification.Spec","text":"Spec\n\nAbstract super-type for input-output specifications.\n\n\n\n\n\n","category":"type"},{"location":"safety_spec/#ModelVerification.classification_spec-Tuple{Any, Any}","page":"Input-Output Specification","title":"ModelVerification.classification_spec","text":"classification_spec(n, target)\n\n\n\n\n\n","category":"method"},{"location":"safety_spec/#ModelVerification.get_linear_spec-Tuple{AbstractVector}","page":"Input-Output Specification","title":"ModelVerification.get_linear_spec","text":"get_linear_spec(batch_out_set::AbstractVector)\n\nRetrieves the linear specifications of the batch of output sets and returns a LinearSpec structure. \n\nFields:\n\nbatch_out_set (AbstractVector): batch of output sets.\n\nReturns:\n\nLinearSpec of the batch of output sets.\n\n\n\n\n\n","category":"method"},{"location":"safety_spec/#ModelVerification.get_size-Tuple{ImageConvexHull}","page":"Input-Output Specification","title":"ModelVerification.get_size","text":"get_size(input_spec::ImageConvexHull)\n\nGiven an ImageConvexHull, it determines the size.\n\n\n\n\n\n","category":"method"},{"location":"safety_spec/#ModelVerification.get_size-Tuple{LazySets.LazySet}","page":"Input-Output Specification","title":"ModelVerification.get_size","text":"get_size(input_spec::LazySet)\n\nGiven a LazySet, it determines the size.\n\n\n\n\n\n","category":"method"},{"location":"utils/#Helper-Functions","page":"Helper Functions","title":"Helper Functions","text":"","category":"section"},{"location":"utils/#Flux-to-Network,-Network-to-Flux","page":"Helper Functions","title":"Flux-to-Network, Network-to-Flux","text":"","category":"section"},{"location":"utils/","page":"Helper Functions","title":"Helper Functions","text":"network(c::Chain) = Network([layer.(c.layers)...])","category":"page"},{"location":"utils/","page":"Helper Functions","title":"Helper Functions","text":"Converts Flux.Chain to a Network.","category":"page"},{"location":"utils/","page":"Helper Functions","title":"Helper Functions","text":"Flux.Chain(m::Network) = _flux(m)","category":"page"},{"location":"utils/","page":"Helper Functions","title":"Helper Functions","text":"Converts Network to a Flux.Chain.","category":"page"},{"location":"utils/#Testing-Functions","page":"Helper Functions","title":"Testing Functions","text":"","category":"section"},{"location":"utils/","page":"Helper Functions","title":"Helper Functions","text":"Modules=[ModelVerification]\nPages=[\"testing_utils.jl\"]","category":"page"},{"location":"nnet_converter/#NNet-Converter","page":"NNet Converter","title":"NNet Converter","text":"","category":"section"},{"location":"python_interface/#Python-Interface","page":"Python Interface","title":"Python Interface","text":"","category":"section"},{"location":"python_interface/","page":"Python Interface","title":"Python Interface","text":"PyJulia - for Luca","category":"page"},{"location":"problem/","page":"Problem Outline","title":"Problem Outline","text":"Pages=[\"problem.md\"]\nDepth = 3","category":"page"},{"location":"problem/#Problem-Outline","page":"Problem Outline","title":"Problem Outline","text":"","category":"section"},{"location":"problem/","page":"Problem Outline","title":"Problem Outline","text":"Verification checks if the input-output relationships of a function, specifically deep neural networks (DNN) mathcalF in this case, hold. For an input specification imposed by a set mathcalXsubseteq mathcalD_x, we would like to check if the corresponding output of the function is contained in an output specification imposed by a set mathcalYsubseteq mathcalD_y:","category":"page"},{"location":"problem/","page":"Problem Outline","title":"Problem Outline","text":"xinmathcalX Longrightarrow y = mathcalF(x) in mathcalY","category":"page"},{"location":"problem/","page":"Problem Outline","title":"Problem Outline","text":"Thus, a DNN-Verification problem consists of two main components:","category":"page"},{"location":"problem/","page":"Problem Outline","title":"Problem Outline","text":"model (DNN) : mathcalF\nsafety property (input-output specification) : mathcalX mathcalY.","category":"page"},{"location":"problem/","page":"Problem Outline","title":"Problem Outline","text":"Due to the nonlinear and nonconvex nature of DNNs, estimating the exact reachable set is impractical, although there are algorithms that allow us to do this such as ExactReach. Thus, we preform an over-approximation of the reachable set, called mathcalR. We check its containment in the desired reachable set mathcalY which if ture, we can assert that the safety property holds.","category":"page"},{"location":"problem/","page":"Problem Outline","title":"Problem Outline","text":"Once we instantiate ","category":"page"},{"location":"problem/","page":"Problem Outline","title":"Problem Outline","text":"Below, we give a brief overview of models (Network), safety property, and outputs (verification results).","category":"page"},{"location":"problem/#Network","page":"Problem Outline","title":"Network","text":"","category":"section"},{"location":"problem/","page":"Problem Outline","title":"Problem Outline","text":"Details on Network","category":"page"},{"location":"problem/#Safety-Property","page":"Problem Outline","title":"Safety Property","text":"","category":"section"},{"location":"problem/","page":"Problem Outline","title":"Problem Outline","text":"Details on Input-Output Specification","category":"page"},{"location":"problem/#Output-(Verification-Results)","page":"Problem Outline","title":"Output (Verification Results)","text":"","category":"section"},{"location":"problem/","page":"Problem Outline","title":"Problem Outline","text":"Output result Explanation\n[BasicResult::hold] The input-output constraint is always satisfied\n[BasicResult::violated] The input-output constraint is violated, i.e., it exists a single point in the input constraint that violates the property\n[BasicResult::timeout] Could not be determined if the property holds due to timeout in the computation\n[CounterExampleResult] Like BasicResult, but also returns a counterexample if one is found (if status = :violated). The counterexample is a point in the input set that, after the NN, lies outside the output constraint set.\n[AdversarialResult] Like BasicResult, but also returns the maximum allowable disturbance in the input (if status = :violated)\n[ReachabilityResult] Like BasicResult, but also returns the output reachable set given the input constraint (if status = :violated).\n[EnumerationResult] Set of all the (un)safe regions in the safety property's domain.","category":"page"},{"location":"problem/#Problem-and-Result-Documentation","page":"Problem Outline","title":"Problem and Result Documentation","text":"","category":"section"},{"location":"problem/","page":"Problem Outline","title":"Problem Outline","text":"Modules=[ModelVerification]\nPages=[\"problem.jl\"]","category":"page"},{"location":"problem/#ModelVerification.AdversarialResult","page":"Problem Outline","title":"ModelVerification.AdversarialResult","text":"AdversarialResult(status, max_disturbance)\n\nLike BasicResult, but also returns the maximum allowable disturbance in the input (if status = :violated).\n\n\n\n\n\n","category":"type"},{"location":"problem/#ModelVerification.BasicResult","page":"Problem Outline","title":"ModelVerification.BasicResult","text":"BasicResult(status::Symbol)\n\nResult type that captures whether the input-output constraint is satisfied. Possible status values:\n\n:holds (io constraint is satisfied always)\n\n:violated (io constraint is violated)\n\n:unknown (could not be determined)\n\n\n\n\n\n","category":"type"},{"location":"problem/#ModelVerification.CounterExampleResult","page":"Problem Outline","title":"ModelVerification.CounterExampleResult","text":"CounterExampleResult(status, counter_example)\n\nLike BasicResult, but also returns a counter_example if one is found (if status = :violated). The counter_example is a point in the input set that, after the NN, lies outside the output set.\n\n\n\n\n\n","category":"type"},{"location":"problem/#ModelVerification.Problem","page":"Problem Outline","title":"ModelVerification.Problem","text":"Problem{P, Q}(network::Network, input::P, output::Q)\n\nProblem definition for neural verification.\n\nThe verification problem consists of: for all  points in the input set, the corresponding output of the network must belong to the output set.\n\nFields\n\nnetwork : Network that can be constructed either using the path to an onnx   model or a Flux.Chain structure.\ninput : input specification defined using a LazySet.\noutput : output specification defined using a LazySet.\n\n\n\n\n\n","category":"type"},{"location":"problem/#ModelVerification.ReachabilityResult","page":"Problem Outline","title":"ModelVerification.ReachabilityResult","text":"ReachabilityResult(status, reachable)\n\nLike BasicResult, but also returns the output reachable set given the input constraint (if status = :violated).\n\n\n\n\n\n","category":"type"},{"location":"problem/#ModelVerification.Result","page":"Problem Outline","title":"ModelVerification.Result","text":"Result\n\nSupertype of all result types.\n\nSee also: BasicResult, CounterExampleResult, AdversarialResult, ReachabilityResult\n\n\n\n\n\n","category":"type"},{"location":"attack/#Attacks","page":"Attacks","title":"Attacks","text":"","category":"section"},{"location":"attack/","page":"Attacks","title":"Attacks","text":"Modules=[ModelVerification]\nPages=[\"pgd.jl\"]","category":"page"},{"location":"attack/#ModelVerification.APGD-NTuple{4, Any}","page":"Attacks","title":"ModelVerification.APGD","text":"APGD(model, loss, x, y; ϵ = 10, step_size = 0.1, iters = 100, clamp_range = (0, 1))\n\nAuto Projected Gradient Descent (APGD) (https://arxiv.org/pdf/2003.01690.pdf)\n\nArguments:\n\nmodel: The model to base teh attack upon.\nloss: the loss function to use, assuming that it includes the prediction function   i.e. loss(x, y) = crossentropy(m(x), y)\nx: The input to be perturbed.\nstep_size: The ϵ value in the FGSM step.\nrho: PGD success rate threshold to reduce the step size.\na: momentum.\niters: The maximum number of iterations to run the algorithm for.\n\n\n\n\n\n","category":"method"},{"location":"attack/#ModelVerification.FGSM-Tuple{Any, Any, Any}","page":"Attacks","title":"ModelVerification.FGSM","text":"FGSM(model, loss, x, y; ϵ = 0.1, clamp_range = (0, 1))\n\nFast Gradient Sign Method (FGSM) is a method of creating adversarial examples by pushing the input in the direction of the gradient and bounded by the ε parameter.\n\nThis method was proposed by Goodfellow et al. 2014 (https://arxiv.org/abs/1412.6572)\n\nArguments:\n\nmodel: The model to base the attack upon.\nloss: The loss function to use. This assumes that the loss function includes   the predict function, i.e. loss(x, y) = crossentropy(model(x), y).\nx: The input to be perturbed by the FGSM algorithm.\nϵ: The amount of perturbation to apply.\n\n\n\n\n\n","category":"method"},{"location":"attack/#ModelVerification.PGD-NTuple{4, Any}","page":"Attacks","title":"ModelVerification.PGD","text":"PGD(model, loss, x, y; ϵ = 10, step_size = 0.1, iters = 100, clamp_range = (0, 1))\n\nProjected Gradient Descent (PGD) is an itrative variant of FGSM with a random point. For every step the FGSM algorithm moves the input in the direction of the gradient bounded in the l∞ norm. (https://arxiv.org/pdf/1706.06083.pdf)\n\nArguments:\n\nmodel: The model to base teh attack upon.\nloss: the loss function to use, assuming that it includes the prediction function   i.e. loss(x, y) = crossentropy(m(x), y)\nx: The input to be perturbed.\nstep_size: The ϵ value in the FGSM step.\niters: The maximum number of iterations to run the algorithm for.\n\n\n\n\n\n","category":"method"},{"location":"attack/#ModelVerification.attack-Tuple{Any, Any, Any}","page":"Attacks","title":"ModelVerification.attack","text":"attack(model, input, output; restart=100)\n\n\n\n\n\n","category":"method"},{"location":"attack/#ModelVerification.attack-Tuple{Any}","page":"Attacks","title":"ModelVerification.attack","text":"attack(problem; restart=100)\n\n\n\n\n\n","category":"method"},{"location":"attack/#ModelVerification.project-Tuple{Any, AbstractVector, LazySets.Hyperrectangle}","page":"Attacks","title":"ModelVerification.project","text":"project(x, dir::AbstractVector, set::Hyperrectangle)\n\n\n\n\n\n","category":"method"},{"location":"attack/#ModelVerification.project-Tuple{Any, AbstractVector, LazySets.LazySet}","page":"Attacks","title":"ModelVerification.project","text":"project(x, dir::AbstractVector, set::LazySet)\n\n\n\n\n\n","category":"method"},{"location":"attack/#ModelVerification.project-Tuple{Any, LazySets.Hyperrectangle}","page":"Attacks","title":"ModelVerification.project","text":"project(p, rect::Hyperrectangle)\n\n\n\n\n\n","category":"method"},{"location":"attack/#ModelVerification.project-Tuple{Any, LazySets.LazySet}","page":"Attacks","title":"ModelVerification.project","text":"project(p, polytope::LazySet)\n\n\n\n\n\n","category":"method"},{"location":"benchmark/#Benchmark","page":"Benchmark","title":"Benchmark","text":"","category":"section"},{"location":"#ModelVerification.jl","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"","category":"section"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Pages=[\"index.md\"]","category":"page"},{"location":"#Introduction","page":"ModelVerification.jl","title":"Introduction","text":"","category":"section"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Deep Neural Network (DNN) is crucial in approximating nonlinear functions across diverse applications, such as computer vision and control. Verifying specific input-output properties can be a highly challenging task. To this end, we present ModelVerification.jl, the only cutting-edge toolbox that contains a suite of state-of-the-art methods for verifying DNNs. This toolbox significantly extends and improves the previous version (NeuralVerification.jl) and is designed to empower developers and machine learning practioners with robust tools for verifying and ensuring the trustworthiness of their DNN models.","category":"page"},{"location":"#Key-features:","page":"ModelVerification.jl","title":"Key features:","text":"","category":"section"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Julia and Python integration: Built on Julia programming language, ModelVerification.jl leverages Julia's high-performance capabilities, ensuring efficient and scalable verification processes. Moreover, we provide the user with an easy, ready-to-use Python interface to exploit the full potential of the toolbox even without knowledge of the Julia language.\nDifferent types of verification: ModelVerification.jl enables verification of several input-output specifications, such as reacability analysis, behavioral properties (e.g., to verify Deep Reinforcement Learning policies), or even robustness properties for Convolutional Neural Network (CNN). It also introduces new types of verification, not only for finding individual adversarial input, but for enumerating the entire set of unsafe zones for a given network and safety properties.\nVerification benchmarks: Compare our or your verification toolboxes against state-of-the-art benchmarks and evaluation criteria (VNN-Comp 2023). ModelVerification.jl includes a collection of solvers and standard benchmarks to perform this evaluation efficiently.","category":"page"},{"location":"#Setup","page":"ModelVerification.jl","title":"Setup","text":"","category":"section"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"This toolbox requires Julia v1.5 or later. Refer the official Julia documentation to install it for your system.","category":"page"},{"location":"#Installation","page":"ModelVerification.jl","title":"Installation","text":"","category":"section"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"To download this toolbox, clone it from the Julia package manager like so:","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"pkg> add https://github.com/intelligent-control-lab/ModelVerification.jl/","category":"page"},{"location":"#Develop-the-toolbox-(for-development)","page":"ModelVerification.jl","title":"Develop the toolbox (for development)","text":"","category":"section"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Deprecated once project is done and should be changed to \"Building the package\".","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Go to the toolbox directory and start the Julia REPL. ","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"julia > ]\n(@v1.9) > develop .\n(@v1.9) > activate .\n(@v1.9) > instantiate","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"This will enable development mode for the toolbox. The dependency packages will also be installed. Some of the important ones are listed below. ","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Flux\nLazySets\nJuMP\nZygote","category":"page"},{"location":"#Overview-of-the-toolbox","page":"ModelVerification.jl","title":"Overview of the toolbox","text":"","category":"section"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"(Image: )","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"ModelVerification.jl receives input as a set consisting of:","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Model to be verified,\nA safety property encoded as input-output specifications for the neural network,\nThe solver to be used for the formal verification process.","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"The toolbox's output varies depending on the type of verification we are performing. Nonetheless, at the end of the verification process, the response of the toolbox potentially allows us to obtain provable guarantees that a given safety property holds (or does not hold) for the model tested.","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"For more details on how the toolbox works, please refer to the tutorial below.","category":"page"},{"location":"#Quickstart","page":"ModelVerification.jl","title":"Quickstart","text":"","category":"section"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Here is a simple example for verifying that the user-given safety property holds for a small deep neural network (DNN) with a single input node, two hidden layers with two ReLU nodes, and a single output node. We use the formal verification results obtained through the reachability analysis to get a provable answer whether the safety property holds.","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"First, we load the relevant libraries and the ModelVerification.jl toolbox.","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"using ModelVerification\nusing Flux\nusing LazySets","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"First, load the model.","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"onnx_path = \"models/small_nnet.onnx\"\ntoy_model = build_flux_model(onnx_path)","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Suppose we want to verify that all inputs in mathcalX=-25 25 are mapped into mathcalY=185 1145. We encode this safety property using convex sets, provided by LazySets. ","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"X = Hyperrectangle(low = [-2.5], high = [2.5]) # expected out: [18.5, 114.5]\nY = Hyperrectangle(low = [18.5], high = [114.5]) # here we expect the property holds","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Now, we construct a Problem instance. Note that ModelVerification.jl converts the .onnx model into a Flux model.","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"problem = Problem(toy_model, X, Y)","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Instantiate the solver, which in this case is CROWN. We also need search, split, and propagation methods in addition to the solver and Problem.","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"search_method = BFS(max_iter=100, batch_size=1)\nsplit_method = Bisect(1)\n\nuse_gpu = false\nlower_bound = true\nupper_bound = true\nsolver = Crown(use_gpu, lower_bound, upper_bound)","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Finally, we can verify that the safety property holds for this simple example!","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"result = verify(search_method, split_method, solver, problem)\nprintln(result)\nprintln(result.status)","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"CROWN verifies that the input-output relationship holds!","category":"page"},{"location":"#Tutorials","page":"ModelVerification.jl","title":"Tutorials","text":"","category":"section"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Tutorials\nExample 1: Verifying a toy DNN with reachability analysis\nExample 2: Verifying a Deep Reinforcement Learning (DRL) policy for collision avoidance safety property\nExample 3: Verifying a CNN for robustness safety property","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"<!– - MLP examples","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"CNN examples\nMNIST examples\nACASXU examples –>","category":"page"},{"location":"#Toolbox-Outline","page":"ModelVerification.jl","title":"Toolbox Outline","text":"","category":"section"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"(Image: )","category":"page"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Pages = [\"problem.md\", \"network.md\", \"safety_spec.md\", \"branching.md\", \"propagate.md\", \"solvers.md\", \"attack.md\", \"utils.md\"]\nDepth = 3","category":"page"},{"location":"#Python-Interface","page":"ModelVerification.jl","title":"Python Interface","text":"","category":"section"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Pages = [\"nnet_converter.md\"]\nDepth = 3","category":"page"},{"location":"#Benchmarks","page":"ModelVerification.jl","title":"Benchmarks","text":"","category":"section"},{"location":"","page":"ModelVerification.jl","title":"ModelVerification.jl","text":"Pages = [\"benchmark.md\"]\nDepth = 3","category":"page"}]
}
