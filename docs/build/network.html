<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Network · ModelVerification.jl</title><meta name="title" content="Network · ModelVerification.jl"/><meta property="og:title" content="Network · ModelVerification.jl"/><meta property="twitter:title" content="Network · ModelVerification.jl"/><meta name="description" content="Documentation for ModelVerification.jl."/><meta property="og:description" content="Documentation for ModelVerification.jl."/><meta property="twitter:description" content="Documentation for ModelVerification.jl."/><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="search_index.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="index.html"><img src="assets/logo.png" alt="ModelVerification.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="index.html">ModelVerification.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="index.html">ModelVerification.jl</a></li><li><span class="tocitem">Toolbox</span><ul><li><input class="collapse-toggle" id="menuitem-2-1" type="checkbox" checked/><label class="tocitem" for="menuitem-2-1"><span class="docs-label">Problem</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="problem.html">Problem Outline</a></li><li class="is-active"><a class="tocitem" href="network.html">Network</a><ul class="internal"><li><a class="tocitem" href="#Model"><span>Model</span></a></li><li><a class="tocitem" href="#Network-2"><span>Network</span></a></li><li><a class="tocitem" href="#Activation-Functions"><span>Activation Functions</span></a></li><li><a class="tocitem" href="#Helper-Functions"><span>Helper Functions</span></a></li></ul></li><li><a class="tocitem" href="safety_spec.html">Input-Output Specification</a></li></ul></li><li><a class="tocitem" href="branching.html">Branching</a></li><li><a class="tocitem" href="propagate.html">Propagation</a></li><li><a class="tocitem" href="solvers.html">Solvers</a></li><li><a class="tocitem" href="attack.html">Attacks</a></li><li><a class="tocitem" href="utils.html">Helper Functions</a></li></ul></li><li><span class="tocitem">Python Interface</span><ul><li><a class="tocitem" href="nnet_converter.html">NNet Converter</a></li><li><a class="tocitem" href="python_interface.html">Python Interface</a></li></ul></li><li><a class="tocitem" href="existing_implementations.html">Existing Implementations</a></li><li><a class="tocitem" href="about.html">About</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Toolbox</a></li><li><a class="is-disabled">Problem</a></li><li class="is-active"><a href="network.html">Network</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="network.html">Network</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/intelligent-control-lab/ModelVerification.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/master/docs/src/network.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><ul><li><a href="network.html#Network">Network</a></li><li class="no-marker"><ul><li><a href="network.html#Model">Model</a></li><li><a href="network.html#Network-2">Network</a></li><li><a href="network.html#Activation-Functions">Activation Functions</a></li><li><a href="network.html#Helper-Functions">Helper Functions</a></li><li class="no-marker"><ul><li><a href="network.html#Network-loading-and-dumping">Network loading and dumping</a></li><li><a href="network.html#Network-properties">Network properties</a></li><li><a href="network.html#Activation-function-operations">Activation function operations</a></li><li><a href="network.html#Gradient-operations">Gradient operations</a></li><li><a href="network.html#Bound-and-Specification-operations">Bound &amp; Specification operations</a></li></ul></li></ul></li></ul><h1 id="Network"><a class="docs-heading-anchor" href="#Network">Network</a><a id="Network-1"></a><a class="docs-heading-anchor-permalink" href="#Network" title="Permalink"></a></h1><h2 id="Model"><a class="docs-heading-anchor" href="#Model">Model</a><a id="Model-1"></a><a class="docs-heading-anchor-permalink" href="#Model" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.Model" href="#ModelVerification.Model"><code>ModelVerification.Model</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Model</code></pre><p>Structure containing the information of the neural network to be verified.</p><p><strong>Fields</strong></p><ul><li><code>start_nodes</code> (<code>Array{String, 1}</code>): List of input layer nodes&#39; names.</li><li><code>final_nodes</code> (<code>Array{String, 1}</code>): List of output layer nodes&#39; names.</li><li><code>all_nodes</code> (<code>Array{String, 1}</code>): List of all the nodes&#39;s names.</li><li><code>node_layer</code> (<code>Dict</code>): Dictionary of all the nodes. The key is the name of the    node and the value is the operation performed at the node.</li><li><code>node_prevs</code> (<code>Dict</code>): Dictionary of the nodes connected to the current node.   The key is the name of the node and the value is the list of nodes.</li><li><code>node_nexts</code> (<code>Dict</code>): Dictionary of the nodes connected from the current    node. The key is the name of the node and the value is the list of nodes.</li><li><code>activation_nodes</code> (<code>Array{String, 1}</code>): List of all the activation nodes&#39;    names.</li><li><code>activation_number</code> (<code>Int</code>): Number of activation nodes (deprecated in the    future).</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/preprocessing.jl#L1-L20">source</a></section></article><h2 id="Network-2"><a class="docs-heading-anchor" href="#Network-2">Network</a><a class="docs-heading-anchor-permalink" href="#Network-2" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.Network" href="#ModelVerification.Network"><code>ModelVerification.Network</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Network</code></pre><p>A vector of layers.</p><p><strong>Fields</strong></p><ul><li><code>layers</code> (<code>Vector{Layer}</code>): Layers of the network, including the output layer.</li></ul><p>See also: <a href="network.html#ModelVerification.Layer"><code>Layer</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/network.jl#L28-L37">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.Layer" href="#ModelVerification.Layer"><code>ModelVerification.Layer</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Layer{F&lt;:ActivationFunction, N&lt;:Number}</code></pre><p>Consists of <code>weights</code> and <code>bias</code> for linear mapping, and <code>activation</code> for  nonlinear mapping.</p><p><strong>Fields</strong></p><ul><li><code>weights::Matrix{N}</code></li><li><code>bias::Vector{N}</code></li><li><code>activation::F</code></li></ul><p>See also: <a href="network.html#ModelVerification.Network"><code>Network</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/network.jl#L9-L21">source</a></section></article><h2 id="Activation-Functions"><a class="docs-heading-anchor" href="#Activation-Functions">Activation Functions</a><a id="Activation-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Activation-Functions" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.ActivationFunction" href="#ModelVerification.ActivationFunction"><code>ModelVerification.ActivationFunction</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ActivationFunction</code></pre><p>Function that calculates the output of the node. Supported activation functions are:</p><ul><li>ReLU (<code>ReLU</code>)</li><li>Max (<code>Max</code>)</li><li>Identity (<code>Id</code>)</li><li>Sigmoid (<code>Sigmoid</code>)</li><li>Tanh (<code>Tanh</code>)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/activation.jl#L3-L13">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.GeneralAct" href="#ModelVerification.GeneralAct"><code>ModelVerification.GeneralAct</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GeneralAct &lt;: ActivationFunction</code></pre><p>Wrapper type for a general activation function.</p><p><strong>Usage</strong></p><pre><code class="language-julia hljs">act = GeneralAct(tanh)

act(0) == tanh(0)           # true
act(10.0) == tanh(10.0)     # true</code></pre><pre><code class="language-julia hljs">act = GeneralAct(x-&gt;tanh.(x))

julia&gt; act(-2:2)
5-element Array{Float64,1}:
 -0.9640275800758169
 -0.7615941559557649
  0.0
  0.7615941559557649
  0.9640275800758169</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/activation.jl#L53-L76">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.Id" href="#ModelVerification.Id"><code>ModelVerification.Id</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Id &lt;: ActivationFunction</code></pre><p>Identity operator</p><p>(Id())(x) -&gt; x</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/activation.jl#L30-L36">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.Max" href="#ModelVerification.Max"><code>ModelVerification.Max</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Max &lt;: ActivationFunction</code></pre><p>(Max())(x) -&gt; max(maximum(x), 0)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/activation.jl#L23-L27">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.PiecewiseLinear" href="#ModelVerification.PiecewiseLinear"><code>ModelVerification.PiecewiseLinear</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">PiecewiseLinear &lt;: ActivationFunction</code></pre><p>Activation function that uses linear interpolation between supplied <code>knots</code>. An extrapolation condition can be set for values outside the set of knots. Default is <code>Linear</code>.</p><pre><code class="nohighlight hljs">PiecewiseLinear(knots_x, knots_y, [extrapolation = Line()])</code></pre><p><strong>Usage</strong></p><pre><code class="language-julia hljs">kx = [0.0, 1.2, 1.7, 3.1]
ky = [0.0, 0.5, 1.0, 1.5]
act = PiecewiseLinear(kx, ky)

act(first(kx)) == first(ky) == 0.0
act(last(kx))  == last(ky)  == 1.5

act(1.0)    # 0.4166666666666667
act(-102)   # -42.5</code></pre><pre><code class="language-julia hljs">act = PiecewiseLinear(kx, ky, Flat())

act(-102)   # 0.0
act(Inf)    # 1.5</code></pre><p><strong>Extrapolations</strong></p><ul><li>Flat()</li><li>Line()</li><li>constant (supply a number as the argument)</li><li>Throw() (throws bounds error)</li></ul><p><code>PiecewiseLinear</code> uses <a href="http://juliamath.github.io/Interpolations.jl/latest/">Interpolations.jl</a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/activation.jl#L86-L119">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.ReLU" href="#ModelVerification.ReLU"><code>ModelVerification.ReLU</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ReLU &lt;: ActivationFunction</code></pre><p>(ReLU())(x) -&gt; max.(x, 0)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/activation.jl#L16-L20">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.Sigmoid" href="#ModelVerification.Sigmoid"><code>ModelVerification.Sigmoid</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Sigmoid &lt;: ActivationFunction</code></pre><p>(Sigmoid())(x) -&gt; 1 ./ (1 .+ exp.(-x))</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/activation.jl#L39-L43">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.Tanh" href="#ModelVerification.Tanh"><code>ModelVerification.Tanh</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Tanh &lt;: ActivationFunction</code></pre><p>(Tanh())(x) -&gt; tanh.(x)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/activation.jl#L46-L50">source</a></section></article><h2 id="Helper-Functions"><a class="docs-heading-anchor" href="#Helper-Functions">Helper Functions</a><a id="Helper-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Helper-Functions" title="Permalink"></a></h2><p>Below are the helper functions regarding <a href="network.html#network-loading-and-dumping">network loading (from file) &amp; dumping (to file)</a>, <a href="network.html#network-properties">property-related</a>, <a href="network.html#activation-function-operations">activation function operations</a>, <a href="network.html#gradient-operations">gradient-related operations</a>, and <a href="network.html#bound--specification-operations">bound &amp; specification related operations</a>.</p><h3 id="Network-loading-and-dumping"><a class="docs-heading-anchor" href="#Network-loading-and-dumping">Network loading and dumping</a><a id="Network-loading-and-dumping-1"></a><a class="docs-heading-anchor-permalink" href="#Network-loading-and-dumping" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.onnx_parse-Tuple{Any}" href="#ModelVerification.onnx_parse-Tuple{Any}"><code>ModelVerification.onnx_parse</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">onnx_parse(onnx_model_path)</code></pre><p>Creates the <code>Model</code> from the <code>onnx_model_path</code>. First, the computational graph  of the ONNX model is created. Then, the <code>Model</code> is created using the information retrieved from the computational graph.</p><p><strong>Arguments</strong></p><ul><li><code>onnx_model_path</code>: String path to the ONNX model.</li></ul><p><strong>Returns</strong></p><ul><li><code>model_info</code> (<code>Model</code>): Contains network information retrieved from the    computational graph of the ONNX model.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/preprocessing.jl#L109-L122">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.read_nnet-Tuple{String}" href="#ModelVerification.read_nnet-Tuple{String}"><code>ModelVerification.read_nnet</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">read_nnet(fname::String; last_layer_activation = Id())</code></pre><p>Read in neural net from a <code>.nnet</code> file and return Network struct. The <code>.nnet</code> format is borrowed from <a href="https://github.com/sisl/NNet">NNet</a>. The format assumes all hidden layers have ReLU activation. Keyword argument <code>last_layer_activation</code> sets the activation of the last layer, and defaults to <code>Id()</code>, (i.e. a linear output layer).</p><p><strong>Arguments</strong></p><ul><li><code>fname</code> (<code>String</code>): String path to the <code>.nnet</code> file.</li><li><code>last_layer_activation</code>: Keyword argument that sets the activation of the last    layer which defaults to <code>Id()</code>.</li></ul><p><strong>Returns</strong></p><ul><li>A vector of layers saved as <code>Network</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/util.jl#L1-L17">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.read_layer" href="#ModelVerification.read_layer"><code>ModelVerification.read_layer</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">read_layer(output_dim::Int64, f::IOStream, act = ReLU())</code></pre><p>Read in layer from <code>.nnet</code> file and return a <code>Layer</code> containing its  weights &amp; biases. Optional argument <code>act</code> sets the activation function for the  layer.</p><p><strong>Arguments</strong></p><ul><li><code>output_dim</code> (Int64): Output dimension of the layer.</li><li><code>f</code> (<code>IOStream</code>): IO stream of the <code>.nnet</code> file.</li><li><code>act</code>: Optional argument specifying the activation function of the layer.    Defaults to <code>ReLU()</code>.</li></ul><p><strong>Returns</strong></p><ul><li><code>Layer</code> containing the weights and bias values (and the activation function    of the layer).</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/util.jl#L39-L55">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.to_comment-Tuple{Any}" href="#ModelVerification.to_comment-Tuple{Any}"><code>ModelVerification.to_comment</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">to_comment(txt)</code></pre><p>Prepend <code>//</code> to each line of a string.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/util.jl#L69-L73">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.print_layer-Tuple{IOStream, Any}" href="#ModelVerification.print_layer-Tuple{IOStream, Any}"><code>ModelVerification.print_layer</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">print_layer(file::IOStream, layer)</code></pre><p>Print to <code>file</code> an object implementing <code>weights(layer)</code> and <code>bias(layer)</code>.</p><p><strong>Arguments</strong></p><ul><li><code>file</code> (<code>IOStream</code>): IO stream of the target <code>.nnet</code> file.</li><li><code>layer</code>: Layer to be transcribed to <code>file</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/util.jl#L76-L84">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.print_header-Tuple{IOStream, Any}" href="#ModelVerification.print_header-Tuple{IOStream, Any}"><code>ModelVerification.print_header</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">print_header(file::IOStream, network; header_text=&quot;&quot;)</code></pre><p>The NNet format has a particular header containing information about the  network size and training data. <code>print_header</code> does not take training-related  information into account (subject to change).</p><p><strong>Arguments</strong></p><ul><li><code>file</code> (<code>IOStream</code>): IO stream of the target <code>.nnet</code> file.</li><li><code>network</code>: Network to be transcribed to <code>file</code>.</li><li><code>header_text</code>: Optional header text that comes before the network information.    Defaults to an empty string.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/util.jl#L93-L105">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.write_nnet-Tuple{Any, Any}" href="#ModelVerification.write_nnet-Tuple{Any, Any}"><code>ModelVerification.write_nnet</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">write_nnet(filename, network; header_text)</code></pre><p>Write <code>network</code> to <code>filename.nnet</code>. Note: Does not perform safety checks on inputs, so use with caution.</p><p>Based on python code at https://github.com/sisl/NNet/blob/master/utils/writeNNet.py and follows .nnet format given here: https://github.com/sisl/NNet.</p><p><strong>Arguments</strong></p><ul><li><code>outfile</code>: String name of the <code>.nnet</code> file.</li><li><code>network</code>: Network to be transcribed to <code>outfile.nnet</code>.</li><li><code>header_text</code>: Optional header text that comes before the network information.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/util.jl#L132-L145">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.build_flux_model-Tuple{Any}" href="#ModelVerification.build_flux_model-Tuple{Any}"><code>ModelVerification.build_flux_model</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">build_flux_model(onnx_model_path)</code></pre><p>Builds a <code>Flux.Chain</code> from the given ONNX model path.</p><p><strong>Arguments</strong></p><ul><li><code>onnx_model_path</code>: String path to ONNX model in <code>.onnx</code> file.</li></ul><p><strong>Returns</strong></p><ul><li><code>model</code>: <code>Flux.Chain</code> constructed from the <code>.onnx</code> file.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/problem.jl#L46-L56">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.get_chain-Tuple{Any}" href="#ModelVerification.get_chain-Tuple{Any}"><code>ModelVerification.get_chain</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">get_chain(vertex)</code></pre><p>Returns a <code>Flux.Chain</code> constructed from the given vertex. This is a helper  function for <code>build_flux_model</code>. </p><p><strong>Arguments</strong></p><ul><li><code>vertex</code>: Vertex from the <code>NaiveNASflux</code> computation graph.</li></ul><p><strong>Returns</strong></p><ul><li><code>model</code>: <code>Flux.Chain</code> constructed from the given vertex.</li><li><code>curr_vertex</code>: The last vertex in the chain.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/problem.jl#L1-L13">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.purify_flux_model-Tuple{Flux.Chain}" href="#ModelVerification.purify_flux_model-Tuple{Flux.Chain}"><code>ModelVerification.purify_flux_model</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">purify_flux_model(model::Chain)</code></pre><p>Removes the starting <code>Flatten</code> layer from the model. This is a wrapper function  for <code>remove_flux_start_flatten</code>.</p><p><strong>Arguments</strong></p><ul><li><code>model</code> (<code>Chain</code>): <code>Flux.Chain</code> model.</li></ul><p><strong>Returns</strong></p><ul><li><code>model</code> (<code>Chain</code>): <code>Flux.Chain</code> model with the starting <code>Flatten</code> layer    removed.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/problem.jl#L87-L99">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.remove_flux_start_flatten-Tuple{Flux.Chain}" href="#ModelVerification.remove_flux_start_flatten-Tuple{Flux.Chain}"><code>ModelVerification.remove_flux_start_flatten</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">remove_flux_start_flatten(model::Chain)</code></pre><p>Removes the starting <code>Flatten</code> layer from the model.</p><p><strong>Arguments</strong></p><ul><li><code>model</code> (<code>Chain</code>): <code>Flux.Chain</code> model.</li></ul><p><strong>Returns</strong></p><ul><li><code>model</code> (<code>Chain</code>): <code>Flux.Chain</code> model with the starting <code>Flatten</code> layer    removed.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/problem.jl#L69-L80">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.build_onnx_model-Tuple{Any, Flux.Chain, InputSpec}" href="#ModelVerification.build_onnx_model-Tuple{Any, Flux.Chain, InputSpec}"><code>ModelVerification.build_onnx_model</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">build_onnx_model(path, model::Chain, input::InputSpec)</code></pre><p>Builds an ONNX model from the given <code>Flux.Chain</code> model and input specification.  The ONNX model is saved to the given path.</p><p><strong>Arguments</strong></p><ul><li><code>path</code> (<code>String</code>): Path to save the ONNX model.</li><li><code>model</code> (<code>Chain</code>): <code>Flux.Chain</code> model.</li><li><code>input</code> (<code>InputSpec</code>): Input specification.</li></ul><p><strong>Returns</strong></p><ul><li><code>path</code> (<code>String</code>): Path to the saved ONNX model.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/problem.jl#L135-L148">source</a></section></article><h3 id="Network-properties"><a class="docs-heading-anchor" href="#Network-properties">Network properties</a><a id="Network-properties-1"></a><a class="docs-heading-anchor-permalink" href="#Network-properties" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.get_act-Tuple{Any}" href="#ModelVerification.get_act-Tuple{Any}"><code>ModelVerification.get_act</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">get_act(l)</code></pre><p>Returns the activation function of the node <code>l</code> if it exists.</p><p><strong>Arguments</strong></p><ul><li><code>l</code>: node</li></ul><p><strong>Returns</strong></p><ul><li>Activation function of the node if it exists.</li><li>Otherwise, return <code>nothing</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/preprocessing.jl#L56-L67">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.n_nodes-Tuple{ModelVerification.Layer}" href="#ModelVerification.n_nodes-Tuple{ModelVerification.Layer}"><code>ModelVerification.n_nodes</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">n_nodes(L::Layer)</code></pre><p>Returns the number of neurons in a layer.</p><p><strong>Arguments</strong></p><ul><li><code>L</code> (<code>Layer</code>): Layer of a network.</li></ul><p><strong>Returns</strong></p><ul><li><code>n</code> (<code>Int</code>): Number of nodes in the layer <code>L</code> which is equivalent to the    number of biases in the layer.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/network.jl#L42-L53">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.get_sub_model-Tuple{Any, Any}" href="#ModelVerification.get_sub_model-Tuple{Any, Any}"><code>ModelVerification.get_sub_model</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">get_sub_model(model_info, end_node)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/network.jl#L56-L58">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.compute_output-Tuple{ModelVerification.Network, Any}" href="#ModelVerification.compute_output-Tuple{ModelVerification.Network, Any}"><code>ModelVerification.compute_output</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">compute_output(nnet::Network, input)</code></pre><p>Propagates a given vector through a <code>Network</code> and computes the output.</p><p><strong>Arguments</strong></p><ul><li><code>nnet</code> (<code>Network</code>): Network to be propagated.</li><li><code>input</code>: Vector to be propagated through <code>nnet</code>.</li></ul><p><strong>Returns</strong></p><ul><li><code>Vector</code> of the output of <code>nnet</code> given <code>input</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/util.jl#L157-L168">source</a></section></article><h3 id="Activation-function-operations"><a class="docs-heading-anchor" href="#Activation-function-operations">Activation function operations</a><a id="Activation-function-operations-1"></a><a class="docs-heading-anchor-permalink" href="#Activation-function-operations" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.get_activation-Tuple{ModelVerification.Layer{ModelVerification.ReLU}, Vector}" href="#ModelVerification.get_activation-Tuple{ModelVerification.Layer{ModelVerification.ReLU}, Vector}"><code>ModelVerification.get_activation</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">get_activation(L::Layer{ReLU}, x::Vector)</code></pre><p>Finds the activation pattern of a vector <code>x</code> subject to the activation function  given by the layer <code>L</code>. Returns a Vector{Bool} where <code>true</code> denotes the node is  &quot;active&quot;. In the sense of ReLU, this would be <code>x[i] &gt;= 0</code>.</p><p><strong>Arguments</strong></p><ul><li><code>L</code> (<code>Layer{ReLU}</code>): Layer with ReLU activation function.</li><li><code>x</code> (<code>Vector</code>): Vector to be propagated through the ReLU activation function.</li></ul><p><strong>Returns</strong></p><ul><li><code>Vector{Bool}</code> where <code>true</code> denotes the node is element-wise &quot;active&quot;.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/util.jl#L177-L190">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.get_activation-Tuple{ModelVerification.Layer{ModelVerification.Id}, Vararg{Any}}" href="#ModelVerification.get_activation-Tuple{ModelVerification.Layer{ModelVerification.Id}, Vararg{Any}}"><code>ModelVerification.get_activation</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">get_activation(L::Layer{Id}, args...)</code></pre><p>Finds the activation pattern of a vector <code>x</code> subject to the activation function  given by the layer <code>L</code>. Returns a Vector{Bool} where <code>true</code> denotes the node is  &quot;active&quot;. In the sense of Identity, this would be a vector of <code>true</code>&#39;s for all  nodes in the layer <code>L</code>.</p><p><strong>Arguments</strong></p><ul><li><code>L</code> (<code>Layer{Id}</code>): Layer with Identity activation function.</li><li><code>x</code> (<code>Vector</code>): Vector to be propagated through the Identity activation    function.</li></ul><p><strong>Returns</strong></p><ul><li><code>Vector{Bool}</code> where <code>true</code> denotes the node is element-wise &quot;active&quot;.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/util.jl#L193-L208">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.get_activation-Tuple{ModelVerification.Network, Vector{Float64}}" href="#ModelVerification.get_activation-Tuple{ModelVerification.Network, Vector{Float64}}"><code>ModelVerification.get_activation</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">get_activation(nnet::Network, x::Vector{Float64})</code></pre><p>Given a network, find the activation pattern of all neurons at a given point x. Returns Vector{Vector{Bool}}. Each Vector{Bool} refers to the activation pattern  of a particular layer.</p><p><strong>Arguments</strong></p><ul><li><code>nnet</code> (<code>Network</code>): Network to be propagated.</li><li><code>x</code> (<code>Vector{Float64}</code>): Vector to be propagated through <code>nnet</code>.</li></ul><p><strong>Returns</strong></p><ul><li><code>Vector{Vector{Bool}}</code> where each Vector{Bool} refers to the activation    pattern of a particular layer.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/util.jl#L211-L225">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.get_activation-Tuple{ModelVerification.Network, LazySets.Hyperrectangle}" href="#ModelVerification.get_activation-Tuple{ModelVerification.Network, LazySets.Hyperrectangle}"><code>ModelVerification.get_activation</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">get_activation(nnet::Network, input::Hyperrectangle)</code></pre><p>Given a network, find the activation pattern of all neurons for a given input  set. Assume ReLU activation function for all layers. This function first  computes the node-wise bounds of the input set, and then computes the  activation pattern using <code>get_activation(nnet, bounds)</code>.</p><p><strong>Arguments</strong></p><ul><li><code>nnet</code> (<code>Network</code>): Network to be propagated, with the activation function    assumed to be ReLU for all layers.</li><li><code>input</code> (<code>Hyperrectangle</code>): Input set to be propagated through <code>nnet</code>,        represented as a <code>Hyperrectangle</code>.</li></ul><p><strong>Returns</strong></p><ul><li><code>Vector{Vector{Bool}}</code> where each Vector{Bool} refers to the activation    pattern of a particular layer. Each element in each <code>Vector{Bool}</code> specifies    the activation pattern of a particular neuron. <code>1</code> means activated, <code>0</code>    means undetermined, and <code>-1</code> means not activated.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/util.jl#L237-L256">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.get_activation-Tuple{ModelVerification.Network, Vector{LazySets.Hyperrectangle}}" href="#ModelVerification.get_activation-Tuple{ModelVerification.Network, Vector{LazySets.Hyperrectangle}}"><code>ModelVerification.get_activation</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">get_activation(nnet::Network, bounds::Vector{Hyperrectangle})</code></pre><p>Given a network, find the activation pattern of all neurons given the node-wise  bounds. Assume ReLU activation function for all layers. Assume pre-activation  bounds where the bounds on the input are given by the first hyperrectangle, the  first hidden layer by the second hyperrectangle, and so on.</p><p><strong>Arguments</strong></p><ul><li><code>nnet</code> (<code>Network</code>): Network to be propagated, with the activation function    assumed to be ReLU for all layers.</li><li><code>bounds</code> (<code>Vector{Hyperrectangle}</code>): Vector of node-wise bounds, where the    bounds on the input are given by the first hyperrectangle, the first hidden    layer by the second hyperrectangle, and so on.</li></ul><p><strong>Returns</strong></p><ul><li><code>Vector{Vector{Bool}}</code> where each Vector{Bool} refers to the activation    pattern of a particular layer. Each element in each <code>Vector{Bool}</code> specifies    the activation pattern of a particular neuron. <code>1</code> means activated, <code>0</code>    means undetermined, and <code>-1</code> means not activated.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/util.jl#L262-L282">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.get_activation-Tuple{ModelVerification.Layer{ModelVerification.ReLU}, LazySets.Hyperrectangle}" href="#ModelVerification.get_activation-Tuple{ModelVerification.Layer{ModelVerification.ReLU}, LazySets.Hyperrectangle}"><code>ModelVerification.get_activation</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">get_activation(L::Layer{ReLU}, bounds::Hyperrectangle)</code></pre><p>Given a layer, find the activation pattern of all neurons in the layer given the  node-wise bounds. Assume ReLU activation function for the given layer. Assume  bounds is the pre-activation bounds for each ReLU in the layer.</p><p><strong>Arguments</strong></p><ul><li><code>L</code> (<code>Layer{ReLU}</code>): Layer to be propagated, with the activation function    assumed to be ReLU.</li><li><code>bounds</code> (<code>Hyperrectangle</code>): Node-wise pre-activation bounds for the layer.</li></ul><p><strong>Returns</strong></p><ul><li><code>Vector{Bool}</code> where each element refers to the activation pattern of a    particular neuron. <code>1</code> means activated, <code>0</code> means undetermined, and <code>-1</code>    means not activated.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/util.jl#L291-L307">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.approximate_act_map-Tuple{ModelVerification.ActivationFunction, LazySets.Hyperrectangle}" href="#ModelVerification.approximate_act_map-Tuple{ModelVerification.ActivationFunction, LazySets.Hyperrectangle}"><code>ModelVerification.approximate_act_map</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">approximate_act_map(act::ActivationFunction, input::Hyperrectangle)</code></pre><p>Returns a Hyperrectangle overapproximation of the activation map of the input. <code>act</code> must be monotonic.</p><p><strong>Arguments</strong></p><ul><li><code>act</code> (<code>ActivationFunction</code>): Activation function to be propagated.</li><li><code>input</code> (<code>Hyperrectangle</code>): Input set to be propagated through <code>act</code>.</li></ul><p><strong>Returns</strong></p><ul><li><code>Hyperrectangle</code> overapproximation of the activation map of the input.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/util.jl#L598-L610">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.approximate_act_map-Tuple{ModelVerification.Layer, LazySets.Hyperrectangle}" href="#ModelVerification.approximate_act_map-Tuple{ModelVerification.Layer, LazySets.Hyperrectangle}"><code>ModelVerification.approximate_act_map</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">approximate_act_map(layer::Layer, input::Hyperrectangle)</code></pre><p>Returns a Hyperrectangle overapproximation of the activation map of the input  for the given layer. The activation function of the layer must be monotonic. </p><p><strong>Arguments</strong></p><ul><li><code>layer</code> (<code>Layer</code>): Layer to be propagated for the activation map.</li><li><code>input</code> (<code>Hyperrectangle</code>): Input set to be propagated through <code>layer</code>.</li></ul><p><strong>Returns</strong></p><ul><li><code>Hyperrectangle</code> overapproximation of the activation map of the input.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/util.jl#L620-L632">source</a></section></article><h3 id="Gradient-operations"><a class="docs-heading-anchor" href="#Gradient-operations">Gradient operations</a><a id="Gradient-operations-1"></a><a class="docs-heading-anchor-permalink" href="#Gradient-operations" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.get_gradient-Tuple{ModelVerification.Network, Vector}" href="#ModelVerification.get_gradient-Tuple{ModelVerification.Network, Vector}"><code>ModelVerification.get_gradient</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">get_gradient(nnet::Network, x::Vector)</code></pre><p>Given a network, find the gradient for the input x. The function propagates  through the layers of the network, and computes the gradient at each layer.  The gradient at each layer is computed by multiplying the gradient at the  previous layer with the gradient of the current layer.</p><p><strong>Arguments</strong></p><ul><li><code>nnet</code> (<code>Network</code>): Network to be propagated.</li><li><code>x</code> (<code>Vector</code>): Vector to be propagated through <code>nnet</code>.</li></ul><p><strong>Returns</strong></p><ul><li><code>Matrix</code> of the gradient for the input <code>x</code> after propagating through <code>nnet</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/util.jl#L322-L336">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.act_gradient-Tuple{ModelVerification.ReLU, Vector}" href="#ModelVerification.act_gradient-Tuple{ModelVerification.ReLU, Vector}"><code>ModelVerification.act_gradient</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">act_gradient(act::ReLU, z_hat::Vector)</code></pre><p>Compute the gradient of an ReLU activation function at point z<em>hat. For each  element in `z</em>hat<code>, if</code>z<em>hat[i] &gt; 0<code>, then</code>act</em>gradient[i] = 1<code>, else</code>act_gradient[i] = 0`.</p><p><strong>Arguments</strong></p><ul><li><code>act</code> (<code>ReLU</code>): ReLU activation function.</li><li><code>z_hat</code> (<code>Vector</code>): Vector to be propagated through <code>act</code>.</li></ul><p><strong>Returns</strong></p><ul><li><code>Vector</code> of the gradient of <code>act</code> at <code>z_hat</code>. Each element in the vector    corresponds to the gradient of a particular neuron.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/util.jl#L349-L363">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.act_gradient-Tuple{ModelVerification.Id, Vector}" href="#ModelVerification.act_gradient-Tuple{ModelVerification.Id, Vector}"><code>ModelVerification.act_gradient</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">act_gradient(act::Id, z_hat::Vector)</code></pre><p>Compute the gradient of an Identity activation function at point z<em>hat. For  each element in `z</em>hat<code>,</code>act_gradient[i] = 1`. </p><p><strong>Arguments</strong></p><ul><li><code>act</code> (<code>Id</code>): Identity activation function.</li><li><code>z_hat</code> (<code>Vector</code>): Vector to be propagated through <code>act</code>.</li></ul><p><strong>Returns</strong></p><ul><li><code>Vector</code> of the gradient of <code>act</code> at <code>z_hat</code>. Each element in the vector    corresponds to the gradient of a particular neuron. </li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/util.jl#L366-L379">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.relaxed_relu_gradient-Tuple{Real, Real}" href="#ModelVerification.relaxed_relu_gradient-Tuple{Real, Real}"><code>ModelVerification.relaxed_relu_gradient</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">relaxed_relu_gradient(l::Real, u::Real)</code></pre><p>Return the relaxed slope of a ReLU activation based on its lower and upper  bounds. The relaxed ReLU function allows for a smooth approximation of the  gradient of the ReLU function. The relaxed ReLU function is defined as follows: </p><ul><li><code>f&#39;(x) = 0</code> if <code>upper-bound &lt; 0</code>, </li><li><code>f&#39;(x) = 1</code> if <code>lower-bound &gt; 0</code>, </li><li>and <code>f&#39;(x) = x/(u-l)</code> if <code>lower-bound &lt; x &lt; upper-bound</code> which is the slope of    the line connecting the points <code>(l, ReLU(l))</code> and <code>(u, ReLU(u))</code>.</li></ul><p>This provides a differentiable approximation of the ReLU function within the  interval [l, u].</p><p><strong>Arguments</strong></p><ul><li><code>l</code> (<code>Real</code>): Lower-bound of the input to the ReLU activation function.</li><li><code>u</code> (<code>Real</code>): Upper-bound of the input to the ReLU activation function.</li></ul><p><strong>Returns</strong></p><ul><li><code>0.0</code> if <code>u &lt;= 0.0</code>, </li><li><code>1.0</code> if <code>l &gt;= 0.0</code>,</li><li><code>u/(u-l)</code> otherwise.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/util.jl#L382-L404">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.act_gradient_bounds-Tuple{ModelVerification.Network, LazySets.AbstractPolytope}" href="#ModelVerification.act_gradient_bounds-Tuple{ModelVerification.Network, LazySets.AbstractPolytope}"><code>ModelVerification.act_gradient_bounds</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">act_gradient_bounds(nnet::Network, input::AbstractPolytope)</code></pre><p>Compute the bit-wise bounds on the gradient post activation operation given an  input  set. Currently only support ReLU activation function. It first calculates  the bounds of the input for each layer using <code>get_bounds</code> function (this  function propagates through each layer and computes the bounds of each layer).  Then, it computes the bit-wise lower and upper gradient for each layer using  <code>act_gradient</code>. The final output is a tuple of two vectors, where each vector is  a vector of bit-vectors. Each element in the vector corresponds to the gradient  of a particular neuron which can be either <code>0</code> (not activated) or  <code>1</code> (activated).</p><p><strong>Arguments</strong></p><ul><li><code>nnet</code> (<code>Network</code>): Network to be propagated.</li><li><code>input</code> (<code>AbstractPolytope</code>): Input set to be propagated through <code>nnet</code>.</li></ul><p><strong>Returns</strong></p><ul><li><code>LΛ, UΛ::NTuple{2, Vector{BitVector}}</code>: lower and upper bit-wsie bounds on the    activation gradients for each layer.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/util.jl#L411-L431">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.get_gradient_bounds-Tuple{ModelVerification.Network, LazySets.AbstractPolytope}" href="#ModelVerification.get_gradient_bounds-Tuple{ModelVerification.Network, LazySets.AbstractPolytope}"><code>ModelVerification.get_gradient_bounds</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">get_gradient_bounds(nnet::Network, input::AbstractPolytope)</code></pre><p>Get lower and upper bounds on network gradient for given gradient bounds on  activations, or given an input set. It first calculates the bit-wise lower and upper gradient bounds for each layer  using  <code>act_gradient_bounds</code>. Then, it computes the gradient bounds of the  entire network for the weights using <code>get_gradient_bounds</code>.</p><p><strong>Arguments</strong></p><ul><li><code>nnet</code> (<code>Network</code>): Network to be propagated.</li><li><code>input</code> (<code>AbstractPolytope</code>): Input set to be propagated through <code>nnet</code>.</li></ul><p><strong>Returns</strong></p><ul><li><code>(LG, UG)</code>: <code>NTuple{2, Matrix{Float64}</code> of the lower and upper bounds of the    entire network.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/util.jl#L448-L464">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.get_gradient_bounds-Tuple{ModelVerification.Network, Vector{&lt;:AbstractVector}, Vector{&lt;:AbstractVector}}" href="#ModelVerification.get_gradient_bounds-Tuple{ModelVerification.Network, Vector{&lt;:AbstractVector}, Vector{&lt;:AbstractVector}}"><code>ModelVerification.get_gradient_bounds</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">get_gradient_bounds(nnet::Network, LΛ::Vector{AbstractVector}, 
                    UΛ::Vector{AbstractVector})</code></pre><p>Given bit-wise lower and upper gradient bounds for each layer (<code>LΛ</code> and <code>UΛ</code>),  compute the lower and upper bounds of the entire network for the weights of the  layers. </p><p><strong>Arguments</strong></p><ul><li><code>nnet</code> (<code>Network</code>): Network to be propagated.</li><li><code>LΛ</code> (<code>Vector{AbstractVector}</code>): Vector of bit-wise lower gradient bounds for    each layer. </li><li><code>UΛ</code> (<code>Vector{AbstractVector}</code>): Vector of bit-wise upper gradient bounds for   each layer.    </li></ul><p><strong>Returns</strong></p><ul><li><code>(LG, UG)</code>: <code>NTuple{2, Matrix{Float64}</code> of the lower and upper bounds of the    entire network.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/util.jl#L470-L488">source</a></section></article><h3 id="Bound-and-Specification-operations"><a class="docs-heading-anchor" href="#Bound-and-Specification-operations">Bound &amp; Specification operations</a><a id="Bound-and-Specification-operations-1"></a><a class="docs-heading-anchor-permalink" href="#Bound-and-Specification-operations" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.interval_map-Tuple{Matrix, AbstractVecOrMat, AbstractVecOrMat}" href="#ModelVerification.interval_map-Tuple{Matrix, AbstractVecOrMat, AbstractVecOrMat}"><code>ModelVerification.interval_map</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">interval_map(W::Matrix, l::AbstractVecOrMat, u::AbstractVecOrMat)</code></pre><p>Simple linear mapping of the weights on intervals. <code>L, U := ([W]₊*l + [W]₋*u), ([W]₊*u + [W]₋*l)</code></p><p><strong>Arguments</strong></p><ul><li><code>W</code> (<code>AbstractMatrix</code>): Matrix of weights.</li><li><code>l</code> (<code>AbstractVecOrMat</code>): Vector or matrix of lower bounds.</li><li><code>u</code> (<code>AbstractVecOrMat</code>): Vector or matrix of upper bounds.</li></ul><p><strong>Returns</strong></p><ul><li><code>(l_new, u_new)</code>: New bounds after the linear mapping.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/util.jl#L501-L514">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.get_bounds-Tuple{ModelVerification.Network, Any}" href="#ModelVerification.get_bounds-Tuple{ModelVerification.Network, Any}"><code>ModelVerification.get_bounds</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">get_bounds(nnet::Network, input; before_act::Bool = false)</code></pre><p>Computes node-wise bounds given a input set. The optional last argument determines whether the bounds are pre- or post-activation.</p><p><strong>Arguments</strong></p><ul><li><code>nnet</code> (<code>Network</code>): Network to be propagated.</li><li><code>input</code> (<code>AbstractPolytope</code>): Input set to be propagated through <code>nnet</code>.</li><li><code>before_act</code>: Optional argument that determines whether the bounds are    pre- or post-activation. Defaults to <code>false</code>.</li></ul><p><strong>Returns</strong></p><ul><li><code>Vector{Hyperrectangle}</code>: bounds for all nodes. <code>bounds[1]</code> is the    input set overapproximated with a <code>Hyperrectangle</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/util.jl#L521-L536">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.get_bounds-Tuple{Problem}" href="#ModelVerification.get_bounds-Tuple{Problem}"><code>ModelVerification.get_bounds</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">get_bounds(problem::Problem; kwargs...)</code></pre><p>Compute node-wise bounds for a given <code>Problem</code> using <code>get_bounds(nnet, input)</code>.</p><p><strong>Arguments</strong></p><ul><li><code>problem</code> (<code>Problem</code>): Problem to be propagated.</li><li><code>kwargs</code>: Keyword arguments to be passed to <code>get_bounds(nnet, input)</code> such as    the optional boolean argument <code>before_act</code>.</li></ul><p><strong>Returns</strong></p><ul><li><code>Vector{Hyperrectangle}</code>: bounds for all nodes. <code>bounds[1]</code> is the input set.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/util.jl#L554-L566">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.isbounded-Tuple{Any}" href="#ModelVerification.isbounded-Tuple{Any}"><code>ModelVerification.isbounded</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">isbounded(input)</code></pre><p>Check if input set is bounded. If the <code>input</code> is of type <code>HPolytope</code>, then  <code>LazySets.isbounded</code> converts the <code>HPolytope</code> to a <code>HPolyhedron</code> and checks if  that is bounded. Otherwise, <code>LazySets.isbounded</code> is called directly.</p><p><strong>Arguments</strong></p><ul><li><code>input</code>: Input set to be checked for boundedness.</li></ul><p><strong>Returns</strong></p><ul><li><code>true</code> if <code>input</code> is bounded, <code>false</code> otherwise.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/util.jl#L648-L660">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.is_hypercube-Tuple{LazySets.Hyperrectangle}" href="#ModelVerification.is_hypercube-Tuple{LazySets.Hyperrectangle}"><code>ModelVerification.is_hypercube</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">is_hypercube(set::Hyperrectangle)</code></pre><p>Check if <code>set</code> is a is_hypercube. This is done by checking if all the radii of  the <code>Hyperrectangle</code> are equal in all directions.</p><p><strong>Arguments</strong></p><ul><li><code>set</code> (<code>Hyperrectangle</code>): Set to be checked for hypercube-ness.</li></ul><p><strong>Returns</strong></p><ul><li><code>true</code> if <code>set</code> is a hypercube, <code>false</code> otherwise.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/util.jl#L669-L680">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.is_halfspace_equivalent-Tuple{Any}" href="#ModelVerification.is_halfspace_equivalent-Tuple{Any}"><code>ModelVerification.is_halfspace_equivalent</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">is_halfspace_equivalent(set)</code></pre><p>Check if <code>set</code> is halfspace equivalent. This is done by checking if the number  of constraints in the <code>set</code> is equal to 1.</p><p><strong>Arguments</strong></p><ul><li><code>set</code>: Set to be checked for halfspace equivalence.</li></ul><p><strong>Returns</strong></p><ul><li><code>true</code> if <code>set</code> is halfspace equivalent, <code>false</code> otherwise.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/util.jl#L683-L694">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ModelVerification.UnboundedInputError" href="#ModelVerification.UnboundedInputError"><code>ModelVerification.UnboundedInputError</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">UnboundedInputError &lt;: Exception</code></pre><p>Exception thrown when an input set is unbounded.</p><p><strong>Fields</strong></p><ul><li><code>msg</code> (<code>String</code>): Error message.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/intelligent-control-lab/ModelVerification.jl/blob/a36fadb97c1a44b916edba244c133ab1ae10825b/src/utils/util.jl#L635-L642">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="problem.html">« Problem Outline</a><a class="docs-footer-nextpage" href="safety_spec.html">Input-Output Specification »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.1.0 on <span class="colophon-date" title="Monday 11 December 2023 10:58">Monday 11 December 2023</span>. Using Julia version 1.9.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
