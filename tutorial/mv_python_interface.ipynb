{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ModelVerfication.jl Python Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we report how it is possible to use ModelVerification directly in Python:\n",
    "\n",
    "## Installation dependencies for ModelVerfication.jl Python interface:\n",
    "\n",
    "  \n",
    "To have compatibility with our toolbox, we created an interface to merge Julia and Python code. Hence, to run the toolbox using a python script follow these steps:\n",
    "\n",
    "1) Download and Install Julia from here: https://julialang.org/downloads/ and select the stable version.\n",
    "\n",
    "2) Copy and paste this line in the terminal: \n",
    "\n",
    "> export PATH=\"$PATH:where-is-located-the-folder/julia-1.9.3/bin\"\n",
    "\n",
    "Note: Replace 'julia-1.8.5-linux-x86_64' with your Julia's version that was previously downloaded.\n",
    "\n",
    "1) Start Julia by running `julia` in the terminal, if everything is correctly installed, the Julia prompt should appear.\n",
    "\n",
    "2) Set the `ENV[\"PYTHON\"]` variable in Julia:\n",
    "\n",
    "\n",
    "> ENV[\"PYTHON\"] = \"/Users/your-name/location-of-you-python-bin-file\"\n",
    "\n",
    "Note: replace the path with your python path. The last path part should be the same.\n",
    "\n",
    "5) Now install PyCall and other packages using Pkg, Juliaâ€™s package manager:\n",
    "\n",
    "> using Pkg\n",
    "\n",
    "> Pkg.add(\"PyCall\")\n",
    " \n",
    "6) pip install julia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from julia.api import Julia\n",
    "jl = Julia(compiled_modules=False)\n",
    "from julia import Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let's import some useful packages in Julia (it will require at least 5 min)\n",
    "Main.eval(\"using Revise; using ModelVerification;using LazySets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can convert your .h5, .pt(h) model file into onnx using one of the scripts provided in the 'converters/' folder... let's now first test a forward propagion and then define the safety property to be verified!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PyCall.jlwrap Chain(Dense(1 => 2, relu), Dense(2 => 2, relu), Dense(2 => 1, relu))>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, let's load the model\n",
    "onnx_path = \"models/small_nnet.onnx\"\n",
    "Main.eval(f'toy_model = ModelVerification.build_flux_model(\"{onnx_path}\")')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test propagation onnx:\n",
      "[68.90342096]\n"
     ]
    }
   ],
   "source": [
    "print(\"Test propagation onnx:\")\n",
    "output = Main.eval(\"toy_model([0.60014254])\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As reported in the tutorial suppose we want to verify the following safety property.  We consider the following DNN called \"small_nnet\":\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"images_tutorial/toyDNN.png\" alt=\"Drawing\" align=\"center\" style=\"width: 600px;\"/>\n",
    "</p>\n",
    "\n",
    "The model has a single input node, two hidden layers composed of two ReLU nodes, and a single output node. Hence this DNN is a non-linear function that maps $\\mathbb{R}^1 \\to \\mathbb{R}^1$. Suppose we want to verify if all the possible inputs in a vector that assume values between $\\mathcal{X}=[-2.5, 2.5]$ are mapped in the vector $\\mathcal{Y}=[18.5, 114.5]$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lower bound is:  [-2.5]\n",
      "The upper bound is:  [2.5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<PyCall.jlwrap Ai2z()>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "property = {\"X\": [[-2.5, 2.5]], \"Y\":[18.5, 114.5]}\n",
    "lower = [l[0] for l in property[\"X\"]]\n",
    "upper = [l[1] for l in property[\"X\"]]\n",
    "\n",
    "print(\"The lower bound is: \", lower)\n",
    "print(\"The upper bound is: \", upper)\n",
    "\n",
    "Main.eval(f'X = Hyperrectangle(low={lower}, high={upper})')\n",
    "Main.eval(f'Y = Hyperrectangle(low=[{property[\"Y\"][0]}], high=[{property[\"Y\"][1]}])')\n",
    "\n",
    "# let's instantiate the Problem for the ModelVerification.jl toolbox\n",
    "Main.eval(\"problem = Problem(toy_model, X, Y)\")\n",
    "\n",
    "# we instantiate the 3 main components for the verification process\n",
    "Main.eval(\"search_method = BFS(max_iter=100, batch_size=1)\")\n",
    "Main.eval(\"split_method = Bisect(1)\")\n",
    "Main.eval(\"solver = Ai2()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result is:  <PyCall.jlwrap BasicResult(:holds)>\n",
      "The property holds !\n"
     ]
    }
   ],
   "source": [
    "# run the verification part\n",
    "# we then start the verification process using the verify function of ModelVerification.jl\n",
    "result = Main.eval(\"verify(search_method, split_method, solver, problem)\")\n",
    "\n",
    "# the verification result is stored in 'result'. Let's print it!\n",
    "print(\"The result is: \", result)\n",
    "\n",
    "# the verification result is stored in 'result.status'. Let's see if the property holds...\n",
    "print(\"The property\", result.status, \"!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
