{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Revise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ModelVerification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LazySets\n",
    "using PyCall\n",
    "using CSV\n",
    "using ONNX\n",
    "using Flux\n",
    "using ONNXNaiveNASflux\n",
    "using Test\n",
    "using NNlib\n",
    "using NaiveNASflux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Flux: onehotbatch, onecold, flatten\n",
    "# using Flux.Losses: logitcrossentropy\n",
    "# using Statistics: mean\n",
    "using CUDA\n",
    "using MLDatasets: CIFAR10, MNIST\n",
    "using MLUtils: splitobs, DataLoader\n",
    "using Accessors\n",
    "using Profile\n",
    "using LinearAlgebra\n",
    "using Einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_bound.batch_data_min max\n",
      "[-2.5;;][2.5;;]\n",
      "---"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1\n",
      "[0.0;;]\n",
      "---\n",
      "2\n",
      "[0.0; 0.0;;]\n",
      "---\n",
      "3\n",
      "[8.333361500856284e-10; 8.333361500856284e-10;;]\n",
      "batch_info[:spec_A_b]\n",
      "Array{Float64}[[1.0; -1.0;;;], [-115.0; 18.0;;]]\n",
      "out_l, out_u\n",
      "[18.499999999999993;;;][114.5;;;]\n",
      "spec_l, spec_u\n",
      "[-96.5; -0.5000000800002704;;;][-0.4999999999999858; -0.4999999799999324;;;]\n",
      "batch_bound.batch_data_min max\n",
      "[-2.5;;][2.5;;]\n",
      "---\n",
      "1\n",
      "[0.0;;]\n",
      "---\n",
      "2\n",
      "[0.0; 0.0;;]\n",
      "---\n",
      "3\n",
      "[8.333361500856284e-10; 8.333361500856284e-10;;]\n",
      "batch_info[:spec_A_b]\n",
      "Array{Float64}[[1.0; -1.0;;;], [-114.0; 19.0;;]]\n",
      "out_l, out_u\n",
      "[18.499999999999993;;;][114.5;;;]\n",
      "spec_l, spec_u\n",
      "[-95.5; 0.4999999199997296;;;][0.5000000000000142; 0.5000000200000676;;;]\n",
      "batch_bound.batch_data_min max\n",
      "[-2.5;;][0.0;;]\n",
      "---\n",
      "1\n",
      "[0.0;;]\n",
      "---\n",
      "2\n",
      "[0.0; 0.0;;]\n",
      "---\n",
      "3\n",
      "[8.333361500856284e-10; 8.333361500856284e-10;;]\n",
      "batch_info[:spec_A_b]\n",
      "Array{Float64}[[1.0; -1.0;;;], [-114.0; 19.0;;]]\n",
      "out_l, out_u\n",
      "[18.5;;;][54.5;;;]\n",
      "spec_l, spec_u\n",
      "[-95.5; 0.4999999699998986;;;][-59.5; 0.5000000200000676;;;]\n",
      "batch_bound.batch_data_min max\n",
      "[0.0;;][2.5;;]\n",
      "---"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1\n",
      "[0.0;;]\n",
      "---\n",
      "2\n",
      "[0.0; 0.0;;]\n",
      "---\n",
      "3\n",
      "[0.0; 0.0;;]\n",
      "batch_info[:spec_A_b]\n",
      "Array{Float64}[[1.0; -1.0;;;], [-114.0; 19.0;;]]\n",
      "out_l, out_u\n",
      "[54.5;;;][114.5;;;]\n",
      "spec_l, spec_u\n",
      "[-59.5; -95.5;;;][0.5; -35.5;;;]\n",
      "batch_bound.batch_data_min max\n",
      "[-2.5;;][-1.25;;]\n",
      "---\n",
      "1\n",
      "[0.0;;]\n",
      "---\n",
      "2\n",
      "[0.0; 0.0;;]\n",
      "---\n",
      "3\n",
      "[-0.41876119232573705; -0.41876119232573705;;]\n",
      "batch_info[:spec_A_b]\n",
      "Array{Float64}[[1.0; -1.0;;;], [-114.0; 19.0;;]]\n",
      "out_l, out_u\n",
      "[18.5;;;][24.5;;;]\n",
      "spec_l, spec_u\n",
      "[-95.5; 0.5;;;][-89.5; 0.5;;;]\n",
      "batch_bound.batch_data_min max\n",
      "[-2.5;;][2.5;;]\n",
      "---\n",
      "1\n",
      "[0.0;;]\n",
      "---\n",
      "2\n",
      "[0.0; 0.0;;]\n",
      "---\n",
      "3\n",
      "[8.333361500856284e-10; 8.333361500856284e-10;;]\n",
      "batch_info[:spec_A_b]\n",
      "Array{Float64}[[1.0; -1.0;;;], [-118.0; 115.0;;]]\n",
      "out_l, out_u\n",
      "[37.69999997999994;;;][37.70000008000027;;;]\n",
      "spec_l, spec_u\n",
      "[-80.30000002000007; 19.69999999999998;;;][-80.29999991999973; 115.69999999999999;;;]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(value = \u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m, time = 0.525718638, bytes = 67379300, gctime = 0.0, gcstats = Base.GC_Diff(67379300, 0, 0, 1272249, 141, 0, 0, 0, 0))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function test_mlp(prop_method)\n",
    "    small_nnet_file = \"/home/verification/ModelVerification.jl/test/networks/small_nnet.nnet\"\n",
    "    # small_nnet encodes the simple function 24*max(x + 1.5, 0) + 18.5\n",
    "    small_nnet = read_nnet(small_nnet_file, last_layer_activation = ModelVerification.ReLU())\n",
    "    flux_model = Flux.Chain(small_nnet)\n",
    "    #ONNXNaiveNASflux.save(\"/home/verification/ModelVerification.jl/small_nnet.onnx\", flux_model, (1,1))\n",
    "    #println(flux_model)\n",
    "    #println(flux_model.layers[1].weight, \" \", flux_model.layers[1].bias) # max(x+1.5, 0) max(x+1.5, 0)              [0,4]\n",
    "    #println(flux_model.layers[2].weight, \" \", flux_model.layers[2].bias) # 4*max(x+1.5, 0)+2.5 4*max(x+1.5, 0)+2.5  [2.5, 18.5]\n",
    "    #println(flux_model.layers[3].weight, \" \", flux_model.layers[3].bias) # 24*max(x+1.5, 0)+18.5                    [18.5, 114.5]\n",
    "    in_hyper  = Hyperrectangle(low = [-2.5], high = [2.5]) # expected out: [18.5, 114.5]\n",
    "    out_holds = Hyperrectangle(low = [18], high = [115.0]) # \n",
    "    out_violated    = Hyperrectangle(low = [19], high = [114]) #\n",
    "    comp_holds    = Complement(Hyperrectangle(low = [115], high = [118])) # y ≤ 115 or 118 ≤ y\n",
    "    comp_violated    = Complement(Hyperrectangle(low = [10], high = [19])) # y ≤ 10 or 19 ≤ y\n",
    "    info = nothing\n",
    "    search_method = BFS(max_iter=5, batch_size=1)\n",
    "    split_method = Bisect(1)\n",
    "    # @test verify(search_method, split_method, prop_method, Problem(\"/home/verification/ModelVerification.jl/small_nnet.onnx\", in_hyper, out_holds)).status == :holds\n",
    "    # @test verify(search_method, split_method, prop_method, Problem(\"/home/verification/ModelVerification.jl/small_nnet.onnx\", in_hyper, out_violated)).status == :violated\n",
    "    # @test verify(search_method, split_method, prop_method, Problem(\"/home/verification/ModelVerification.jl/small_nnet.onnx\", in_hyper, comp_holds)).status == :holds\n",
    "    @test verify(search_method, split_method, prop_method, Problem(\"/home/verification/ModelVerification.jl/small_nnet.onnx\", in_hyper, comp_violated)).status == :violated\n",
    "    #= @test verify(search_method, split_method, prop_method, Problem(flux_model, in_hyper, out_holds)).status == :holds\n",
    "    @test verify(search_method, split_method, prop_method, Problem(flux_model, in_hyper, out_violated)).status == :violated\n",
    "    @test verify(search_method, split_method, prop_method, Problem(flux_model, in_hyper, comp_holds)).status == :holds\n",
    "    @test verify(search_method, split_method, prop_method, Problem(flux_model, in_hyper, comp_violated)).status == :violated =#\n",
    "end\n",
    "@timed begin\n",
    "    # #for i in 1:1\n",
    "    #     test_mlp(Ai2z())\n",
    "        # test_mlp(Crown(true, true))\n",
    "    #     test_mlp(StarSet(Crown(true, true)))\n",
    "        test_mlp(AlphaCrown(Crown(true, true), true, false, Flux.Optimiser(Flux.ADAM(0.1)), 10))\n",
    "    #end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Chain([\n",
    "    Conv((3, 3), 3 => 8, relu, pad=SamePad(), stride=(2, 2)), #pad=SamePad() ensures size(output,d) == size(x,d) / stride.\n",
    "    BatchNorm(8),\n",
    "    MeanPool((2,2)),\n",
    "    SkipConnection(\n",
    "        Chain([\n",
    "            Conv((5, 5), 8 => 8, relu, pad=SamePad(), stride=(1, 1))\n",
    "            ]),\n",
    "        +\n",
    "    ),\n",
    "    #ConvTranspose((3, 3), 8 => 4, relu, pad=SamePad(), stride=(2, 2)),#pad=SamePad() ensures size(output,d) == size(x,d) * stride.\n",
    "    Flux.flatten,\n",
    "    Dense(512, 100, relu),\n",
    "    Dense(100, 10)\n",
    "])\n",
    "testmode!(model)\n",
    "# image_seeds = CIFAR10(:train)[1:5].features # 32 x 32 x 3 x 5\n",
    "image_seeds = [CIFAR10(:train)[i].features for i in 1:2]\n",
    "input_set = ImageConvexHull(image_seeds)\n",
    "# println(typeof(image_seeds[1][1,1,1,1]))\n",
    "search_method = BFS(max_iter=1, batch_size=1)\n",
    "split_method = Bisect(1)\n",
    "output_set = BallInf(zeros(10), 1.0)\n",
    "onnx_model_path = \"/home/verification/ModelVerification.jl/mlp.onnx\"\n",
    "flux_model = model\n",
    "image_shape = (32, 32, 3, 5)\n",
    "println(image_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_method = ImageStar()\n",
    "@timed verify(search_method, split_method, prop_method, Problem(flux_model, input_set, output_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_method = ImageStarZono()\n",
    "@timed verify(search_method, split_method, prop_method, Problem(onnx_model_path, image_seeds, output_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Chain([\n",
    "    Flux.flatten,\n",
    "    Dense(784, 200, relu),\n",
    "    Dense(200, 10)\n",
    "])\n",
    "image_seeds = [MNIST(:train)[i].features for i in 1:1]\n",
    "search_method = BFS(max_iter=1, batch_size=1)\n",
    "split_method = Bisect(1)\n",
    "output_set = BallInf(zeros(10), 1.0)\n",
    "onnx_model_path = \"/home/verification/ModelVerification.jl/debug.onnx\"\n",
    "Flux_model = model\n",
    "image_shape = (28, 28, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Chain([\n",
    "    Conv((3, 3), 3 => 8, relu, pad=SamePad(), stride=(2, 2)), #pad=SamePad() ensures size(output,d) == size(x,d) / stride.\n",
    "    BatchNorm(8),\n",
    "    MeanPool((2,2)),\n",
    "    SkipConnection(\n",
    "        Chain([\n",
    "            Conv((5, 5), 8 => 8, relu, pad=SamePad(), stride=(1, 1))\n",
    "            ]),\n",
    "        +\n",
    "    ),\n",
    "    Conv((3, 3), 8 => 8, relu, pad=SamePad(), stride=(2, 2)),\n",
    "    #ConvTranspose((3, 3), 8 => 4, relu, pad=SamePad(), stride=(2, 2)),#pad=SamePad() ensures size(output,d) == size(x,d) * stride.\n",
    "    Flux.flatten,\n",
    "    Dense(128, 100, relu),\n",
    "    Dense(100, 10)\n",
    "])\n",
    "testmode!(model)\n",
    "# image_seeds = CIFAR10(:train)[1:5].features # 32 x 32 x 3 x 5\n",
    "image_seeds = [CIFAR10(:train)[i].features for i in 1:2]\n",
    "# println(typeof(image_seeds[1][1,1,1,1]))\n",
    "search_method = BFS(max_iter=1, batch_size=1)\n",
    "split_method = Bisect(1)\n",
    "output_set = BallInf(zeros(10), 1.0)\n",
    "onnx_model_path = \"/home/verification/ModelVerification.jl/mlp.onnx\"\n",
    "Flux_model = model\n",
    "image_shape = (32, 32, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_method = ImageStar()\n",
    "@timed verify(search_method, split_method, prop_method, Problem(onnx_model_path, Flux_model, image_shape, image_seeds, output_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_method = ImageStarZono()\n",
    "@timed verify(search_method, split_method, prop_method, Problem(onnx_model_path, Flux_model, image_shape, image_seeds, output_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Chain([\n",
    "    Conv((3, 3), 3 => 128, relu, pad=SamePad(), stride=(2, 2)), #pad=SamePad() ensures size(output,d) == size(x,d) / stride.\n",
    "    BatchNorm(128),\n",
    "    MeanPool((2,2)),\n",
    "    SkipConnection(\n",
    "        Chain([\n",
    "            Conv((5, 5), 128 => 128, relu, pad=SamePad(), stride=(1, 1))\n",
    "            ]),\n",
    "        +\n",
    "    ),\n",
    "    ConvTranspose((3, 3), 128 => 128, relu, pad=SamePad(), stride=(2, 2)),#pad=SamePad() ensures size(output,d) == size(x,d) * stride.\n",
    "    Flux.flatten,\n",
    "    Dense(32768, 100, relu),\n",
    "    Dense(100, 10)\n",
    "])\n",
    "testmode!(model)\n",
    "# image_seeds = CIFAR10(:train)[1:5].features # 32 x 32 x 3 x 5\n",
    "image_seeds = [CIFAR10(:train)[i].features for i in 1:2]\n",
    "# println(typeof(image_seeds[1][1,1,1,1]))\n",
    "search_method = BFS(max_iter=1, batch_size=1)\n",
    "split_method = Bisect(1)\n",
    "output_set = BallInf(zeros(10), 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_method = ImageStarZono()\n",
    "@timed verify(search_method, split_method, prop_method, Problem(model, image_seeds, output_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Profile.clear()\n",
    "@profile verify(search_method, split_method, prop_method, Problem(model, image_seeds, output_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open(\"./prof.txt\", \"w\") do s\n",
    "    Profile.print(IOContext(s, :displaysize => (24, 500)))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
