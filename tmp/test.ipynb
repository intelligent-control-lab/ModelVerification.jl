{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Revise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ModelVerification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LazySets\n",
    "using PyCall\n",
    "using CSV\n",
    "using ONNX\n",
    "using Flux\n",
    "using Test\n",
    "using NNlib\n",
    "using ONNXNaiveNASflux\n",
    "using NaiveNASflux\n",
    "using Zygote\n",
    "# using DataFrames\n",
    "# import Flux: flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Flux: onehotbatch, onecold, flatten\n",
    "# using Flux.Losses: logitcrossentropy\n",
    "# using Statistics: mean\n",
    "using CUDA\n",
    "using MLDatasets: CIFAR10, MNIST\n",
    "using MLUtils: splitobs, DataLoader\n",
    "using Accessors\n",
    "using Profile\n",
    "using LinearAlgebra\n",
    "using Einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct AlphaLayer\n",
    "    node\n",
    "    alpha\n",
    "    lower\n",
    "    unstable_mask\n",
    "    lower_mask \n",
    "    upper_slope\n",
    "    lower_bias\n",
    "    upper_bias\n",
    "end\n",
    "Flux.@functor AlphaLayer (alpha,)\n",
    "\n",
    "function (f::AlphaLayer)(x)\n",
    "    Last_A = x[1]\n",
    "    Last_bias = x[2]\n",
    "    lower_slope = clamp.(f.alpha, 0, 1) .* f.unstable_mask .+ f.lower_mask \n",
    "    if f.lower \n",
    "        New_A = bound_oneside(Last_A, lower_slope, f.upper_slope)\n",
    "    else\n",
    "        New_A = bound_oneside(Last_A, f.upper_slope, lower_slope)\n",
    "    end\n",
    "\n",
    "    if isnothing(Last_bias)\n",
    "        return [New_A, nothing]\n",
    "    end\n",
    "    New_bias = multiply_bias(Last_bias, f.upper_slope, f.upper_bias, f.lower_bias)\n",
    "\n",
    "    return [New_A, New_bias]\n",
    "end\n",
    "\n",
    "#Upper bound slope and intercept according to CROWN relaxation.\n",
    "function relu_upper_bound(lower, upper)\n",
    "    lower_r = clamp.(lower, -Inf, 0)\n",
    "    upper_r = clamp.(upper, 0, Inf)\n",
    "    upper_r .= max.(upper_r, lower_r .+ 1e-8)\n",
    "    upper_slope = upper_r ./ (upper_r .- lower_r) #the slope of the relu upper bound\n",
    "    upper_bias = - lower_r .* upper_slope #the bias of the relu upper bound\n",
    "    return upper_slope, upper_bias\n",
    "end\n",
    "\n",
    "function clamp_mutiply_A(last_A, slope_pos, slope_neg) \n",
    "    A_pos = clamp.(last_A, 0, Inf)\n",
    "    A_neg = clamp.(last_A, -Inf, 0)\n",
    "    slope_pos = repeat(reshape(slope_pos,(1, size(slope_pos)...)), size(A_pos)[1], 1, 1) #add spec dim for slope_pos\n",
    "    slope_neg = repeat(reshape(slope_neg,(1, size(slope_neg)...)), size(A_neg)[1], 1, 1) #add spec dim for slope_pos\n",
    "    New_A = slope_pos .* A_pos .+ slope_neg .* A_neg \n",
    "    return New_A\n",
    "end \n",
    "\n",
    "\n",
    "function clamp_mutiply_bias(last_A, bias_pos, bias_neg) \n",
    "    A_pos = clamp.(last_A, 0, Inf)\n",
    "    A_neg = clamp.(last_A, -Inf, 0) \n",
    "    if bias_pos !== nothing #new_bias_pos = torch.einsum('s...b,s...b->sb', A_pos, bias_pos)\n",
    "        new_bias_pos = zeros((size(A_pos)[1], size(A_pos)[end]))#spec_dim x batch dim\n",
    "        @einsum new_bias_pos[s,b] = A_pos[s,r,b] * bias_pos[r,b]\n",
    "    end\n",
    "\n",
    "    if bias_neg !== nothing #new_bias_neg = torch.einsum('...sb,...sb->sb', A_neg, bias_neg)\n",
    "        new_bias_neg = zeros((size(A_neg)[1], size(A_neg)[end]))#spec_dim x batch dim\n",
    "        @einsum new_bias_neg[s,b] = A_neg[s,r,b] * bias_neg[r,b]\n",
    "    end\n",
    "    New_bias = new_bias_pos .+ new_bias_neg\n",
    "    return New_bias\n",
    "end \n",
    "\n",
    "#using last_A for getting New_A\n",
    "function multiply_by_A_signs(last_A, slope_pos, slope_neg)\n",
    "    if ndims(slope_pos) == 1\n",
    "        # Special case for LSTM, the bias term is 1-dimension. \n",
    "        New_A = clamp.(last_A, 0, Inf) .* slope_pos .+ clamp.(last_A, -Inf, 0) .* slope_neg\n",
    "    else\n",
    "        New_A = clamp_mutiply_A(last_A, slope_pos, slope_neg)\n",
    "        return New_A\n",
    "    end\n",
    "end\n",
    "\n",
    "function multiply_bias(last_A, upper_slope, bias_pos, bias_neg)\n",
    "    if ndims(upper_slope) == 1\n",
    "        # Special case for LSTM, the bias term is 1-dimension. \n",
    "        New_bias = clamp.(last_A, 0, Inf) .* bias_pos .+ clamp.(last_A, -Inf, 0) .* bias_neg\n",
    "    else\n",
    "        New_bias = clamp_mutiply_bias(last_A, bias_pos, bias_neg)\n",
    "        return New_bias\n",
    "    end\n",
    "end\n",
    "\n",
    "#bound oneside of the relu, like upper or lower\n",
    "function bound_oneside(last_A, slope_pos, slope_neg)\n",
    "    if isnothing(last_A)\n",
    "        return nothing, nothing\n",
    "    end\n",
    "    New_A = multiply_by_A_signs(last_A, slope_pos, slope_neg)\n",
    "    return New_A\n",
    "end\n",
    "\n",
    "\n",
    "alpha_lower = [20]\n",
    "alpha_upper = [1]\n",
    "unstable_mask = [1]\n",
    "lower_mask = [1]\n",
    "upper_slope = [2]\n",
    "upper_bias = [0]\n",
    "lower_bias = [0]\n",
    "lower = upper = true\n",
    "if lower == true\n",
    "    Alpha_Lower_Layer = AlphaLayer(\"relu_1\", alpha_lower, true, unstable_mask, lower_mask, upper_slope, upper_bias, lower_bias)\n",
    "end\n",
    "if upper ==true\n",
    "    Alpha_Upper_Layer = AlphaLayer(\"relu_1\", alpha_upper, false, unstable_mask, lower_mask, upper_slope, lower_bias, upper_bias)\n",
    "end\n",
    "a = []\n",
    "push!(a, Alpha_Lower_Layer) \n",
    "push!(a, Alpha_Upper_Layer)\n",
    "println(Flux.params(Alpha_Lower_Layer))\n",
    "println(Flux.params(a)) \n",
    "a = Chain(a)\n",
    "println(a([2, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for activation_node in model_info.activation_nodes\n",
    "    batch_info[activation_node][:split_active] = []\n",
    "end\n",
    "primals, duals, mini_inp = None, None, None\n",
    "upper_bound = zeros(size(lower_bound)) .+ Inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "function test_mlp(prop_method)\n",
    "    small_nnet_file = \"/home/verification/ModelVerification.jl/test/networks/small_nnet.nnet\"\n",
    "    # small_nnet encodes the simple function 24*max(x + 1.5, 0) + 18.5\n",
    "    small_nnet = read_nnet(small_nnet_file, last_layer_activation = ModelVerification.ReLU())\n",
    "    flux_model = Flux.Chain(small_nnet)\n",
    "    #ONNXNaiveNASflux.save(\"/home/verification/ModelVerification.jl/small_nnet.onnx\", flux_model, (1,1))\n",
    "    #println(flux_model)\n",
    "    #println(flux_model.layers[1].weight, \" \", flux_model.layers[1].bias) # max(x+1.5, 0) max(x+1.5, 0)              [0,4]\n",
    "    #println(flux_model.layers[2].weight, \" \", flux_model.layers[2].bias) # 4*max(x+1.5, 0)+2.5 4*max(x+1.5, 0)+2.5  [2.5, 18.5]\n",
    "    #println(flux_model.layers[3].weight, \" \", flux_model.layers[3].bias) # 24*max(x+1.5, 0)+18.5                    [18.5, 114.5]\n",
    "    in_hyper  = Hyperrectangle(low = [-2.5], high = [2.5]) # expected out: [18.5, 114.5]\n",
    "    out_violated    = Hyperrectangle(low = [19], high = [114]) # 20.0 ≤ y ≤ 90.0\n",
    "    out_holds = Hyperrectangle(low = [18], high = [115.0]) # -1.0 ≤ y ≤ 50.0\n",
    "    comp_violated    = Complement(Hyperrectangle(low = [10], high = [19])) # y ≤ 10.0 or 19 ≤ y\n",
    "    comp_holds    = Complement(Hyperrectangle(low = [115], high = [118])) # y ≤ 10.0 or 18 ≤ y\n",
    "    info = nothing\n",
    "    search_method = BFS(max_iter=100, batch_size=1)\n",
    "    split_method = Bisect(1)\n",
    "    @test verify(search_method, split_method, prop_method, Problem(\"/home/verification/ModelVerification.jl/small_nnet.onnx\", in_hyper, out_holds)).status == :holds\n",
    "    @test verify(search_method, split_method, prop_method, Problem(\"/home/verification/ModelVerification.jl/small_nnet.onnx\", in_hyper, out_violated)).status == :violated\n",
    "    @test verify(search_method, split_method, prop_method, Problem(\"/home/verification/ModelVerification.jl/small_nnet.onnx\", in_hyper, comp_holds)).status == :holds\n",
    "    @test verify(search_method, split_method, prop_method, Problem(\"/home/verification/ModelVerification.jl/small_nnet.onnx\", in_hyper, comp_violated)).status == :violated\n",
    "    #= @test verify(search_method, split_method, prop_method, Problem(flux_model, in_hyper, out_holds)).status == :holds\n",
    "    @test verify(search_method, split_method, prop_method, Problem(flux_model, in_hyper, out_violated)).status == :violated\n",
    "    @test verify(search_method, split_method, prop_method, Problem(flux_model, in_hyper, comp_holds)).status == :holds\n",
    "    @test verify(search_method, split_method, prop_method, Problem(flux_model, in_hyper, comp_violated)).status == :violated =#\n",
    "end\n",
    "@timed begin\n",
    "    #for i in 1:1\n",
    "        test_mlp(AlphaCrown(Crown(true, true), true, false, Flux.Optimiser(Flux.ADAM(0.1)), 10))\n",
    "        #test_mlp(Ai2z())\n",
    "        #test_mlp(Crown(true, true))\n",
    "        #test_mlp(StarSet(Crown(true, true)))\n",
    "    #end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 1)\n",
      "[18.5;;;]\n"
     ]
    }
   ],
   "source": [
    "last_A = [1;;;]\n",
    "println(size(last_A))\n",
    "x = [18.5;;]\n",
    "println(size(x))\n",
    "bias = [0;;]\n",
    "println(size(bias))\n",
    "out = NNlib.batched_mul(last_A, x) .+ bias\n",
    "println(size(out))\n",
    "println(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5; 1.5;;]\n",
      "(1, 1, 1)\n",
      "[28.799999999999997;;;]\n"
     ]
    }
   ],
   "source": [
    "last_A = [9.6 9.6;;;]\n",
    "bias = [1.5; 1.5;;]\n",
    "println(bias)\n",
    "New_bias = NNlib.batched_mul(last_A, bias)\n",
    "println(size(New_bias))\n",
    "println(New_bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Chain([\n",
    "    Conv((3, 3), 3 => 8, relu, pad=SamePad(), stride=(2, 2)), #pad=SamePad() ensures size(output,d) == size(x,d) / stride.\n",
    "    BatchNorm(8),\n",
    "    MeanPool((2,2)),\n",
    "    SkipConnection(\n",
    "        Chain([\n",
    "            Conv((5, 5), 8 => 8, relu, pad=SamePad(), stride=(1, 1))\n",
    "            ]),\n",
    "        +\n",
    "    ),\n",
    "    #ConvTranspose((3, 3), 8 => 4, relu, pad=SamePad(), stride=(2, 2)),#pad=SamePad() ensures size(output,d) == size(x,d) * stride.\n",
    "    Flux.flatten,\n",
    "    Dense(512, 100, relu),\n",
    "    Dense(100, 10)\n",
    "])\n",
    "testmode!(model)\n",
    "# image_seeds = CIFAR10(:train)[1:5].features # 32 x 32 x 3 x 5\n",
    "image_seeds = [CIFAR10(:train)[i].features for i in 1:2]\n",
    "input_set = ImageConvexHull(image_seeds)\n",
    "# println(typeof(image_seeds[1][1,1,1,1]))\n",
    "search_method = BFS(max_iter=1, batch_size=1)\n",
    "split_method = Bisect(1)\n",
    "output_set = BallInf(zeros(10), 1.0)\n",
    "onnx_model_path = \"/home/verification/ModelVerification.jl/mlp.onnx\"\n",
    "flux_model = model\n",
    "image_shape = (32, 32, 3, 5)\n",
    "println(image_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_method = ImageStar()\n",
    "@timed verify(search_method, split_method, prop_method, Problem(flux_model, input_set, output_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_method = ImageStarZono()\n",
    "@timed verify(search_method, split_method, prop_method, Problem(onnx_model_path, image_seeds, output_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Chain([\n",
    "    Flux.flatten,\n",
    "    Dense(784, 200, relu),\n",
    "    Dense(200, 10)\n",
    "])\n",
    "image_seeds = [MNIST(:train)[i].features for i in 1:1]\n",
    "search_method = BFS(max_iter=1, batch_size=1)\n",
    "split_method = Bisect(1)\n",
    "output_set = BallInf(zeros(10), 1.0)\n",
    "onnx_model_path = \"/home/verification/ModelVerification.jl/debug.onnx\"\n",
    "Flux_model = model\n",
    "image_shape = (28, 28, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Chain([\n",
    "    Conv((3, 3), 3 => 8, relu, pad=SamePad(), stride=(2, 2)), #pad=SamePad() ensures size(output,d) == size(x,d) / stride.\n",
    "    BatchNorm(8),\n",
    "    MeanPool((2,2)),\n",
    "    SkipConnection(\n",
    "        Chain([\n",
    "            Conv((5, 5), 8 => 8, relu, pad=SamePad(), stride=(1, 1))\n",
    "            ]),\n",
    "        +\n",
    "    ),\n",
    "    Conv((3, 3), 8 => 8, relu, pad=SamePad(), stride=(2, 2)),\n",
    "    #ConvTranspose((3, 3), 8 => 4, relu, pad=SamePad(), stride=(2, 2)),#pad=SamePad() ensures size(output,d) == size(x,d) * stride.\n",
    "    Flux.flatten,\n",
    "    Dense(128, 100, relu),\n",
    "    Dense(100, 10)\n",
    "])\n",
    "testmode!(model)\n",
    "# image_seeds = CIFAR10(:train)[1:5].features # 32 x 32 x 3 x 5\n",
    "image_seeds = [CIFAR10(:train)[i].features for i in 1:2]\n",
    "# println(typeof(image_seeds[1][1,1,1,1]))\n",
    "search_method = BFS(max_iter=1, batch_size=1)\n",
    "split_method = Bisect(1)\n",
    "output_set = BallInf(zeros(10), 1.0)\n",
    "onnx_model_path = \"/home/verification/ModelVerification.jl/mlp.onnx\"\n",
    "Flux_model = model\n",
    "image_shape = (32, 32, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_method = ImageStar()\n",
    "@timed verify(search_method, split_method, prop_method, Problem(onnx_model_path, Flux_model, image_shape, image_seeds, output_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_method = ImageStarZono()\n",
    "@timed verify(search_method, split_method, prop_method, Problem(onnx_model_path, Flux_model, image_shape, image_seeds, output_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Chain([\n",
    "    Conv((3, 3), 3 => 128, relu, pad=SamePad(), stride=(2, 2)), #pad=SamePad() ensures size(output,d) == size(x,d) / stride.\n",
    "    BatchNorm(128),\n",
    "    MeanPool((2,2)),\n",
    "    SkipConnection(\n",
    "        Chain([\n",
    "            Conv((5, 5), 128 => 128, relu, pad=SamePad(), stride=(1, 1))\n",
    "            ]),\n",
    "        +\n",
    "    ),\n",
    "    ConvTranspose((3, 3), 128 => 128, relu, pad=SamePad(), stride=(2, 2)),#pad=SamePad() ensures size(output,d) == size(x,d) * stride.\n",
    "    Flux.flatten,\n",
    "    Dense(32768, 100, relu),\n",
    "    Dense(100, 10)\n",
    "])\n",
    "testmode!(model)\n",
    "# image_seeds = CIFAR10(:train)[1:5].features # 32 x 32 x 3 x 5\n",
    "image_seeds = [CIFAR10(:train)[i].features for i in 1:2]\n",
    "# println(typeof(image_seeds[1][1,1,1,1]))\n",
    "search_method = BFS(max_iter=1, batch_size=1)\n",
    "split_method = Bisect(1)\n",
    "output_set = BallInf(zeros(10), 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_method = ImageStarZono()\n",
    "@timed verify(search_method, split_method, prop_method, Problem(model, image_seeds, output_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Profile.clear()\n",
    "@profile verify(search_method, split_method, prop_method, Problem(model, image_seeds, output_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open(\"./prof.txt\", \"w\") do s\n",
    "    Profile.print(IOContext(s, :displaysize => (24, 500)))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
