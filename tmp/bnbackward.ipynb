{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Revise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PaddedViews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ModelVerification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bound_backward (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "include(\"/home/verification/ModelVerification.jl/src/propagate/operators/normalise.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8028800801277876 1.7728881334766937 4.049660434098465 1.1046790590760636; -1.9526299235427618 0.03672485612543106 -0.9479850736138964 2.70318299566221; -1.3770138255462074 -0.4261121865350151 0.7507181112931276 -1.1785275293304183; -2.344875759640336 0.19852449602452993 1.7456640797825003 2.4072354874167017;;; 0.577458948769741 -1.1250927168686509 -0.6589886905653882 0.09659873634797574; 2.022627713076763 -0.49920366057950977 0.24671757473068953 -1.360424978603499; -0.9250241685749053 0.13907141369512796 0.806859860201764 -3.318520384781599; 0.6795146977954626 -0.2593747513585449 -0.6209603409663081 0.684462223024118;;;;]\n",
      "[0.0]\n"
     ]
    }
   ],
   "source": [
    "bn_layer = BatchNorm(2)\n",
    "last_A = [0.80288410  1.77289701  4.04968071  1.10468459; \n",
    "-1.95263970  0.03672504 -0.94798982  2.70319653; \n",
    "-1.37702072 -0.42611432  0.75072187 -1.17853343; \n",
    "-2.34488750  0.19852549  1.74567282  2.40724754;;; \n",
    "0.57746184 -1.12509835 -0.65899199  0.09659922; \n",
    "2.02263784 -0.49920616  0.24671881 -1.36043179; \n",
    "-0.92502880  0.13907211  0.80686390 -3.31853700; \n",
    "0.67951810 -0.25937605 -0.62096345  0.68446565;;;;]\n",
    "batch_info = nothing\n",
    "batch_reach, batch_bias, batch_info = bound_backward(bn_layer, last_A, batch_info)\n",
    "println(batch_reach)\n",
    "println(batch_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector{Float32}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1-element Vector{Float64}:\n",
       " 0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#= model = Chain(\n",
    "    Conv((4, 4), 3=>16, stride=2, pad=(1, 1), identity),\n",
    "    Conv((3, 3), 16=>32, stride=2, pad=(1, 1), identity),\n",
    "    Conv((5, 5), 32=>64, stride=2, pad=(1, 1), identity),\n",
    ") =#\n",
    "bn_layer = BatchNorm(2)\n",
    "β, γ, μ, σ², ϵ, momentum, affine, track_stats = bn_layer.β, bn_layer.γ, bn_layer.μ, bn_layer.σ², bn_layer.ϵ, bn_layer.momentum, bn_layer.affine, bn_layer.track_stats\n",
    "channels = 2\n",
    "β = affine ? β : 1.0\n",
    "γ = affine ? γ : 0.0\n",
    "μ = track_stats ? μ : zeros(channels)\n",
    "σ² = track_stats ? σ² : ones(channels)\n",
    "last_A = [0.80288410  1.77289701  4.04968071  1.10468459; \n",
    "-1.95263970  0.03672504 -0.94798982  2.70319653; \n",
    "-1.37702072 -0.42611432  0.75072187 -1.17853343; \n",
    "-2.34488750  0.19852549  1.74567282  2.40724754;;; \n",
    "0.57746184 -1.12509835 -0.65899199  0.09659922; \n",
    "2.02263784 -0.49920616  0.24671881 -1.36043179; \n",
    "-0.92502880  0.13907211  0.80686390 -3.31853700; \n",
    "0.67951810 -0.25937605 -0.62096345  0.68446565;;;;]\n",
    "tmp_β = β .- μ ./ sqrt.(σ² .+ ϵ) .* γ\n",
    "tmp_γ = γ ./ sqrt.(σ² .+ ϵ)\n",
    "println(typeof(tmp_γ))\n",
    "tmp_γ = reshape(tmp_γ, (channels, 1))\n",
    "for i in 1:(ndims(last_A)-2)\n",
    "    tmp_γ = reshape(tmp_γ, (1, size(tmp_γ)...))\n",
    "end\n",
    "next_A = last_A .* tmp_γ\n",
    "channel_dim = ndims(last_A) - 1\n",
    "if (ndims(last_A) > 2)\n",
    "    tmp_last_A = dropdims(sum(last_A, dims = Tuple(1:channel_dim-1)), dims = Tuple(1:channel_dim-1))\n",
    "    sum_bias = dropdims(sum((tmp_last_A .* tmp_β), dims = 1), dims = 1)\n",
    "else\n",
    "    sum_bias = dropdims(sum((last_A .* tmp_β), dims = channel_dim), dims = channel_dim)\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "                    #batch_reach, batch_reach_β, info = backward_linear(bn_layer, input_size, batch_output, nothing)\n",
    "#print(batch_reach_β)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
