{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Revise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ModelVerification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LazySets\n",
    "using PyCall\n",
    "using CSV\n",
    "using ONNX\n",
    "using Flux\n",
    "using Test\n",
    "using NNlib\n",
    "using ONNXNaiveNASflux\n",
    "using NaiveNASflux\n",
    "using DataStructures\n",
    "# using DataFrames\n",
    "# import Flux: flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Flux: onehotbatch, onecold, flatten\n",
    "# using Flux.Losses: logitcrossentropy\n",
    "# using Statistics: mean\n",
    "using CUDA\n",
    "using MLDatasets: CIFAR10, MNIST\n",
    "using MLUtils: splitobs, DataLoader\n",
    "using Accessors\n",
    "using Profile\n",
    "using LinearAlgebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#= abstract type Perturbation end\n",
    "\n",
    "mutable struct LP{T<:Real} <: Perturbation\n",
    "    norm::Float64\n",
    "    eps::Float64\n",
    "end\n",
    " =#\n",
    "mutable struct CrownBound3{T<:Real}\n",
    "    batch_Low::AbstractArray   \n",
    "    batch_Up::AbstractArray          \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "init_perturbation (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#= function init_perturbation(node, batch_input, perturbation_info::LP, batch_info, global_info)#batch_input include data, data_min, data_max\n",
    "        if(perturbation_info.norm == Inf)\n",
    "            batch_Low = batch_input .- perturbation_info[\"eps\"]\n",
    "            batch_Up = batch_input .+ perturbation_info[\"eps\"] \n",
    "        else\n",
    "            batch_Low = batch_input\n",
    "            batch_Up = batch_input\n",
    "        end\n",
    "        new_bound = CrownBound2(batch_Low, batch_Up) #batch_info[node][\"data_min\"], batch_info[node][\"data_max\"])\n",
    "end =#\n",
    "\n",
    "function init_perturbation(node, batch_input, perturbation_info, batch_info, global_info)#batch_input include data, data_min, data_max\n",
    "    if(perturbation_info[\"norm\"] == Inf)\n",
    "        batch_Low = batch_input .- perturbation_info[\"eps\"]\n",
    "        batch_Up = batch_input .+ perturbation_info[\"eps\"] \n",
    "    else\n",
    "        batch_Low = batch_input\n",
    "        batch_Up = batch_input\n",
    "    end\n",
    "    println(size(batch_Low))\n",
    "    println(size(batch_Up))\n",
    "    new_bound = CrownBound3(batch_Low, batch_Up) #batch_info[node][\"data_min\"], batch_info[node][\"data_max\"])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set(Any[\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flatten\", \"Relu\", \"Gemm\"])\n"
     ]
    }
   ],
   "source": [
    "onnx_model_path = \"/home/verification/ModelVerification.jl/debug.onnx\"\n",
    "\n",
    "comp_graph = ONNXNaiveNASflux.load(onnx_model_path, infer_shapes=false)\n",
    "batch_info = Dict()\n",
    "global_info = Dict()\n",
    "push!(global_info, \"activation_number\" => 0)\n",
    "push!(global_info, \"activation_nodes\" => [])\n",
    "push!(global_info, \"final_nodes\" => [])\n",
    "push!(global_info, \"all_nodes\" => [])\n",
    "for (index, vertex) in enumerate(ONNXNaiveNASflux.vertices(comp_graph))\n",
    "    if index == 1 # the vertex which index == 1 has no useful information, so it's output node will be the start node of the model\n",
    "        push!(global_info, \"start_nodes\" => [NaiveNASflux.name(output_node) for output_node in outputs(vertex)]) \n",
    "        continue\n",
    "    end \n",
    "        \n",
    "    node_name = NaiveNASflux.name(vertex)\n",
    "    new_dict = Dict() # store the information of this vertex \n",
    "    push!(new_dict, \"vertex\" => vertex)\n",
    "    push!(new_dict, \"layer\" => NaiveNASflux.layer(vertex))\n",
    "    push!(new_dict, \"index\" => index)\n",
    "    push!(new_dict, \"outputs\" => [NaiveNASflux.name(output_node) for output_node in outputs(vertex)])\n",
    "    # add input nodes of current node. If the input nodes of current node have activation(except identity), then the \"inputs\" should be the activation node\n",
    "    if !(node_name in global_info[\"start_nodes\"])# if current node is not one of the start node\n",
    "        push!(new_dict, \"inputs\" => [])\n",
    "        for input_node in inputs(vertex)\n",
    "            input_node_name = NaiveNASflux.name(input_node)\n",
    "            if hasfield(typeof(batch_info[input_node_name][\"layer\"]), :σ) && string(batch_info[input_node_name][\"layer\"].σ) != \"identity\"\n",
    "                push!(new_dict[\"inputs\"], batch_info[input_node_name][\"outputs\"][1])\n",
    "            else\n",
    "                push!(new_dict[\"inputs\"], input_node_name)\n",
    "            end\n",
    "        end\n",
    "    else\n",
    "        push!(new_dict, \"inputs\" => nothing)\n",
    "    end\n",
    "    \n",
    "    if length(string(NaiveNASflux.name(vertex))) >= 7 && string(NaiveNASflux.name(vertex))[1:7] == \"Flatten\" \n",
    "        push!(new_dict, \"layer\" => Flux.flatten)\n",
    "        push!(batch_info, node_name => new_dict) #new_dict belongs to batch_info\n",
    "        push!(global_info[\"all_nodes\"], node_name) \n",
    "    elseif length(string(NaiveNASflux.name(vertex))) >= 3 && string(NaiveNASflux.name(vertex))[1:3] == \"add\" \n",
    "        push!(new_dict, \"layer\" => +)\n",
    "        push!(batch_info, node_name => new_dict) #new_dict belongs to batch_info\n",
    "        push!(global_info[\"all_nodes\"], node_name) \n",
    "    elseif length(string(NaiveNASflux.name(vertex))) >= 4 && string(NaiveNASflux.name(vertex))[1:4] == \"relu\" \n",
    "        global_info[\"activation_number\"] += 1\n",
    "        node_name = \"relu\" * \"_\" * string(global_info[\"activation_number\"]) #activate == \"relu_5\" doesn't mean this node is 5th relu node, but means this node is 5th activation node\n",
    "        push!(new_dict, \"layer\" => NNlib.relu)\n",
    "        push!(batch_info, node_name => new_dict) #new_dict belongs to batch_info\n",
    "        push!(global_info[\"activation_nodes\"], node_name)\n",
    "        push!(global_info[\"all_nodes\"], node_name) \n",
    "    elseif hasfield(typeof(NaiveNASflux.layer(vertex)), :σ) && string(NaiveNASflux.layer(vertex).σ) != \"identity\"#split this layer into a linear layer and a activative layer\n",
    "        global_info[\"activation_number\"] += 1\n",
    "        activation_name = string(NaiveNASflux.layer(vertex).σ) * \"_\" * string(global_info[\"activation_number\"])\n",
    "        push!(new_dict, \"outputs\" => [activation_name]) #new_dict store the information of the linear layer\n",
    "        push!(batch_info, node_name => new_dict) #new_dict belongs to batch_info\n",
    "        push!(global_info[\"all_nodes\"], node_name) \n",
    "            \n",
    "        activation_new_dict = Dict()#store the information of the activative layer\n",
    "        push!(activation_new_dict, \"vertex\" => vertex)\n",
    "        push!(activation_new_dict, \"layer\" => NaiveNASflux.layer(vertex).σ)\n",
    "        push!(activation_new_dict, \"index\" => index)# Do not need to change index\n",
    "        push!(activation_new_dict, \"inputs\" => [node_name])\n",
    "        push!(activation_new_dict, \"outputs\" => [NaiveNASflux.name(output_nodes) for output_nodes in outputs(vertex)])\n",
    "        push!(batch_info, activation_name => activation_new_dict)\n",
    "        push!(global_info[\"activation_nodes\"], activation_name)\n",
    "        push!(global_info[\"all_nodes\"], activation_name) \n",
    "\n",
    "        node_name = activation_name #for getting the final_nodes\n",
    "    else\n",
    "        push!(batch_info, node_name => new_dict) #new_dict belongs to batch_info\n",
    "        push!(global_info[\"all_nodes\"], node_name) \n",
    "    end\n",
    "    \n",
    "    if length(batch_info[node_name][\"outputs\"]) == 0  #the final_node node has no output nodes\n",
    "        push!(global_info[\"final_nodes\"], node_name) \n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in global_info[\"all_nodes\"]\n",
    "    # Check whether all prior intermediate bounds already exist\n",
    "    push!(batch_info[node], \"prior_checked\" => false)\n",
    "    # check whether weights are perturbed and set nonlinear for some operations\n",
    "    if isa(batch_info[node][\"layer\"], Flux.Dense) || isa(batch_info[node][\"layer\"], Flux.Conv) || isa(batch_info[node][\"layer\"], Flux.BatchNorm)#if the params of Linear, Conv, Batchnorm need to be perturbed, the Linear, Conv, Batchnorm will be non_linear\n",
    "        push!(batch_info[node], \"nonlinear\" => false)\n",
    "        if haskey(batch_info[node], \"weight_ptb\") || haskey(batch_info[node], \"bias_ptb\" )\n",
    "            push!(batch_info[node], \"nonlinear\" => true)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dict{Any, Any} with 17 entries:\n",
       "  \"vertex\"        => MutationVertex(CompVertex(LazyMutable(MutableLayer(Dense(7…\n",
       "  \"ptb\"           => true\n",
       "  \"outputs\"       => [\"relu_1\"]\n",
       "  \"layer\"         => Dense(784 => 200, relu)\n",
       "  \"prior_checked\" => false\n",
       "  \"bounded\"       => true\n",
       "  \"nonlinear\"     => false\n",
       "  \"weight_ptb\"    => false\n",
       "  \"alpha\"         => 1.0\n",
       "  \"used\"          => true\n",
       "  \"center\"        => [0.013 0.013 … 0.013 0.013; 0.013 0.013 … 0.013 0.013; … ;…\n",
       "  \"index\"         => 3\n",
       "  \"beta\"          => 1.0\n",
       "  \"lA\"            => [1, 2, 3, 4, 5, 6, 8, 9, 11, 12  …  188, 190, 192, 193, 19…\n",
       "  \"uA\"            => [1, 2, 3, 4, 5, 6, 8, 9, 11, 12  …  188, 190, 192, 193, 19…\n",
       "  \"bias_ptb\"      => false\n",
       "  \"inputs\"        => Any[\"Flatten_0\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input = ones(28, 28, 1, 1) .* 0013\n",
    "push!(global_info, \"model_inputs\" => input)\n",
    "push!(batch_info[\"Flatten_0\"], \"perturbation_info\" => Dict(\"norm\" => Inf, \"eps\" => 0013))\n",
    "push!(batch_info[\"relu_1\"], \"requires_input_bounds\" => [1])\n",
    "#push!(batch_info[\"Flatten_0\"], \"weight_ptb\" => true)\n",
    "for node in global_info[\"all_nodes\"]\n",
    "    # Check whether all prior intermediate bounds already exist\n",
    "    push!(batch_info[node], \"prior_checked\" => false)\n",
    "    push!(batch_info[node], \"used\" => true)\n",
    "    push!(batch_info[node], \"ptb\" => true)\n",
    "    push!(batch_info[node], \"alpha\" => 1.0)\n",
    "    push!(batch_info[node], \"beta\" => 1.0)\n",
    "    push!(batch_info[node], \"weight_ptb\" => false)\n",
    "    push!(batch_info[node], \"bias_ptb\" => false)\n",
    "end\n",
    "println(isa(batch_info[\"dense_0\"][\"layer\"], Flux.Dense))\n",
    "lower = input .- 0013\n",
    "upper = input .+ 0013\n",
    "push!(batch_info[\"Flatten_0\"], \"interval\" => [lower, upper])\n",
    "push!(batch_info[\"Flatten_0\"], \"lower\" => lower)\n",
    "push!(batch_info[\"Flatten_0\"], \"upper\" => upper)\n",
    "push!(batch_info[\"Flatten_0\"], \"center\" => input)\n",
    "push!(batch_info[\"dense_0\"], \"center\" => input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair{Any, Any}\n",
      "Pair{Any, Any}\n",
      "Pair{Any, Any}\n",
      "Pair{Any, Any}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any[\"Flatten_0\", \"dense_0\", \"relu_1\", \"dense_1\"]\n"
     ]
    }
   ],
   "source": [
    "for i in batch_info\n",
    "    println(typeof(i))\n",
    "end\n",
    "println(global_info[\"all_nodes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "check_prior_bounds (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function check_prior_bounds(node, batch_info, global_info)\n",
    "    if batch_info[node][\"prior_checked\"] || !(batch_info[node][\"used\"] && batch_info[node][\"ptb\"])\n",
    "        return\n",
    "    end\n",
    "    \n",
    "    if !isnothing(batch_info[node][\"inputs\"])\n",
    "        for input_node in batch_info[node][\"inputs\"]\n",
    "            check_prior_bounds(input_node, batch_info, global_info)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if haskey(batch_info[node], \"nonlinear\") && batch_info[node][\"nonlinear\"]\n",
    "        for input_node in batch_info[node][\"inputs\"]\n",
    "            #compute_intermediate_bounds(input_node, batch_info, global_info, prior_checked = true)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if haskey(batch_info[node], \"requires_input_bounds\")\n",
    "        for i in batch_info[node][\"requires_input_bounds\"]\n",
    "            #compute_intermediate_bounds(batch_info[node][\"inputs\"][i], batch_info, global_info, prior_checked = true)\n",
    "        end\n",
    "    end\n",
    "    push!(batch_info[node], \"prior_checked\" => true)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any, Any} with 13 entries:\n",
       "  \"vertex\"        => MutationVertex(CompVertex(LazyMutable(MutableLayer(Dense(2…\n",
       "  \"ptb\"           => true\n",
       "  \"outputs\"       => Any[]\n",
       "  \"layer\"         => Dense(200 => 10)\n",
       "  \"prior_checked\" => true\n",
       "  \"nonlinear\"     => false\n",
       "  \"weight_ptb\"    => false\n",
       "  \"alpha\"         => 1.0\n",
       "  \"used\"          => true\n",
       "  \"index\"         => 4\n",
       "  \"beta\"          => 1.0\n",
       "  \"bias_ptb\"      => false\n",
       "  \"inputs\"        => Any[\"relu_1\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_node = global_info[\"final_nodes\"][1]\n",
    "check_prior_bounds(final_node, batch_info, global_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0 1.0 1.0 1.0 1.0]\n"
     ]
    }
   ],
   "source": [
    "a = ones(1, 155, 784) \n",
    "b = ones(1, 784, 1)\n",
    "d = ones(1, 5) .* (-1)\n",
    "#c = a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "(1, 10, 1)\n",
      "[0.8996035499999999 -0.42670631 0.45987493 -1.42302948 -1.31039339 -0.31737727 1.7427944599999998 0.92044079 1.6577974;;;]\n"
     ]
    },
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching iterate(::Nothing)\nClosest candidates are:\n  iterate(!Matched::Union{LinRange, StepRangeLen}) at range.jl:872\n  iterate(!Matched::Union{LinRange, StepRangeLen}, !Matched::Integer) at range.jl:872\n  iterate(!Matched::T) where T<:Union{Base.KeySet{<:Any, <:Dict}, Base.ValueIterator{<:Dict}} at dict.jl:712\n  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching iterate(::Nothing)\n",
      "Closest candidates are:\n",
      "  iterate(!Matched::Union{LinRange, StepRangeLen}) at range.jl:872\n",
      "  iterate(!Matched::Union{LinRange, StepRangeLen}, !Matched::Integer) at range.jl:872\n",
      "  iterate(!Matched::T) where T<:Union{Base.KeySet{<:Any, <:Dict}, Base.ValueIterator{<:Dict}} at dict.jl:712\n",
      "  ...\n",
      "\n",
      "Stacktrace:\n",
      " [1] indexed_iterate(I::Nothing, i::Int64)\n",
      "   @ Base ./tuple.jl:91\n",
      " [2] bound_backward(layer::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, node::String, batch_info::Dict{Any, Any}, global_info::Dict{Any, Any})\n",
      "   @ Main ~/ModelVerification.jl/tmp/debug.ipynb:111\n",
      " [3] backward_general(C::Array{Int64, 3}, node::String, unstable_idx::Vector{Int64}, unstable_size::Int64, batch_info::Dict{Any, Any}, global_info::Dict{Any, Any})\n",
      "   @ Main ~/ModelVerification.jl/tmp/debug.ipynb:223\n",
      " [4] top-level scope\n",
      "   @ ~/ModelVerification.jl/tmp/debug.ipynb:257"
     ]
    }
   ],
   "source": [
    "push!(global_info, \"bound_lower\" => true)\n",
    "push!(global_info, \"bound_upper\" => true)\n",
    "function get_degrees(node, batch_info, global_info)\n",
    "    degrees = Dict()\n",
    "    push!(batch_info[node], \"bounded\" => false)\n",
    "    queue = Queue{Any}()\n",
    "    enqueue!(queue, node)\n",
    "    while !isempty(queue)\n",
    "        node = dequeue!(queue)\n",
    "        if !isnothing(batch_info[node][\"inputs\"])\n",
    "            for input_node in batch_info[node][\"inputs\"]\n",
    "                if haskey(degrees, input_node)\n",
    "                    push!(degrees, input_node => degrees[input_node] + 1)\n",
    "                else\n",
    "                    push!(degrees, input_node => 1)\n",
    "                end\n",
    "                if batch_info[input_node][\"bounded\"]\n",
    "                    push!(batch_info[input_node], \"bounded\" => false)\n",
    "                    enqueue!(queue, input_node)\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return degrees\n",
    "end\n",
    "\n",
    "function is_activation(l)\n",
    "    for f in NNlib.ACTIVATIONS\n",
    "        isa(l, typeof(@eval NNlib.$(f))) && return true\n",
    "    end\n",
    "    return false\n",
    "end\n",
    "\n",
    "function _preprocess(node, batch_info, global_info, a, b, c = nothing)#a:input node's lower/upper b:weight's lower/upper c:bias's lower/upper\n",
    "    if batch_info[node][\"alpha\"] != 1.0 \n",
    "        a = batch_info[node][\"alpha\"] .* a\n",
    "    end\n",
    "    if !isnothing(c)\n",
    "        if batch_info[node][\"beta\"] != 1.0 \n",
    "            c = batch_info[node][\"beta\"] .* c\n",
    "        end\n",
    "    end\n",
    "    return a, b, c\n",
    "end\n",
    "\n",
    "function bound_oneside(last_A, weight, bias)\n",
    "    if isnothing(last_A)\n",
    "        return nothing, 0\n",
    "    end\n",
    "\n",
    "    weight = reshape(weight, (size(weight)..., 1)) \n",
    "    weight = repeat(weight, 1, 1, size(last_A)[end]) #add batch dim in weight\n",
    "    weight = permutedims(weight, (2, 1, 3)) #permute the 1st and 2sd dims for batched_mul\n",
    "    new_A = NNlib.batched_mul(weight, last_A) #note: must be weight * last_A, not last_A * weight\n",
    "    \n",
    "    if !isnothing(bias)\n",
    "        bias = reshape(bias, (size(bias)..., 1, 1)) #add input dim in weight\n",
    "        bias = repeat(bias, 1, 1, size(last_A)[end]) #add batch dim in weight\n",
    "        bias = permutedims(bias, (2, 1, 3))\n",
    "        sum_bias = NNlib.batched_mul(bias, last_A)\n",
    "    else\n",
    "        sum_bias = 0.0\n",
    "    end\n",
    "\n",
    "    return next_A, sum_bias\n",
    "end\n",
    "\n",
    "function bound_backward(layer::Dense, node, batch_info, global_info)\n",
    "    last_lA = batch_info[node][\"lA\"] #last_lA means lA that has already stored in batch_info[node]\n",
    "    last_uA = batch_info[node][\"uA\"] #last_lA means lA that has already stored in batch_info[node]\n",
    "    input_node = batch_info[node][\"inputs\"][1] #Dense layer could only have 1 input Node\n",
    "    if haskey(batch_info[input_node], \"lower\") \n",
    "        input_node_lb = batch_info[input_node][\"lower\"]\n",
    "    else\n",
    "        input_node_lb = nothing\n",
    "    end\n",
    "\n",
    "    if haskey(batch_info[input_node], \"upper\") \n",
    "        input_node_ub = batch_info[input_node][\"upper\"]\n",
    "    else\n",
    "        input_node_ub = nothing\n",
    "    end\n",
    "\n",
    "    #TO DO: we haven't consider the perturbation in weight and bias\n",
    "    input_node_lb, weight_lb, bias_lb = _preprocess(node, batch_info, global_info, input_node_lb, layer.weight, layer.bias)\n",
    "    input_node_ub, weight_ub, bias_ub = _preprocess(node, batch_info, global_info, input_node_ub, layer.weight, layer.bias)\n",
    "    lA_y = uA_y = lA_bias = uA_bias = nothing\n",
    "    lbias = ubias = 0\n",
    "    batch_size = !isnothing(last_lA) ? size(last_lA)[end] : size(last_lA)[end]\n",
    "\n",
    "    if !batch_info[node][\"weight_ptb\"] && (!batch_info[node][\"bias_ptb\"] || isnothing(layer.bias))\n",
    "        weight = weight_lb\n",
    "        bias = bias_lb\n",
    "        \n",
    "        #= index = last_lA\n",
    "        coeffs = nothing\n",
    "        \n",
    "        if !isnothing(weight)\n",
    "            new_weight = weight[index, :] #get the parameters that correspond to unstable neuron\n",
    "            lA_x = reshape(new_weight, (size(new_weight)..., 1))\n",
    "        end\n",
    "        if !isnothing(bias)\n",
    "            new_bias = bias[index, :] #get the parameters that correspond to unstable neuron\n",
    "            lbias = reshape(new_bias, (size(new_bias)..., 1))\n",
    "        end\n",
    "        uA_x, ubias = lA_x, lbias =#\n",
    "        \n",
    "        lA_x, lbias = bound_oneside(last_lA, weight, bias)\n",
    "        uA_x, ubias = bound_oneside(last_uA, weight, bias)\n",
    "\n",
    "        return [(lA_x, uA_x), (lA_y, uA_y), (lA_bias, uA_bias)], lbias, ubias\n",
    "    end\n",
    "\n",
    "    return input_node_lb, weight_lb, bias_lb\n",
    "end\n",
    "\n",
    "\n",
    "function add_bound(node, input_node, lA, uA, batch_info, global_info)\n",
    "    if !isnothing(lA)\n",
    "        if isnothing(batch_info[input_node][\"lA\"])\n",
    "            # First A added to this node.\n",
    "            push!(batch_info[input_node], \"lA\" => lA)\n",
    "        else\n",
    "            #node_pre.zero_lA_mtx = node_pre.zero_lA_mtx and node.zero_backward_coeffs_l\n",
    "            new_node_lA = batch_info[input_node][\"lA\"] .+ lA\n",
    "            push!(batch_info[input_node], \"lA\" => new_node_lA)\n",
    "        end\n",
    "    end\n",
    "    if !isnothing(uA)\n",
    "        if isnothing(batch_info[input_node][\"uA\"])\n",
    "            # First A added to this node.\n",
    "            push!(batch_info[input_node], \"uA\" => uA)\n",
    "        else\n",
    "            #node_pre.zero_lA_mtx = node_pre.zero_lA_mtx and node.zero_backward_coeffs_l\n",
    "            new_node_uA = batch_info[input_node][\"uA\"] .+ uA\n",
    "            push!(batch_info[input_node], \"uA\" => new_node_uA)\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "function concretize_matrix(x, A, perturbation_info, sign, batch_info, global_info)\n",
    "    x_L = x - perturbation_info[\"eps\"]\n",
    "    x_U = x + perturbation_info[\"eps\"]\n",
    "    center = (x_L .+ x_U) ./ 2.0\n",
    "    diff = (x_U .- x_L) ./ 2.0\n",
    "    bound = NNlib.batched_mul(A, center) .+ sign .* NNlib.batched_mul(abs.(A), diff)\n",
    "    return bound\n",
    "end\n",
    "\n",
    "function ptb_concretize(x, A, sign, batch_info, global_info)\n",
    "    if isnothing(A)\n",
    "        return nothing\n",
    "    end\n",
    "    return concretize_matrix(x, A, sign, batch_info, global_info)\n",
    "end\n",
    "\n",
    "function concretize(lb, ub, batch_info, global_info)\n",
    "    node = global_info[\"start_nodes\"][1]\n",
    "    if haskey(batch_info[node], \"perturbation_info\") #the node need to be perturbated\n",
    "        if global_info[\"bound_lower\"]\n",
    "            lb = lb .+ ptb_concretize(global_info[\"model_inputs\"], batch_info[node][\"lA\"], -1, batch_info, global_info)\n",
    "        else\n",
    "            lb = nothing\n",
    "        end\n",
    "        if global_info[\"bound_upper\"]\n",
    "            ub = ub .+ ptb_concretize(model_inputs, batch_info[node][\"uA\"], +1)\n",
    "        else\n",
    "            ub = nothing\n",
    "        end    \n",
    "    else #the node doesn't need to be perturbated\n",
    "    end\n",
    "end\n",
    "\n",
    "#TO Do\n",
    "function preprocess_C(C, node, batch_info, global_info)\n",
    "    batch_size = size(C)[end]\n",
    "    output_dim = size(C)[2]\n",
    "    output_shape = [-1]\n",
    "    return C, batch_size, output_dim, output_shape\n",
    "end\n",
    "\n",
    "function backward_general(C, node, unstable_idx, unstable_size, batch_info, global_info)\n",
    "    for node in global_info[\"all_nodes\"]\n",
    "        push!(batch_info[node], \"lA\" => nothing)\n",
    "        push!(batch_info[node], \"uA\" => nothing)\n",
    "        push!(batch_info[node], \"bounded\" => true)\n",
    "    end\n",
    "    \n",
    "    push!(batch_info[node], \"lA\" => global_info[\"bound_lower\"] ? C : nothing)\n",
    "    push!(batch_info[node], \"uA\" => global_info[\"bound_upper\"] ? C : nothing)\n",
    "    lb = ub = 0\n",
    "    degree_out = get_degrees(node, batch_info, global_info)\n",
    "    C, batch_size, output_dim, output_shape = preprocess_C(C, node, batch_info, global_info)#size(C)=(10, 9, 1) \n",
    "    #batch_size = 1, output_dim = 9, output_shape = [-1] \n",
    "    queue = Queue{Any}()\n",
    "    enqueue!(queue, node)\n",
    "\n",
    "    while !isempty(queue)\n",
    "        n = dequeue!(queue)\n",
    "        push!(batch_info[n], \"bounded\" => true)\n",
    "\n",
    "        for input_node in batch_info[n][\"inputs\"]\n",
    "            degree_out[input_node] -= 1\n",
    "            if degree_out[input_node] == 0\n",
    "                enqueue!(queue, input_node)\n",
    "            end\n",
    "        end\n",
    "\n",
    "        if !batch_info[n][\"ptb\"]\n",
    "            if !haskey(batch_info[n], \"forward_value\")\n",
    "                get_forward_value(n)\n",
    "            end\n",
    "            lb, ub = add_constant_node(lb, ub, n, batch_info, global_info)\n",
    "            continue\n",
    "        end\n",
    "        \n",
    "        if isa(typeof(batch_info[n][\"layer\"]), typeof(relu))\n",
    "            A, lower_b, upper_b = bound_backward(batch_info[n][\"layer\"], n, node, unstable_idx)\n",
    "        elseif is_activation(batch_info[n][\"layer\"])   \n",
    "        else\n",
    "            A, lower_b, upper_b = bound_backward(batch_info[n][\"layer\"], node, batch_info, global_info) \n",
    "        end\n",
    "\n",
    "        lb = lb .+ lower_b\n",
    "        ub = ub .+ upper_b\n",
    "\n",
    "        for (i, input_node) in enumerate(batch_info[node][\"inputs\"])\n",
    "            add_bound(node, input_node, A[i][1], A[i][2], batch_info, global_info)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    lb, ub = concretize(lb, ub, batch_info, global_info)\n",
    "\n",
    "end\n",
    "\n",
    "unstable_idx = [0,    1,   2,   3,   4,   5,   7,   8,  10,  11,  12,  13,  15,  16, 19,  20,  21,  22,  23,  24,  25,  26,  28,  29,  30,  31,  32,  35,\n",
    "37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  51, 52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  64,  65,  68,\n",
    "70,  71,  73,  74,  75,  77,  78,  80,  82,  84,  86,  87,  89,  90, 91,  92,  93,  94,  95,  96,  98,  99, 100, 102, 103, 104, 105, 106,\n",
    "107, 108, 109, 110, 112, 113, 114, 115, 116, 120, 121, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 136, 137, 138, 140, 141, 142, 143,\n",
    "145, 146, 148, 149, 151, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 168, 169, 171, 172, 173, 174, 176, 177, 178, 179, 180,\n",
    "181, 182, 184, 185, 186, 187, 189, 191, 192, 194, 195, 196, 197, 198, 199]\n",
    "unstable_idx = unstable_idx .+ 1\n",
    "unstable_size = 155\n",
    "C = [-1 0 0 0 0 0 0 0 0; \n",
    "0 -1 0 0 0 0 0 0 0; \n",
    "0 0 -1 0 0 0 0 0 0; \n",
    "0 0 0 -1 0 0 0 0 0; \n",
    "0 0 0 0 -1 0 0 0 0; \n",
    "0 0 0 0 0 -1 0 0 0; \n",
    "1 1 1 1 1 1 1 1 1; \n",
    "0 0 0 0 0 0 -1 0 0; \n",
    "0 0 0 0 0 0 0 -1 0; \n",
    "0 0 0 0 0 0 0 0 -1;;;] # size(C) = (10, 9, 1) = (class_number, spec_number, batch_size)\n",
    "\n",
    "backward_general(C, \"dense_1\", unstable_idx, unstable_size, batch_info, global_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_intermediate_bounds (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function compute_intermediate_bounds(node, batch_info, global_info, prior_checked = false)\n",
    "    if haskey(batch_info[node], \"lower\")# && !isnothing(batch_info[node][\"lower\"])\n",
    "        return\n",
    "    end\n",
    "\n",
    "    if !prior_checked\n",
    "        check_prior_bounds(node, batch_info, global_info)\n",
    "    end\n",
    "\n",
    "    if !batch_info[node][\"ptb\"]\n",
    "        fv = get_forward_value(node)\n",
    "        push!(batch_info[node], \"interval\" => [fv, fv])\n",
    "        push!(batch_info[node], \"lower\" => fv)\n",
    "        push!(batch_info[node], \"upper\" => fv)\n",
    "        return\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = size(global_info[\"model_inputs\"])[end]\n",
    "dim_in = 0\n",
    "for node in global_info[\"start_nodes\"]\n",
    "    value = global_info[\"model_inputs\"]\n",
    "    if haskey(batch_info[node], \"ptb\") \n",
    "        ret_init = init_perturbation(node, value, batch_info[node][\"perturbation_info\"], batch_info, global_info)\n",
    "        push!(batch_info[node], \"interval\" => [ret_init.batch_Low, ret_init.batch_Up])\n",
    "        push!(batch_info[node], \"lower\" => ret_init.batch_Low)\n",
    "        push!(batch_info[node], \"upper\" => ret_init.batch_Up)\n",
    "        push!(batch_info[node], \"bound\" => ret_init)\n",
    "    else\n",
    "        # This input/parameter does not have perturbation.\n",
    "        push!(batch_info[node], \"interval\" => [value, value])\n",
    "        push!(batch_info[node], \"forward_value\" => value)\n",
    "        new_bound = CrownBound3(value, value)#, batch_info[node][\"data_min\", batch_info[node][\"data_max\"]])\n",
    "        push!(batch_info[node], \"lower\" => value)\n",
    "        push!(batch_info[node], \"upper\" => value)\n",
    "        push!(batch_info[node], \"bound\" => new_bound)\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Chain([\n",
    "    Flux.flatten,\n",
    "    Dense(784, 200, relu),\n",
    "    Dense(200, 10)\n",
    "])\n",
    "image_seeds = [MNIST(:train)[i].features for i in 1:1]\n",
    "search_method = BFS(max_iter=1, batch_size=1)\n",
    "split_method = Bisect(1)\n",
    "output_set = BallInf(zeros(10), 1.0)\n",
    "onnx_model_path = \"/home/verification/ModelVerification.jl/debug.onnx\"\n",
    "Flux_model = model\n",
    "image_shape = (28, 28, 1, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
