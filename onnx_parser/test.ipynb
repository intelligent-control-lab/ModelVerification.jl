{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Revise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Images, ImageIO\n",
    "using ONNXNaiveNASflux, NaiveNASflux, .NaiveNASlib\n",
    "using LinearAlgebra\n",
    "using OpenCV\n",
    "using Flux\n",
    "using CSV\n",
    "using DataFrames\n",
    "using DataStructures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "build_flux_model (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "function square_img(image, bbox, img_size)\n",
    "    bbox_width = round(Int, bbox[\"bbox_x2\"] - bbox[\"bbox_x1\"])\n",
    "    bbox_height = round(Int, bbox[\"bbox_y2\"] - bbox[\"bbox_y1\"])\n",
    "    offset_tl = Int.([bbox[\"bbox_x1\"], bbox[\"bbox_y1\"]] .+ 1)\n",
    "    h, _ = img_size\n",
    "    if bbox_width >= bbox_height\n",
    "        sq_img = zeros(UInt8, bbox_width, bbox_width, 3)\n",
    "        if bbox_width >= h\n",
    "            crop_img = image[:, offset_tl[1]: offset_tl[1] + bbox_width - 1, :]\n",
    "            offset_tl[2] = 1\n",
    "            bbox_height = h\n",
    "        elseif offset_tl[2] + bbox_width - 1 >= h\n",
    "            offset_tl[2] = h + 1 - bbox_width\n",
    "            bbox_height = bbox_width\n",
    "            crop_img = image[offset_tl[2] : offset_tl[2] + bbox_width - 1, offset_tl[1] : offset_tl[1] + bbox_width - 1, :]\n",
    "        else\n",
    "            crop_img = image[offset_tl[2] : offset_tl[2] + bbox_width - 1, offset_tl[1]+1 : offset_tl[1] + bbox_width - 1, :]\n",
    "            bbox_height = bbox_width\n",
    "        end\n",
    "        sq_img[1:bbox_height, 1:bbox_width, :] = crop_img\n",
    "    else\n",
    "        sq_img = zeros(UInt8, bbox_height, bbox_height, 3)\n",
    "    end\n",
    "    return sq_img, offset_tl\n",
    "end\n",
    "\n",
    "function preprocess_image(img_path, csv_path)\n",
    "    image = OpenCV.imread(img_path)\n",
    "    _, w, h = size(image)  # (3, 1920, 1200)\n",
    "    # CWH, BGR channel for Julia OpenCV, we desire WHCN for Flux model\n",
    "    image = OpenCV.cvtColor(image, OpenCV.COLOR_BGR2GRAY)\n",
    "    image = OpenCV.cvtColor(image, OpenCV.COLOR_GRAY2RGB)\n",
    "    image = permutedims(image, (3, 2, 1))\n",
    "    \n",
    "    truth_df = DataFrame(CSV.File(csv_path))\n",
    "    bbox = truth_df[!, [:bbox_x1, :bbox_y1, :bbox_x2, :bbox_y2]]\n",
    "    bbox = bbox[parse(Int, split(img_path[1:end-4], '_')[end]) + 1, :]\n",
    "    sq_image, offset_tl = square_img(image, bbox, (h, w))\n",
    "    input_size = 256\n",
    "    sq_image = permutedims(sq_image, (3, 2, 1))  # no need to permute multiple times, will remove it later\n",
    "    resize_img = OpenCV.resize(sq_image, OpenCV.Size{Int32}(input_size, input_size), interpolation=OpenCV.INTER_AREA)\n",
    "    resize_img = resize_img / 255.0\n",
    "    resize_img = permutedims(resize_img, (3, 2, 1))\n",
    "    return resize_img\n",
    "end\n",
    "\n",
    "function get_parallel_chains(comp_vertices, index_more_than_one_outputs)\n",
    "    function get_chain(vertex)\n",
    "        m = Any[]\n",
    "        curr_vertex = vertex\n",
    "        while length(inputs(curr_vertex)) == 1\n",
    "            # println(\"curr vertex \", name(curr_vertex))\n",
    "            push!(m, layer(curr_vertex))\n",
    "            curr_vertex = outputs(curr_vertex)[1]\n",
    "        end\n",
    "        return Chain(m...), curr_vertex\n",
    "    end\n",
    "    outs = outputs(comp_vertices[index_more_than_one_outputs])\n",
    "    @assert length(outs) == 2\n",
    "    chain1, vertex_more_than_one_inputs = get_chain(outs[1])\n",
    "    chain2, _ = get_chain(outs[2])\n",
    "    @assert occursin(\"Add\", name(vertex_more_than_one_inputs))\n",
    "    inner_iter = findfirst(v -> name(v) == name(vertex_more_than_one_inputs), comp_vertices)\n",
    "    if length(chain1) == 0\n",
    "        return SkipConnection(chain2, (+)), inner_iter\n",
    "    elseif length(chain2) == 0\n",
    "        return SkipConnection(chain1, (+)), inner_iter\n",
    "    else\n",
    "        return Parallel(+; α = chain1, β = chain2), inner_iter\n",
    "    end\n",
    "end\n",
    "\n",
    "function build_flux_model(onnx_model_path)\n",
    "    comp_graph = ONNXNaiveNASflux.load(onnx_model_path)\n",
    "    # find mean value\n",
    "    model_vec = Any[]\n",
    "    # sub_vertices = findvertices(\"/Sub\", comp_graph)\n",
    "    # if !isempty(sub_vertices)\n",
    "    #     img_mean = inputs(sub_vertices[1])[2]()\n",
    "    #     println(img_mean)\n",
    "    #     # println(inputs(vertices(comp_graph)[5])[1]())\n",
    "\n",
    "    #     push!(model_vec, x -> x .- img_mean)\n",
    "    # end\n",
    "    \n",
    "\n",
    "    inner_iter = 0\n",
    "    for (index, vertex) in enumerate(vertices(comp_graph))\n",
    "        if index < 5 || index <= inner_iter\n",
    "            continue\n",
    "        end \n",
    "        if string(layer(vertex)) == \"#213\"\n",
    "            push!(model_vec, NNlib.relu)\n",
    "        else\n",
    "            push!(model_vec, layer(vertex))\n",
    "        end\n",
    "        if length(outputs(vertex)) > 1\n",
    "            # println(\"name: \", name(vertex))\n",
    "            parallel_chain, inner_iter = get_parallel_chains(vertices(comp_graph), index)\n",
    "            push!(model_vec, parallel_chain)\n",
    "        end\n",
    "    end\n",
    "    model = Chain(model_vec...)\n",
    "    Flux.testmode!(model)\n",
    "    return (model)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (index, vertex) in enumerate(vertices(comp_graph))\n",
    "    println(inputs(vertex), \"  \", outputs(vertex))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (index, vertex) in enumerate(vertices(comp_graph))\n",
    "    println(outputs(vertex))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set(Any[\"BatchNormalization\", \"Div\", \"Relu\", \"Constant\", \"Sub\", \"Conv\", \"ConvTranspose\", \"AveragePool\", \"Add\"])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompGraph{Vector{NaiveNASlib.AbstractVertex}, Vector{NaiveNASlib.AbstractVertex}}([NaiveNASflux.InputShapeVertex{NaiveNASlib.InputSizeVertex{NaiveNASlib.OutputsVertex{NaiveNASlib.InputVertex{String}}}, NaiveNASflux.GenericFluxConvolutional{2}}], [/final_layer/Conv])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "onnx_model_path = \"/home/verification/ModelVerification.jl/mlp.onnx\"\n",
    "comp_graph = ONNXNaiveNASflux.load(onnx_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "build_flux_model (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function get_parallel_chains(comp_vertices, index_more_than_one_outputs)\n",
    "    function get_chain(vertex)\n",
    "        m = Any[]\n",
    "        curr_vertex = vertex\n",
    "        while length(inputs(curr_vertex)) == 1\n",
    "            # println(\"curr vertex \", name(curr_vertex))\n",
    "            push!(m, layer(curr_vertex))\n",
    "            curr_vertex = outputs(curr_vertex)[1]\n",
    "        end\n",
    "        return Chain(m...), curr_vertex\n",
    "    end\n",
    "    outs = outputs(comp_vertices[index_more_than_one_outputs])\n",
    "    @assert length(outs) == 2\n",
    "    chain1, vertex_more_than_one_inputs = get_chain(outs[1])\n",
    "    chain2, _ = get_chain(outs[2])\n",
    "    @assert occursin(\"Add\", name(vertex_more_than_one_inputs))\n",
    "    inner_iter = findfirst(v -> name(v) == name(vertex_more_than_one_inputs), comp_vertices)\n",
    "    if length(chain1) == 0\n",
    "        return SkipConnection(chain2, (+)), inner_iter\n",
    "    elseif length(chain2) == 0\n",
    "        return SkipConnection(chain1, (+)), inner_iter\n",
    "    else\n",
    "        return Parallel(+; α = chain1, β = chain2), inner_iter\n",
    "    end\n",
    "end\n",
    "\n",
    "function build_flux_model(onnx_model_path)\n",
    "    comp_graph = ONNXNaiveNASflux.load(onnx_model_path)\n",
    "\n",
    "    # find mean value\n",
    "    model_vec = Any[]\n",
    "    # sub_vertices = findvertices(\"/Sub\", comp_graph)\n",
    "    # if !isempty(sub_vertices)\n",
    "    #     img_mean = inputs(sub_vertices[1])[2]()\n",
    "    #     println(img_mean)\n",
    "    #     # println(inputs(vertices(comp_graph)[5])[1]())\n",
    "\n",
    "    #     push!(model_vec, x -> x .- img_mean)\n",
    "    # end\n",
    "    img_mean = reshape([0.48500, 0.45600, 0.40600], (1, 1, 3))\n",
    "    push!(model_vec, x -> x .- img_mean)\n",
    "\n",
    "    img_variance = reshape([0.2990, 0.22400, 0.22500], (1, 1, 3))\n",
    "    push!(model_vec, x -> x ./ img_variance)\n",
    "\n",
    "    inner_iter = 0\n",
    "    for (index, vertex) in enumerate(vertices(comp_graph))\n",
    "        if index < 5 || index <= inner_iter\n",
    "            continue\n",
    "        end \n",
    "        # println(index, \"   \",layer(vertex))\n",
    "        push!(model_vec, layer(vertex))\n",
    "        if length(outputs(vertex)) > 1\n",
    "            # println(name(vertex))\n",
    "            parallel_chain, inner_iter = get_parallel_chains(vertices(comp_graph), index)\n",
    "            push!(model_vec, parallel_chain)\n",
    "        end\n",
    "    end\n",
    "    model = Chain(model_vec...)\n",
    "    Flux.testmode!(model)\n",
    "    return (model)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set(Any[\"BatchNormalization\", \"Div\", \"Relu\", \"Constant\", \"Sub\", \"Conv\", \"ConvTranspose\", \"AveragePool\", \"Add\"])\n",
      "#19"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#20\n",
      "Conv("
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 7), 3 => 64, pad=3, stride=2, bias=false)\n",
      "BatchNorm(64"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", relu, active=false)\n",
      "MeanPool((3, 3), pad=1, stride=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SkipConnection(Chain(Conv((3, 3), 64 => 64, pad=1, bias=false), BatchNorm(64, relu, active=false), Conv((3, 3), 64 => 64, pad=1, bias=false), BatchNorm(64, active=false)), +)\n",
      "#213\n",
      "SkipConnection(Chain(Conv((3, 3), 64 => 64, pad=1, bias=false), BatchNorm(64, relu, active=false), Conv((3, 3), 64 => 64, pad=1, bias=false), BatchNorm(64, active=false)), +)\n",
      "#213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallel(+, α = Chain(Conv((3, 3), 64 => 128, pad=1, stride=2, bias=false), BatchNorm(128, relu, active=false), Conv((3, 3), 128 => 128, pad=1, bias=false), BatchNorm(128, active=false))"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", β = Chain(Conv((1, 1), 64 => 128, stride=2, bias=false), BatchNorm(128, active=false)))\n",
      "#213\n",
      "SkipConnection(Chain(Conv((3, 3), 128 => 128, pad=1, bias=false), BatchNorm(128, relu, active=false), Conv((3, 3), 128 => 128, pad=1, bias=false), BatchNorm(128, active=false)), +)\n",
      "#213\n",
      "Parallel(+, α = Chain(Conv((3, 3), 128 => 256, pad=1, stride=2, bias=false), BatchNorm(256, relu, active=false), Conv((3, 3), 256 => 256, pad=1, bias=false), BatchNorm(256, active=false)), β = Chain(Conv((1, 1), 128 => 256, stride=2, bias=false), BatchNorm(256, active=false)))\n",
      "#213\n",
      "SkipConnection(Chain(Conv((3, 3), 256 => 256, pad=1, bias=false), BatchNorm(256, relu, active=false), Conv((3, 3), 256 => 256, pad=1, bias=false), BatchNorm(256, active=false)), +)\n",
      "#213\n",
      "Parallel(+, α = Chain(Conv((3, 3), 256 => 512, pad=1, stride=2, bias=false), BatchNorm(512, relu, active=false), Conv((3, 3), 512 => 512, pad=1, bias=false), BatchNorm(512, active=false)), β = Chain(Conv((1, 1), 256 => 512, stride=2, bias=false), BatchNorm(512, active=false)))\n",
      "#213\n",
      "SkipConnection(Chain(Conv((3, 3), 512 => 512, pad=1, bias=false), BatchNorm(512, relu, active=false), Conv((3, 3), 512 => 512, pad=1, bias=false), BatchNorm(512, active=false)), +)\n",
      "#213\n",
      "ConvTranspose((2, 2), 512 => 256, stride=2, bias=false)\n",
      "BatchNorm(256, relu, active=false)\n",
      "ConvTranspose((2, 2), 256 => 128, stride=2, bias=false)\n",
      "BatchNorm(128, relu, active=false)\n",
      "ConvTranspose((2, 2), 128 => 64, stride=2, bias=false)\n",
      "BatchNorm(64, relu, active=false)\n",
      "ConvTranspose((2, 2), 64 => 64, stride=2, bias=false)\n",
      "BatchNorm(64, relu, active=false)\n",
      "ConvTranspose((2, 2), 64 => 64, stride=2, bias=false)\n",
      "BatchNorm(64, relu, active=false)\n",
      "Conv("
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1), 64 => 24)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32-element Vector{Nothing}:\n",
       " nothing\n",
       " nothing\n",
       " nothing\n",
       " nothing\n",
       " nothing\n",
       " nothing\n",
       " nothing\n",
       " nothing\n",
       " nothing\n",
       " nothing\n",
       " ⋮\n",
       " nothing\n",
       " nothing\n",
       " nothing\n",
       " nothing\n",
       " nothing\n",
       " nothing\n",
       " nothing\n",
       " nothing\n",
       " nothing"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# +++++++++++++++++++ build flux model +++++++++++++++++++\n",
    "onnx_model_path = \"/home/verification/ModelVerification.jl/onnx_parser/resnet_model.onnx\"\n",
    "model = build_flux_model(onnx_model_path)\n",
    "println.(model)\n",
    "#= queue = Queue{Any}()\n",
    "comp_graph = ONNXNaiveNASflux.load(onnx_model_path)\n",
    "for (index, vertex) in enumerate(vertices(comp_graph))\n",
    "    println(inputs(vertex), \"  \", outputs(vertex))\n",
    "    println(layer(vertex))\n",
    "    enqueue!(queue, layer(vertex))\n",
    "end\n",
    "println(dequeue!(queue)) =#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: using LazySets.vertices in module Main conflicts with an existing identifier.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: using CUDA.name in module Main conflicts with an existing identifier.\n"
     ]
    }
   ],
   "source": [
    "using LazySets\n",
    "using ModelVerification\n",
    "using PyCall\n",
    "using CSV\n",
    "using ONNX\n",
    "using Flux\n",
    "using Test\n",
    "using CUDA\n",
    "using MLDatasets: CIFAR10\n",
    "using MLUtils: splitobs, DataLoader\n",
    "using Accessors\n",
    "using Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float32[-0.21893519 -0.15008841 -0.36900473 -0.33628064 -0.13221027; -0.1850356 -0.101651594 -0.30785286 -0.23966312 -0.21652326; -0.1388096 -0.1630137 -0.1909296 -0.028720766 -0.012907296; -0.047417775 -0.051144868 -0.15390214 0.057320535 0.0035933554; -0.08829597 -0.05016379 -0.05527121 -0.052590728 -0.18598792]\n"
     ]
    }
   ],
   "source": [
    "# # +++++++++++++++++++ preprocess image +++++++++++++++++++\n",
    "img_path = \"./AircraftInspection_00000008.png\"\n",
    "csv_path = \"./SynthPlane_08.csv\"\n",
    "img = preprocess_image(img_path, csv_path)\n",
    "input = reshape(img, (size(img)...,1))   # WHCN for Julia, NCHW for Python\n",
    "input = permutedims(input, (2, 1, 3, 4))\n",
    "img_mean = reshape([0.48500, 0.45600, 0.40600], (1, 1, 3, 1))\n",
    "img_variance = reshape([0.2990, 0.22400, 0.22500], (1, 1, 3, 1))\n",
    "input = (input .- img_mean) ./ img_variance\n",
    "output = model(Float32.(input))\n",
    "println(output[1:5,1:5,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×3 view(::Array{Float64, 4}, 100, 100:101, 1:3, 1) with eltype Float64:\n",
       " -0.5  -0.5  -0.5\n",
       " -0.5  -0.5  -0.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input = reshape(input, 256, 256, 3)\n",
    "input_perturbed = copy(input)\n",
    "# input_perturbed[100:102,100:102,1:3,1] .= -0.5\n",
    "# input_perturbed[1,1,1,1] = -0.5\n",
    "# input_perturbed[100,100,1,1] .= -0.5\n",
    "input_perturbed[100,100:101,1:3,1] .= -0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BallInf{Float64, Vector{Float64}}([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testmode!(model)\n",
    "image_seeds = [input, input_perturbed]  # 256 x 256 x 3 x 2\n",
    "println(typeof(image_seeds[1][1,1,1,1]))\n",
    "search_method = BFS(max_iter=1, batch_size=1)\n",
    "split_method = Bisect(1)\n",
    "output_set = BallInf(zeros(10), 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Zono reach\n",
      "Inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(value = BasicResult(:holds), time = 160.782878615, bytes = 139109526184, gctime = 6.457323193, gcstats = Base.GC_Diff(139109526184, 266, 0, 18641819, 76, 284, 6457323193, 4, 0))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prop_method = ImageStarZono()\n",
    "@timed verify(search_method, split_method, prop_method, Problem(model, image_seeds, output_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
